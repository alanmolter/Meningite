#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dashboard Completo de Meningite Brasil - VersÃ£o 2.0 Corrigida
Inclui todas as anÃ¡lises: regional, avanÃ§ada, ARIMA, testes de hipÃ³teses e exploraÃ§Ã£o livre
"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import streamlit as st
import os
from datetime import datetime
import warnings
from scipy import stats
# Imports condicionais para evitar problemas de compatibilidade
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.seasonal import seasonal_decompose
    STATSMODELS_AVAILABLE = True
except ImportError as e:
    print(f"Aviso: statsmodels nÃ£o disponÃ­vel: {e}")
    STATSMODELS_AVAILABLE = False
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Dashboard Meningite Brasil - AnÃ¡lise Completa",
    page_icon="ğŸ¦ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_all_data():
    """Carrega e prÃ©-processa todos os conjuntos de dados necessÃ¡rios para o dashboard.

    Esta funÃ§Ã£o Ã© responsÃ¡vel por ler os arquivos CSV da pasta 'TABELAS/' e 'data/processed/',
    tratar exceÃ§Ãµes de arquivos ausentes e, em seguida, chamar funÃ§Ãµes auxiliares para
    criar conjuntos de dados derivados, como dados regionais e temporais.

    Returns:
        dict: Um dicionÃ¡rio contendo todos os DataFrames carregados e processados,
              prontos para serem utilizados pelas funÃ§Ãµes de visualizaÃ§Ã£o. As chaves
              do dicionÃ¡rio sÃ£o nomes descritivos dos conjuntos de dados.
              Retorna None se ocorrer um erro crÃ­tico durante o carregamento.
    """
    
    st.info("ğŸ“Š Carregando todos os dados processados...")
    
    try:
        # Dados bÃ¡sicos
        casos_consolidados = pd.read_csv('TABELAS/casos_consolidados_2017_2024.csv')
        sorogrupos_consolidados = pd.read_csv('TABELAS/sorogrupos_consolidados_2007_2024.csv')
        etiologias_consolidadas = pd.read_csv('TABELAS/etiologias_consolidadas_2007_2024.csv')
        
        # Dados de imunizaÃ§Ã£o
        imunizacao_ano = pd.read_csv('TABELAS/imunizacao_por_ano.csv')
        imunizacao_faixa_etaria = pd.read_csv('TABELAS/imunizacao_por_faixa_etaria.csv')
        imunizacao_sorogrupo = pd.read_csv('TABELAS/imunizacao_por_sorogrupo.csv')
        imunizacao_uf = pd.read_csv('TABELAS/imunizacao_por_uf.csv')
        
        # Dados de letalidade e casos
        letalidade_etiologia = pd.read_csv('TABELAS/letalidade_etiologia_2007_2020.csv')
        casos_2017_2022 = pd.read_csv('TABELAS/casos_notificados_2017_2022.csv')
        dados_gerais_2024 = pd.read_csv('TABELAS/dados_gerais_2024.csv')
        bacterianas_2024 = pd.read_csv('TABELAS/bacterianas_2024.csv')
        etiologia_2024 = pd.read_csv('TABELAS/etiologia_2024.csv')
        sorogrupos_2024 = pd.read_csv('TABELAS/sorogrupos_2024.csv')
        
        # Dados de imunizaÃ§Ã£o 2023-2025 (pode ter separador diferente; manter opcional)
        try:
            imunizacao_2023_2025 = pd.read_csv('TABELAS/imunobiologicosem2023a2025.csv')
        except Exception:
            imunizacao_2023_2025 = None

        # Dados de imunizaÃ§Ã£o processados (base principal para anÃ¡lises)
        try:
            imunizacao_processada = pd.read_csv('data/processed/dados_imunizacao_processados.csv')
        except Exception:
            imunizacao_processada = None
        
        # Dados de hospitalizaÃ§Ã£o SIH
        sih_meningite = pd.read_csv('TABELAS/sih_meningite_long.csv')
        
        # Criar dados regionais a partir dos dados disponÃ­veis
        analise_regional = create_regional_data(imunizacao_uf)
        imunizacao_regional = create_temporal_regional_data(imunizacao_2023_2025)
        analise_temporal = create_temporal_analysis(imunizacao_2023_2025)
        matriz_correlacao = create_correlation_matrix()
        
        st.success("âœ… Dados carregados com sucesso!")
        
        return {
            'casos_consolidados': casos_consolidados,
            'sorogrupos_consolidados': sorogrupos_consolidados,
            'etiologias_consolidadas': etiologias_consolidadas,
            'imunizacao_ano': imunizacao_ano,
            'imunizacao_faixa_etaria': imunizacao_faixa_etaria,
            'imunizacao_sorogrupo': imunizacao_sorogrupo,
            'imunizacao_uf': imunizacao_uf,
            'imunizacao_2023_2025': imunizacao_2023_2025,
            'imunizacao_processada': imunizacao_processada,
            'analise_regional': analise_regional,
            'imunizacao_regional': imunizacao_regional,
            'analise_temporal': analise_temporal,
            'matriz_correlacao': matriz_correlacao,
            'casos_2017_2022': casos_2017_2022,
            'dados_gerais_2024': dados_gerais_2024,
            'bacterianas_2024': bacterianas_2024,
            'etiologia_2024': etiologia_2024,
            'sorogrupos_2024': sorogrupos_2024,
            'letalidade_etiologia': letalidade_etiologia,
            'sih_meningite': sih_meningite
        }
    except Exception as e:
        st.error(f"âŒ Erro ao carregar dados: {e}")
        return None

def create_regional_data(imunizacao_uf):
    """Cria um DataFrame com dados regionais simulados a partir de dados por UF.

    Esta funÃ§Ã£o utiliza um mapeamento predefinido de Unidades Federativas (UFs) para
    as cinco grandes regiÃµes do Brasil. Ela entÃ£o gera dados simulados (aleatÃ³rios)
    para o total de doses e a cobertura mÃ©dia de cada regiÃ£o.

    Args:
        imunizacao_uf (pd.DataFrame): DataFrame contendo dados de imunizaÃ§Ã£o por UF.
                                     Atualmente, Ã© usado apenas para referÃªncia do
                                     mapeamento, mas poderia ser usado para agregar
                                     dados reais.

    Returns:
        pd.DataFrame: Um DataFrame com dados agregados por regiÃ£o, contendo as colunas
                      'Regiao', 'Total_UFs', 'Total_Doses' e 'Cobertura_Media'.
    """
    # Mapeamento de UFs para regiÃµes
    mapeamento_regioes = {
        'Norte': ['11 RondÃ´nia', '12 Acre', '13 Amazonas', '14 Roraima', '15 ParÃ¡', '16 AmapÃ¡', '17 Tocantins'],
        'Nordeste': ['21 MaranhÃ£o', '22 PiauÃ­', '23 CearÃ¡', '24 Rio Grande do Norte', '25 ParaÃ­ba', '26 Pernambuco', '27 Alagoas', '28 Sergipe', '29 Bahia'],
        'Centro-Oeste': ['50 Mato Grosso do Sul', '51 Mato Grosso', '52 GoiÃ¡s', '53 Distrito Federal'],
        'Sudeste': ['31 Minas Gerais', '32 EspÃ­rito Santo', '33 Rio de Janeiro', '35 SÃ£o Paulo'],
        'Sul': ['41 ParanÃ¡', '42 Santa Catarina', '43 Rio Grande do Sul']
    }
    
    # Criar dados regionais simulados
    dados_regional = []
    for regiao, ufs in mapeamento_regioes.items():
        total_ufs = len(ufs)
        total_doses = np.random.randint(100000, 1000000)  # Simulado
        cobertura_media = np.random.uniform(70, 95)  # Simulado
        
        dados_regional.append({
            'Regiao': regiao,
            'Total_UFs': total_ufs,
            'Total_Doses': total_doses,
            'Cobertura_Media': cobertura_media
        })
    
    return pd.DataFrame(dados_regional)

def create_temporal_regional_data(imunizacao_2023_2025):
    """Gera dados temporais regionais simulados para anÃ¡lise.

    Esta funÃ§Ã£o cria um DataFrame com dados simulados (aleatÃ³rios) de doses e cobertura
    para cada regiÃ£o do Brasil, ao longo de um perÃ­odo de trÃªs anos (2023-2025).
    Ã‰ Ãºtil para visualizaÃ§Ãµes de sÃ©ries temporais quando dados reais nÃ£o estÃ£o disponÃ­veis.

    Args:
        imunizacao_2023_2025 (pd.DataFrame): DataFrame de referÃªncia. Atualmente nÃ£o utilizado
                                           diretamente para os cÃ¡lculos, mas serve como
                                           gatilho para a criaÃ§Ã£o dos dados.

    Returns:
        pd.DataFrame: Um DataFrame com dados temporais simulados por regiÃ£o,
                      contendo as colunas 'Regiao', 'Ano', 'Total_Doses' e 'Cobertura'.
    """
    # Dados simulados para anÃ¡lise temporal regional
    regioes = ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']
    anos = [2023, 2024, 2025]
    
    dados_temporais = []
    for regiao in regioes:
        for ano in anos:
            dados_temporais.append({
                'Regiao': regiao,
                'Ano': ano,
                'Total_Doses': np.random.randint(50000, 500000),
                'Cobertura': np.random.uniform(75, 98)
            })
    
    return pd.DataFrame(dados_temporais)

def create_temporal_analysis(imunizacao_2023_2025):
    """Cria um DataFrame com dados simulados para anÃ¡lise temporal.

    Gera um conjunto de dados simulados (aleatÃ³rios) de casos de meningite e cobertura
    vacinal para um intervalo de anos (2020-2025). Serve como um substituto para
    anÃ¡lises de tendÃªncia quando dados reais consolidados nÃ£o estÃ£o disponÃ­veis.

    Args:
        imunizacao_2023_2025 (pd.DataFrame): DataFrame de referÃªncia, nÃ£o utilizado
                                           diretamente nos cÃ¡lculos.

    Returns:
        pd.DataFrame: Um DataFrame com dados temporais simulados, contendo as
                      colunas 'Ano', 'Casos' e 'Cobertura'.
    """
    # Dados simulados para anÃ¡lise temporal
    anos = list(range(2020, 2026))
    dados_temporais = []
    
    for ano in anos:
        dados_temporais.append({
            'Ano': ano,
            'Casos': np.random.randint(1000, 5000),
            'Cobertura': np.random.uniform(80, 95)
        })
    
    return pd.DataFrame(dados_temporais)

def create_correlation_matrix():
    """Gera uma matriz de correlaÃ§Ã£o simulada.

    Cria uma matriz de correlaÃ§Ã£o 5x5 com valores aleatÃ³rios para demonstrar
    a funcionalidade de visualizaÃ§Ã£o de correlaÃ§Ãµes (heatmap). As variÃ¡veis
    sÃ£o 'Casos', 'Letalidade', 'Cobertura', 'Populacao' e 'Temperatura'.
    A matriz Ã© simÃ©trica e tem a diagonal principal preenchida com 1.0.

    Returns:
        pd.DataFrame: Uma matriz de correlaÃ§Ã£o simulada como um DataFrame do Pandas.
    """
    # Criar matriz de correlaÃ§Ã£o simulada
    n_vars = 5
    corr_matrix = np.random.rand(n_vars, n_vars)
    np.fill_diagonal(corr_matrix, 1.0)
    
    # Tornar simÃ©trica
    corr_matrix = (corr_matrix + corr_matrix.T) / 2
    
    return pd.DataFrame(
        corr_matrix,
        columns=['Casos', 'Letalidade', 'Cobertura', 'Populacao', 'Temperatura'],
        index=['Casos', 'Letalidade', 'Cobertura', 'Populacao', 'Temperatura']
    )

def show_overview_2024(dados):
    """Exibe a seÃ§Ã£o "VisÃ£o Geral 2024" no dashboard.

    Esta funÃ§Ã£o renderiza uma visÃ£o geral dos dados de meningite para o ano de 2024.
    Ela apresenta mÃ©tricas chave, como total de casos suspeitos e Ã³bitos, letalidade,
    e grÃ¡ficos de distribuiÃ§Ã£o de casos por etiologia e sorogrupo. TambÃ©m inclui
    um resumo estatÃ­stico e informaÃ§Ãµes gerais sobre a doenÃ§a.

    Args:
        dados (dict): O dicionÃ¡rio global contendo todos os DataFrames da aplicaÃ§Ã£o.
                      As chaves 'dados_gerais_2024', 'bacterianas_2024', 'etiologia_2024',
                      e 'sorogrupos_2024' sÃ£o utilizadas.
    """
    st.header("ğŸ  **VisÃ£o Geral 2024 - Meningite Brasil**")
    st.markdown("---")
    
    # Carregar dados especÃ­ficos de 2024
    dados_gerais = dados['dados_gerais_2024']
    bacterianas = dados['bacterianas_2024']
    etiologia = dados['etiologia_2024']
    sorogrupos = dados['sorogrupos_2024']
    
    if dados_gerais is not None and not dados_gerais.empty:
        # MÃ©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = dados_gerais['Casos_Suspeitos'].sum()
            st.metric("ğŸ“Š Total de Casos Suspeitos", f"{total_casos:,}")
        
        with col2:
            total_obitos = dados_gerais['Obitos_Confirmados'].sum()
            st.metric("ğŸ’€ Total de Ã“bitos Confirmados", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("âš ï¸ Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            # Como nÃ£o hÃ¡ coluna UF, vamos mostrar o ano
            ano_2024 = dados_gerais['Ano'].iloc[0]
            st.metric("ğŸ“… Ano", ano_2024)
        
        # GrÃ¡fico de casos por ano (jÃ¡ que nÃ£o temos UF)
        st.subheader("ğŸ“ˆ **Casos por Ano**")
        
        fig_casos_ano = px.bar(
            x=dados_gerais['Ano'],
            y=dados_gerais['Casos_Suspeitos'],
            title="DistribuiÃ§Ã£o de Casos por Ano",
            labels={'x': 'Ano', 'y': 'NÃºmero de Casos'},
            color=dados_gerais['Casos_Suspeitos'],
            color_continuous_scale='Reds'
        )
        
        fig_casos_ano.update_layout(template='plotly_white')
        st.plotly_chart(fig_casos_ano, use_container_width=True)
        
        # AnÃ¡lise por etiologia
        if etiologia is not None and not etiologia.empty:
            st.subheader("ğŸ§¬ **Casos por Etiologia em 2024**")
            
            # Verificar se a coluna existe
            if 'Casos_Suspeitos' in etiologia.columns:
                casos_por_etiologia = etiologia.groupby('Etiologia')['Casos_Suspeitos'].sum().sort_values(ascending=False)
            else:
                # Se nÃ£o existir, usar a primeira coluna numÃ©rica disponÃ­vel
                colunas_numericas = etiologia.select_dtypes(include=[np.number]).columns
                if len(colunas_numericas) > 0:
                    coluna_casos = colunas_numericas[0]
                    casos_por_etiologia = etiologia.groupby('Etiologia')[coluna_casos].sum().sort_values(ascending=False)
                else:
                    st.warning("âš ï¸ NÃ£o foi possÃ­vel encontrar dados numÃ©ricos para anÃ¡lise por etiologia")
                    return
            
            fig_etiologia = px.pie(
                values=casos_por_etiologia.values,
                names=casos_por_etiologia.index,
                title="DistribuiÃ§Ã£o de Casos por Etiologia"
            )
            
            fig_etiologia.update_layout(template='plotly_white')
            st.plotly_chart(fig_etiologia, use_container_width=True)
        
        # AnÃ¡lise por sorogrupo
        if sorogrupos is not None and not sorogrupos.empty:
            st.subheader("ğŸ¦  **Casos por Sorogrupo em 2024**")
            
            # Verificar se a coluna existe
            if 'Casos_Suspeitos' in sorogrupos.columns:
                casos_por_sorogrupo = sorogrupos.groupby('Sorogrupo')['Casos_Suspeitos'].sum().sort_values(ascending=False)
            else:
                # Se nÃ£o existir, usar a primeira coluna numÃ©rica disponÃ­vel
                colunas_numericas = sorogrupos.select_dtypes(include=[np.number]).columns
                if len(colunas_numericas) > 0:
                    coluna_casos = colunas_numericas[0]
                    casos_por_sorogrupo = sorogrupos.groupby('Sorogrupo')[coluna_casos].sum().sort_values(ascending=False)
                else:
                    st.warning("âš ï¸ NÃ£o foi possÃ­vel encontrar dados numÃ©ricos para anÃ¡lise por sorogrupo")
                    return
            
            fig_sorogrupo = px.bar(
                x=casos_por_sorogrupo.index,
                y=casos_por_sorogrupo.values,
                title="DistribuiÃ§Ã£o de Casos por Sorogrupo",
                labels={'x': 'Sorogrupo', 'y': 'NÃºmero de Casos'},
                color=casos_por_sorogrupo.values,
                color_continuous_scale='Blues'
            )
            
            fig_sorogrupo.update_layout(template='plotly_white')
            st.plotly_chart(fig_sorogrupo, use_container_width=True)
        
        # Resumo estatÃ­stico
        st.subheader("ğŸ“‹ **Resumo EstatÃ­stico 2024**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**EstatÃ­sticas Descritivas dos Casos Suspeitos:**")
            st.dataframe(dados_gerais['Casos_Suspeitos'].describe())
        
        with col2:
            st.write("**Dados Gerais 2024:**")
            st.dataframe(dados_gerais)
        
        # InformaÃ§Ãµes sobre meningite
        st.subheader("â„¹ï¸ **Sobre a Meningite**")
        st.markdown("""
        **Meningite** Ã© uma inflamaÃ§Ã£o das membranas que revestem o cÃ©rebro e a medula espinhal.
        
        **Principais sintomas:**
        - Febre alta
        - Dor de cabeÃ§a intensa
        - Rigidez no pescoÃ§o
        - NÃ¡useas e vÃ´mitos
        - AlteraÃ§Ã£o do nÃ­vel de consciÃªncia
        
        **ImportÃ¢ncia da vacinaÃ§Ã£o:**
        - Previne formas graves da doenÃ§a
        - Reduz a transmissÃ£o
        - Protege grupos vulnerÃ¡veis
        """)
    else:
        st.warning("âš ï¸ Dados de 2024 nÃ£o disponÃ­veis")

def show_cases_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise dos Casos Notificados 2017-2024".

    Renderiza uma anÃ¡lise detalhada da evoluÃ§Ã£o temporal dos casos de meningite.
    Apresenta mÃ©tricas gerais, um grÃ¡fico de linha da evoluÃ§Ã£o dos casos, anÃ¡lise
    de sazonalidade (se disponÃ­vel), e uma anÃ¡lise de tendÃªncia linear com
    interpretaÃ§Ãµes estatÃ­sticas detalhadas (coeficiente angular, RÂ², p-valor).

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves 'casos_consolidados'
                      e 'casos_2017_2022'.
    """
    st.header("ğŸ“ˆ **AnÃ¡lise dos Casos Notificados 2017-2024**")
    st.markdown("---")
    
    # Carregar dados de casos
    casos = dados['casos_consolidados']
    casos_2017_2022 = dados['casos_2017_2022']
    
    if casos is not None and not casos.empty:
        # MÃ©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = casos['Casos_Notificados'].sum()
            st.metric("ğŸ“Š Total de Casos Notificados", f"{total_casos:,}")
        
        with col2:
            # Verificar se a coluna Obitos existe
            if 'Obitos' in casos.columns:
                total_obitos = casos['Obitos'].sum()
                st.metric("ğŸ’€ Total de Ã“bitos", f"{total_obitos:,}")
            else:
                st.metric("ğŸ’€ Total de Ã“bitos", "N/A")
        
        with col3:
            # Calcular letalidade se possÃ­vel
            if 'Obitos' in casos.columns and 'Casos_Notificados' in casos.columns:
                total_obitos = casos['Obitos'].sum()
                letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
                st.metric("âš ï¸ Letalidade Geral", f"{letalidade_geral:.1f}%")
            else:
                st.metric("âš ï¸ Letalidade Geral", "N/A")
        
        with col4:
            periodo_anos = casos['Ano'].max() - casos['Ano'].min() + 1
            st.metric("ğŸ“… PerÃ­odo (Anos)", periodo_anos)
        
        # EvoluÃ§Ã£o temporal dos casos
        st.subheader("ğŸ“ˆ **EvoluÃ§Ã£o Temporal dos Casos**")
        
        casos_por_ano = casos.groupby('Ano')['Casos_Notificados'].sum().reset_index()
        
        fig_evolucao = px.line(
            casos_por_ano,
            x='Ano',
            y='Casos_Notificados',
            title="EvoluÃ§Ã£o dos Casos de Meningite (2017-2024)",
            markers=True
        )
        
        fig_evolucao.update_layout(
            xaxis_title="Ano",
            yaxis_title="NÃºmero de Casos",
            template='plotly_white'
        )
        
        fig_evolucao.update_xaxes(tickformat='d')
        st.plotly_chart(fig_evolucao, use_container_width=True)
        
        # ExplicaÃ§Ã£o do grÃ¡fico de evoluÃ§Ã£o temporal
        st.markdown("""
        #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de EvoluÃ§Ã£o Temporal:**
        - **Eixo X (Horizontal):** Anos (2017-2024)
        - **Eixo Y (Vertical):** NÃºmero total de casos notificados por ano
        - **Linha com marcadores:** Cada ponto representa o total de casos em um ano especÃ­fico
        - **TendÃªncia:** A inclinaÃ§Ã£o da linha mostra se os casos estÃ£o aumentando, diminuindo ou estÃ¡veis
        - **VariaÃ§Ãµes:** Picos ou vales podem indicar surtos, mudanÃ§as em polÃ­ticas de saÃºde ou fatores sazonais
        - **Utilidade:** Permite identificar padrÃµes temporais e avaliar a eficÃ¡cia de intervenÃ§Ãµes de saÃºde pÃºblica
        """)
        
        # AnÃ¡lise de sazonalidade
        st.subheader("ğŸŒ¡ï¸ **AnÃ¡lise de Sazonalidade**")
        
        if 'Mes' in casos.columns:
            casos_por_mes = casos.groupby('Mes')['Casos_Notificados'].sum().reset_index()
            
            # Mapear nÃºmeros para nomes dos meses
            meses_nomes = {
                1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Abr', 5: 'Mai', 6: 'Jun',
                7: 'Jul', 8: 'Ago', 9: 'Set', 10: 'Out', 11: 'Nov', 12: 'Dez'
            }
            casos_por_mes['Mes_Nome'] = casos_por_mes['Mes'].map(meses_nomes)
            
            fig_sazonalidade = px.bar(
                casos_por_mes,
                x='Mes_Nome',
                y='Casos_Notificados',
                title="Sazonalidade dos Casos de Meningite",
                color='Casos_Notificados',
                color_continuous_scale='Reds'
            )
            
            fig_sazonalidade.update_layout(
                xaxis_title="MÃªs",
                yaxis_title="NÃºmero de Casos",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_sazonalidade, use_container_width=True)
            
            # ExplicaÃ§Ã£o do grÃ¡fico de sazonalidade
            st.markdown("""
            #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de Sazonalidade:**
            - **Eixo X (Horizontal):** Meses do ano (Jan a Dez)
            - **Eixo Y (Vertical):** NÃºmero total de casos acumulados em cada mÃªs (todos os anos)
            - **Barras coloridas:** Altura representa o total de casos, cores mais intensas = mais casos
            - **PadrÃµes sazonais:** Permite identificar meses com maior/menor incidÃªncia
            - **ImportÃ¢ncia epidemiolÃ³gica:** Ajuda a planejar campanhas preventivas e alocaÃ§Ã£o de recursos
            """)
            
            # InterpretaÃ§Ã£o da sazonalidade
            st.markdown("""
            **ğŸ“Š InterpretaÃ§Ã£o da Sazonalidade:**
            
            **PadrÃµes tÃ­picos observados:**
            - **Inverno/Outono:** Maior incidÃªncia (temperaturas mais baixas)
            - **Primavera/VerÃ£o:** Menor incidÃªncia (temperaturas mais altas)
            
            **Fatores que influenciam:**
            - AglomeraÃ§Ã£o em ambientes fechados
            - Sistema imunolÃ³gico mais vulnerÃ¡vel
            - Maior circulaÃ§Ã£o de vÃ­rus respiratÃ³rios
            """)
        else:
            st.info("â„¹ï¸ Dados de sazonalidade mensal nÃ£o disponÃ­veis")
        
        # DistribuiÃ§Ã£o por ano (jÃ¡ que nÃ£o temos UF)
        st.subheader("ğŸ“Š **DistribuiÃ§Ã£o por Ano**")
        
        fig_distribuicao = px.bar(
            x=casos_por_ano['Ano'],
            y=casos_por_ano['Casos_Notificados'],
            title="Casos por Ano (2017-2024)",
            labels={'x': 'Ano', 'y': 'NÃºmero de Casos'},
            color=casos_por_ano['Casos_Notificados'],
            color_continuous_scale='Blues'
        )
        
        fig_distribuicao.update_layout(
            xaxis_title="Ano",
            yaxis_title="NÃºmero de Casos",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_distribuicao, use_container_width=True)
        
        # AnÃ¡lise de tendÃªncia
        st.subheader("ğŸ“ˆ **AnÃ¡lise de TendÃªncia**")
        
        # Calcular tendÃªncia linear
        x = casos_por_ano['Ano'].values.reshape(-1, 1)
        y = casos_por_ano['Casos_Notificados'].values
        
        if len(x) > 1:
            slope, intercept, r_value, p_value, std_err = stats.linregress(x.flatten(), y)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ğŸ“Š Coeficiente Angular", f"{slope:.1f}")
            
            with col2:
                st.metric("ğŸ“ˆ RÂ²", f"{r_value**2:.3f}")
            
            with col3:
                if p_value < 0.05:
                    st.metric("ğŸ¯ SignificÃ¢ncia", "Significativo (p<0.05)")
                else:
                    st.metric("ğŸ¯ SignificÃ¢ncia", "NÃ£o significativo (pâ‰¥0.05)")
            
            # ExplicaÃ§Ã£o detalhada das mÃ©tricas estatÃ­sticas
            st.markdown("---")
            st.markdown("### ğŸ“š **ExplicaÃ§Ã£o das MÃ©tricas EstatÃ­sticas**")
            
            st.markdown(f"""
            #### ğŸ“Š **Coeficiente Angular ({slope:.1f})**
            - **O que Ã©:** Representa a variaÃ§Ã£o mÃ©dia anual no nÃºmero de casos
            - **InterpretaÃ§Ã£o:** 
              - Se positivo: aumenta {abs(slope):.1f} casos por ano em mÃ©dia
              - Se negativo: diminui {abs(slope):.1f} casos por ano em mÃ©dia
              - Se prÃ³ximo de zero: tendÃªncia estÃ¡vel
            
            #### ğŸ“ˆ **Coeficiente de DeterminaÃ§Ã£o (RÂ² = {r_value**2:.3f})**
            - **O que Ã©:** Mede o quanto da variaÃ§Ã£o nos casos Ã© explicada pela tendÃªncia temporal
            - **Escala:** 0 a 1 (quanto mais prÃ³ximo de 1, melhor o ajuste)
            - **InterpretaÃ§Ã£o atual:** 
              - RÂ² = {r_value**2:.3f} significa que {r_value**2*100:.1f}% da variaÃ§Ã£o nos casos Ã© explicada pelo tempo
              - {100-r_value**2*100:.1f}% da variaÃ§Ã£o se deve a outros fatores (sazonalidade, surtos, polÃ­ticas de saÃºde, etc.)
            - **Qualidade do ajuste:**
              - RÂ² > 0.7: Ajuste forte
              - RÂ² 0.4-0.7: Ajuste moderado  
              - RÂ² < 0.4: Ajuste fraco
              - **Seu resultado:** {"Ajuste forte" if r_value**2 > 0.7 else "Ajuste moderado" if r_value**2 > 0.4 else "Ajuste fraco"}
            
            #### ğŸ¯ **SignificÃ¢ncia EstatÃ­stica (p-valor = {p_value:.4f})**
            - **O que Ã©:** Probabilidade de observar essa tendÃªncia por acaso
            - **InterpretaÃ§Ã£o:**
              - p < 0.05: TendÃªncia estatisticamente significativa (confiÃ¡vel)
              - p â‰¥ 0.05: TendÃªncia pode ser devida ao acaso
              - **Seu resultado:** {"A tendÃªncia Ã© estatisticamente significativa e confiÃ¡vel" if p_value < 0.05 else "A tendÃªncia pode ser devida ao acaso - nÃ£o Ã© estatisticamente significativa"}
            
            #### ğŸ“ **Erro PadrÃ£o ({std_err:.2f})**
            - **O que Ã©:** Mede a incerteza na estimativa do coeficiente angular
            - **InterpretaÃ§Ã£o:** Quanto menor, mais precisa Ã© a estimativa da tendÃªncia
            """)
            
            # InterpretaÃ§Ã£o da tendÃªncia
            if slope > 0:
                st.success("ğŸ“ˆ **TendÃªncia:** Aumento nos casos ao longo do tempo")
            elif slope < 0:
                st.success("ğŸ“‰ **TendÃªncia:** DiminuiÃ§Ã£o nos casos ao longo do tempo")
            else:
                st.info("â¡ï¸ **TendÃªncia:** EstÃ¡vel ao longo do tempo")
        else:
            st.warning("âš ï¸ Dados insuficientes para anÃ¡lise de tendÃªncia")
        
        # Resumo estatÃ­stico
        st.subheader("ğŸ“‹ **Resumo EstatÃ­stico**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**EstatÃ­sticas Descritivas dos Casos:**")
            st.dataframe(casos_por_ano['Casos_Notificados'].describe())
        
        with col2:
            st.write("**Dados por Ano:**")
            st.dataframe(casos_por_ano)
        
        # InformaÃ§Ãµes sobre a anÃ¡lise
        st.subheader("â„¹ï¸ **Sobre a AnÃ¡lise**")
        st.markdown("""
        **Esta anÃ¡lise mostra:**
        - EvoluÃ§Ã£o temporal dos casos de meningite
        - PadrÃµes sazonais (quando disponÃ­veis)
        - TendÃªncias estatÃ­sticas significativas
        - DistribuiÃ§Ã£o temporal dos casos
        
        **ImportÃ¢ncia:**
        - Identificar perÃ­odos de maior risco
        - Planejar aÃ§Ãµes de prevenÃ§Ã£o
        - Avaliar efetividade de medidas de controle
        """)
    else:
        st.warning("âš ï¸ Dados de casos nÃ£o disponÃ­veis")

def show_sorogrupos_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise de Sorogrupos e RelaÃ§Ãµes NÃ£o Lineares".

    Esta funÃ§Ã£o realiza uma anÃ¡lise aprofundada dos sorogrupos de meningite.
    Ela calcula e exibe a letalidade por sorogrupo, explora relaÃ§Ãµes nÃ£o lineares
    entre casos e letalidade com regressÃ£o polinomial, realiza anÃ¡lises de
    correlaÃ§Ã£o de Pearson e Spearman, e oferece uma anÃ¡lise de clustering (K-Means)
    para agrupar sorogrupos com perfis epidemiolÃ³gicos semelhantes.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza a chave 'sorogrupos_consolidados'.
    """
    st.header("ğŸ¦  **AnÃ¡lise de Sorogrupos e RelaÃ§Ãµes NÃ£o Lineares**")
    st.markdown("---")
    
    # Carregar dados de sorogrupos
    sorogrupos = dados['sorogrupos_consolidados']
    
    if sorogrupos is not None and not sorogrupos.empty:
        # MÃ©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = sorogrupos['Casos'].sum()
            st.metric("ğŸ“Š Total de Casos", f"{total_casos:,}")
        
        with col2:
            total_obitos = sorogrupos['Obitos'].sum()
            st.metric("ğŸ’€ Total de Ã“bitos", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("âš ï¸ Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            n_sorogrupos = sorogrupos['Sorogrupo'].nunique()
            st.metric("ğŸ¦  Sorogrupos", n_sorogrupos)
        
        # AnÃ¡lise de letalidade por sorogrupo
        st.subheader("ğŸ“Š **Letalidade por Sorogrupo**")
        
        letalidade_por_sorogrupo = sorogrupos.groupby('Sorogrupo').agg({
            'Casos': 'sum',
            'Obitos': 'sum'
        }).reset_index()
        
        letalidade_por_sorogrupo['Letalidade'] = (
            letalidade_por_sorogrupo['Obitos'] / letalidade_por_sorogrupo['Casos'] * 100
        ).round(2)
        
        # GrÃ¡fico de barras
        fig_letalidade = px.bar(
            letalidade_por_sorogrupo,
            x='Sorogrupo',
            y='Letalidade',
            title="Letalidade por Sorogrupo",
            color='Letalidade',
            color_continuous_scale='Reds'
        )
        
        fig_letalidade.update_layout(
            yaxis_title="Taxa de Letalidade (%)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_letalidade, use_container_width=True)
        
        # ExplicaÃ§Ã£o do grÃ¡fico de letalidade por sorogrupo
        st.markdown("""
        #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de Letalidade por Sorogrupo:**
        - **Eixo X (Horizontal):** Diferentes sorogrupos de meningite (A, B, C, W, Y, etc.)
        - **Eixo Y (Vertical):** Taxa de letalidade em percentual (Ã³bitos/casos Ã— 100)
        - **Barras coloridas:** Altura representa a letalidade, cores mais intensas = maior letalidade
        - **ImportÃ¢ncia clÃ­nica:** Identifica quais sorogrupos sÃ£o mais letais e necessitam atenÃ§Ã£o especial
        - **AplicaÃ§Ã£o:** Orienta estratÃ©gias de tratamento e priorizaÃ§Ã£o de vacinaÃ§Ã£o
        """)
        
        # Mostrar tabela com dados detalhados
        st.markdown("#### ğŸ“‹ **Dados Detalhados por Sorogrupo:**")
        st.dataframe(letalidade_por_sorogrupo.sort_values('Letalidade', ascending=False))
        
        # AnÃ¡lise de relaÃ§Ãµes nÃ£o lineares
        st.subheader("ğŸ”— **AnÃ¡lise de RelaÃ§Ãµes NÃ£o Lineares**")
        
        # Preparar dados para anÃ¡lise
        dados_analise = sorogrupos.groupby('Sorogrupo').agg({
            'Casos': 'sum',
            'Obitos': 'sum'
        }).reset_index()
        
        dados_analise['Letalidade'] = (
            dados_analise['Obitos'] / dados_analise['Casos'] * 100
        ).round(2)
        
        # GrÃ¡fico de dispersÃ£o com regressÃ£o polinomial
        fig_dispersao = px.scatter(
            dados_analise,
            x='Casos',
            y='Letalidade',
            title="RelaÃ§Ã£o entre Casos e Letalidade por Sorogrupo",
            text='Sorogrupo',
            size='Casos'
        )
        
        # Adicionar linha de tendÃªncia polinomial
        if len(dados_analise) > 2:
            x = dados_analise['Casos'].values
            y = dados_analise['Letalidade'].values
            
            # Ajuste polinomial de grau 2
            coeffs = np.polyfit(x, y, 2)
            poly = np.poly1d(coeffs)
            
            x_trend = np.linspace(x.min(), x.max(), 100)
            y_trend = poly(x_trend)
            
            fig_dispersao.add_trace(go.Scatter(
                x=x_trend,
                y=y_trend,
                mode='lines',
                name='TendÃªncia Polinomial (grau 2)',
                line=dict(color='red', dash='dash')
            ))
        
        fig_dispersao.update_layout(
            xaxis_title="NÃºmero de Casos",
            yaxis_title="Taxa de Letalidade (%)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_dispersao, use_container_width=True)
        
        # ExplicaÃ§Ã£o do grÃ¡fico de dispersÃ£o com regressÃ£o polinomial
        st.markdown("""
        #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de DispersÃ£o com RegressÃ£o Polinomial:**
        - **Eixo X (Horizontal):** NÃºmero total de casos por sorogrupo
        - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
        - **Pontos:** Cada ponto representa um sorogrupo especÃ­fico
        - **Tamanho dos pontos:** Proporcional ao nÃºmero de casos (pontos maiores = mais casos)
        - **Linha tracejada vermelha:** TendÃªncia polinomial de grau 2 (curva que melhor se ajusta aos dados)
        - **AnÃ¡lise nÃ£o-linear:** Permite identificar relaÃ§Ãµes complexas que nÃ£o seguem uma linha reta
        - **InterpretaÃ§Ã£o epidemiolÃ³gica:** 
          - Se a curva Ã© crescente: sorogrupos com mais casos tendem a ter maior letalidade
          - Se a curva Ã© decrescente: sorogrupos com mais casos tendem a ter menor letalidade
          - Curva em U ou invertida: relaÃ§Ã£o complexa que requer investigaÃ§Ã£o detalhada
        """)
        
        # AnÃ¡lise de correlaÃ§Ã£o
        st.subheader("ğŸ“Š **AnÃ¡lise de CorrelaÃ§Ã£o**")
        
        if len(dados_analise) > 2:
            # CorrelaÃ§Ã£o de Pearson
            corr_pearson, p_pearson = stats.pearsonr(dados_analise['Casos'], dados_analise['Letalidade'])
            
            # CorrelaÃ§Ã£o de Spearman
            corr_spearman, p_spearman = stats.spearmanr(dados_analise['Casos'], dados_analise['Letalidade'])
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("ğŸ“ˆ CorrelaÃ§Ã£o de Pearson", f"{corr_pearson:.3f}")
                st.write(f"P-valor: {p_pearson:.4f}")
                st.write("**InterpretaÃ§Ã£o:** Mede correlaÃ§Ã£o linear")
                if abs(corr_pearson) > 0.7:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o forte")
                elif abs(corr_pearson) > 0.3:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o moderada")
                else:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o fraca")
            
            with col2:
                st.metric("ğŸ“Š CorrelaÃ§Ã£o de Spearman", f"{corr_spearman:.3f}")
                st.write(f"P-valor: {p_spearman:.4f}")
                st.write("**InterpretaÃ§Ã£o:** Mede correlaÃ§Ã£o monotÃ´nica")
                if abs(corr_spearman) > 0.7:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o forte")
                elif abs(corr_spearman) > 0.3:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o moderada")
                else:
                    st.write("**ForÃ§a:** CorrelaÃ§Ã£o fraca")
            
            # InterpretaÃ§Ã£o das correlaÃ§Ãµes
            st.markdown(f"""
            ### ğŸ“š **ExplicaÃ§Ã£o Detalhada das CorrelaÃ§Ãµes:**
            
            #### ğŸ“ˆ **CorrelaÃ§Ã£o de Pearson = {corr_pearson:.3f}**
            - **O que mede:** ForÃ§a da relaÃ§Ã£o linear entre nÃºmero de casos e letalidade
            - **Escala:** -1 a +1
            - **InterpretaÃ§Ã£o atual:**
              - Valor = {corr_pearson:.3f}
              - {"CorrelaÃ§Ã£o positiva" if corr_pearson > 0 else "CorrelaÃ§Ã£o negativa" if corr_pearson < 0 else "Sem correlaÃ§Ã£o"}
              - P-valor = {p_pearson:.4f} â†’ {"Estatisticamente significativa" if p_pearson < 0.05 else "NÃ£o significativa"}
            - **LimitaÃ§Ãµes:** Assume relaÃ§Ã£o linear, sensÃ­vel a outliers
            
            #### ğŸ“Š **CorrelaÃ§Ã£o de Spearman = {corr_spearman:.3f}**
            - **O que mede:** ForÃ§a da relaÃ§Ã£o monotÃ´nica (crescente ou decrescente)
            - **Escala:** -1 a +1
            - **InterpretaÃ§Ã£o atual:**
              - Valor = {corr_spearman:.3f}
              - {"RelaÃ§Ã£o monotÃ´nica positiva" if corr_spearman > 0 else "RelaÃ§Ã£o monotÃ´nica negativa" if corr_spearman < 0 else "Sem relaÃ§Ã£o monotÃ´nica"}
              - P-valor = {p_spearman:.4f} â†’ {"Estatisticamente significativa" if p_spearman < 0.05 else "NÃ£o significativa"}
            - **Vantagens:** Detecta relaÃ§Ãµes nÃ£o-lineares, robusto a outliers
            
            #### ğŸ” **ComparaÃ§Ã£o dos Resultados:**
            - **DiferenÃ§a:** {abs(corr_pearson - corr_spearman):.3f}
            - **InterpretaÃ§Ã£o:** {"RelaÃ§Ã£o aproximadamente linear" if abs(corr_pearson - corr_spearman) < 0.1 else "PossÃ­vel relaÃ§Ã£o nÃ£o-linear"}
            
            #### ğŸ“‹ **Escalas de InterpretaÃ§Ã£o:**
            - **0.0 - 0.3:** CorrelaÃ§Ã£o fraca
            - **0.3 - 0.7:** CorrelaÃ§Ã£o moderada
            - **0.7 - 1.0:** CorrelaÃ§Ã£o forte
            """)
        
        # EvoluÃ§Ã£o temporal da letalidade
        st.subheader("ğŸ“ˆ **EvoluÃ§Ã£o Temporal da Letalidade**")
        
        if 'Ano' in sorogrupos.columns:
            letalidade_temporal = sorogrupos.groupby(['Ano', 'Sorogrupo']).agg({
                'Casos': 'sum',
                'Obitos': 'sum'
            }).reset_index()
            
            letalidade_temporal['Letalidade'] = (
                letalidade_temporal['Obitos'] / letalidade_temporal['Casos'] * 100
            ).round(2)
            
            # GrÃ¡fico de linha
            fig_temporal = px.line(
                letalidade_temporal,
                x='Ano',
                y='Letalidade',
                color='Sorogrupo',
                title="EvoluÃ§Ã£o da Letalidade por Sorogrupo ao Longo do Tempo",
                markers=True
            )
            
            fig_temporal.update_layout(
                xaxis_title="Ano",
                yaxis_title="Taxa de Letalidade (%)",
                template='plotly_white'
            )
            
            fig_temporal.update_xaxes(tickformat='d')
            st.plotly_chart(fig_temporal, use_container_width=True)
        
        # AnÃ¡lise de clustering
        st.subheader("ğŸ¯ **AnÃ¡lise de Clustering**")
        
        if len(dados_analise) > 3:
            # Preparar dados para clustering
            dados_cluster = dados_analise[['Casos', 'Letalidade']].copy()
            
            # Normalizar dados
            scaler = StandardScaler()
            dados_cluster_norm = scaler.fit_transform(dados_cluster)
            
            # NÃºmero de clusters
            n_clusters = st.slider("NÃºmero de Clusters:", 2, min(5, len(dados_cluster)), 3)
            
            if st.button("ğŸ¯ Executar Clustering"):
                try:
                    # Aplicar K-Means
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                    clusters = kmeans.fit_predict(dados_cluster_norm)
                    
                    # Adicionar clusters aos dados
                    dados_cluster['Cluster'] = clusters
                    
                    # GrÃ¡fico de clusters
                    fig_cluster = px.scatter(
                        dados_cluster,
                        x='Casos',
                        y='Letalidade',
                        color='Cluster',
                        title=f"Clusters de Sorogrupos (K={n_clusters})",
                        text=dados_analise['Sorogrupo'],
                        size='Casos'
                    )
                    
                    fig_cluster.update_layout(
                        xaxis_title="NÃºmero de Casos",
                        yaxis_title="Taxa de Letalidade (%)",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_cluster, use_container_width=True)
                    
                    # ExplicaÃ§Ã£o do grÃ¡fico de clustering K-Means
                    st.markdown(f"""
                    #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de Clustering K-Means:**
                    - **Eixo X (Horizontal):** NÃºmero de casos por sorogrupo
                    - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
                    - **Cores diferentes:** Cada cor representa um cluster diferente
                    - **Tamanho dos pontos:** Proporcional ao nÃºmero de casos
                    - **Algoritmo:** K-Means agrupa sorogrupos similares em casos e letalidade
                    
                    #### ğŸ¯ **Como interpretar os clusters:**
                    - **Cluster 0:** Sorogrupos com caracterÃ­sticas similares de casos/letalidade
                    - **Proximidade:** Sorogrupos no mesmo cluster tÃªm comportamento epidemiolÃ³gico similar
                    - **SeparaÃ§Ã£o:** Clusters distintos indicam perfis epidemiolÃ³gicos diferentes
                    - **AplicaÃ§Ã£o prÃ¡tica:** Permite estratÃ©gias de controle diferenciadas por cluster
                    """)
                    
                    # Resumo dos clusters
                    st.subheader("ğŸ“Š **Resumo dos Clusters**")
                    for i in range(n_clusters):
                        cluster_data = dados_cluster[dados_cluster['Cluster'] == i]
                        st.write(f"**Cluster {i}:** {len(cluster_data)} sorogrupos")
                        for idx in cluster_data.index:
                            sorogrupo = dados_analise.loc[idx, 'Sorogrupo']
                            casos = cluster_data.loc[idx, 'Casos']
                            letalidade = cluster_data.loc[idx, 'Letalidade']
                            st.write(f"  - {sorogrupo}: {casos} casos, {letalidade:.1f}% letalidade")
                    
                except Exception as e:
                    st.error(f"Erro no clustering: {e}")
        
        # Resumo das anÃ¡lises
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Resumo das AnÃ¡lises de Sorogrupos:**
        
        **1. AnÃ¡lise de Letalidade:**
        - IdentificaÃ§Ã£o dos sorogrupos mais letais
        - ComparaÃ§Ã£o entre diferentes tipos
        - PadrÃµes de mortalidade
        
        **2. RelaÃ§Ãµes NÃ£o Lineares:**
        - AnÃ¡lise de correlaÃ§Ãµes complexas
        - IdentificaÃ§Ã£o de padrÃµes nÃ£o lineares
        - RegressÃ£o polinomial para tendÃªncias
        
        **3. AnÃ¡lise Temporal:**
        - EvoluÃ§Ã£o da letalidade ao longo do tempo
        - IdentificaÃ§Ã£o de tendÃªncias
        - ComparaÃ§Ã£o entre perÃ­odos
        
        **4. Clustering:**
        - Agrupamento de sorogrupos similares
        - IdentificaÃ§Ã£o de padrÃµes ocultos
        - AnÃ¡lise de similaridades epidemiolÃ³gicas
        """)
        
    else:
        st.error("âŒ Dados de sorogrupos nÃ£o disponÃ­veis")

def show_etiologia_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise por Etiologia e AnÃ¡lise de Componentes Principais".

    Esta funÃ§Ã£o consolida e analisa os dados de meningite por etiologia (agente causador).
    Ela padroniza os nomes das etiologias, exibe a distribuiÃ§Ã£o de casos e letalidade,
    e realiza anÃ¡lises avanÃ§adas como AnÃ¡lise de Componentes Principais (PCA) para
    reduÃ§Ã£o de dimensionalidade, uma matriz de correlaÃ§Ã£o para identificar padrÃµes
    temporais entre etiologias, e anÃ¡lise de sazonalidade.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves
                      'etiologias_consolidadas', 'etiologia_2024', e 'sih_meningite'.
    """
    st.header("ğŸ§¬ **AnÃ¡lise por Etiologia e AnÃ¡lise de Componentes Principais**")
    st.markdown("---")
    
    # Carregar e consolidar dados de etiologia
    etiologia_consolidada = dados['etiologias_consolidadas']
    etiologia_2024 = dados['etiologia_2024']
    
    if etiologia_consolidada is not None and not etiologia_consolidada.empty:
        # Padronizar nomes das etiologias para remover duplicatas
        mapeamento_etiologias = {
            'DoenÃ§a MeningocÃ³cica': 'Meningite MeningocÃ³cica',
            'DoenÃ§a meningocÃ³cica': 'Meningite MeningocÃ³cica',
            'Meningite PneumocÃ³cica': 'Meningite PneumocÃ³cica',
            'Meningite pneumocÃ³cica': 'Meningite PneumocÃ³cica',
            'Meningite Tuberculosa': 'Meningite Tuberculosa',
            'Meningite tuberculosa': 'Meningite Tuberculosa',
            'Meningite bacteriana': 'Meningite Bacteriana',
            'Meningite bacteriana nÃ£o especificada': 'Meningite Bacteriana',
            'Meningite por hemÃ³filo': 'Meningite por HemÃ³filo',
            'Meningite por outras bactÃ©rias': 'Meningite por Outras BactÃ©rias',
            'Meningite viral': 'Meningite Viral',
            'Meningite de outra etiologia': 'Meningite de Outra Etiologia',
            'Meningite nÃ£o especificada': 'Meningite NÃ£o Especificada',
            'Ignorado/sem informaÃ§Ã£o': 'Ignorado/Sem InformaÃ§Ã£o'
        }
        
        # Aplicar mapeamento e consolidar dados
        etiologia_consolidada['Etiologia_Padronizada'] = etiologia_consolidada['Etiologia'].map(mapeamento_etiologias).fillna(etiologia_consolidada['Etiologia'])
        
        # Se temos dados de 2024, adicionar ao consolidado
        if etiologia_2024 is not None and not etiologia_2024.empty:
            etiologia_2024['Etiologia_Padronizada'] = etiologia_2024['Etiologia'].map(mapeamento_etiologias).fillna(etiologia_2024['Etiologia'])
            
            # Adicionar dados de 2024 ao consolidado
            for _, row in etiologia_2024.iterrows():
                etiologia_consolidada = pd.concat([
                    etiologia_consolidada,
                    pd.DataFrame([{
                        'Ano': row['Ano'],
                        'Etiologia': row['Etiologia'],
                        'Etiologia_Padronizada': row['Etiologia_Padronizada'],
                        'Casos': row['Casos'],
                        'Obitos': row['Obitos'],
                        'Letalidade': row['Letalidade'],
                        'Taxa_Letalidade': row['Letalidade']
                    }])
                ], ignore_index=True)
        
        # Usar a coluna padronizada para anÃ¡lises
        etiologia = etiologia_consolidada.copy()
        etiologia['Etiologia'] = etiologia['Etiologia_Padronizada']
        
        # Remover duplicatas baseadas em Ano e Etiologia padronizada
        etiologia = etiologia.drop_duplicates(subset=['Ano', 'Etiologia'], keep='first')
        
        # MÃ©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = etiologia['Casos'].sum() if 'Casos' in etiologia.columns else 0
            st.metric("ğŸ“Š Total de Casos", f"{total_casos:,}")
        
        with col2:
            total_obitos = etiologia['Obitos'].sum() if 'Obitos' in etiologia.columns else 0
            st.metric("ğŸ’€ Total de Ã“bitos", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("âš ï¸ Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            n_etiologias = etiologia['Etiologia'].nunique()
            st.metric("ğŸ§¬ Etiologias Ãšnicas", n_etiologias)
        
        # DiagnÃ³stico das etiologias
        st.subheader("ğŸ” **DiagnÃ³stico das Etiologias**")
        
        # Mostrar etiologias Ãºnicas
        etiologias_unicas = sorted(etiologia['Etiologia'].unique())
        st.write(f"**Etiologias Ãºnicas encontradas ({len(etiologias_unicas)}):**")
        
        # Criar colunas para melhor visualizaÃ§Ã£o
        n_cols = 3
        for i in range(0, len(etiologias_unicas), n_cols):
            cols = st.columns(n_cols)
            for j, col in enumerate(cols):
                if i + j < len(etiologias_unicas):
                    with col:
                        st.write(f"â€¢ {etiologias_unicas[i + j]}")
        
        # Verificar possÃ­veis duplicatas por nome similar
        st.write("**VerificaÃ§Ã£o de possÃ­veis duplicatas:**")
        etiologias_lower = [et.lower().strip() for et in etiologias_unicas]
        possiveis_duplicatas = []
        
        for i, et1 in enumerate(etiologias_lower):
            for j, et2 in enumerate(etiologias_lower[i+1:], i+1):
                # Verificar similaridade (nomes que diferem apenas por capitalizaÃ§Ã£o ou espaÃ§os)
                if et1 == et2 or et1.replace(' ', '') == et2.replace(' ', ''):
                    possiveis_duplicatas.append((etiologias_unicas[i], etiologias_unicas[j]))
        
        if possiveis_duplicatas:
            st.warning("âš ï¸ **PossÃ­veis duplicatas encontradas:**")
            for dup1, dup2 in possiveis_duplicatas:
                st.write(f"â€¢ '{dup1}' vs '{dup2}'")
        else:
            st.success("âœ… **Nenhuma duplicata Ã³bvia encontrada**")
        
        st.markdown("---")
        
        # AnÃ¡lise de casos por etiologia
        st.subheader("ğŸ“Š **Casos por Etiologia**")
        
        # Verificar se a coluna Casos existe e tratar valores NaN
        if 'Casos' in etiologia.columns:
            # Substituir valores NaN por 0 para anÃ¡lise
            etiologia_analise = etiologia.copy()
            etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
            
            casos_por_etiologia = etiologia_analise.groupby('Etiologia')['Casos'].sum().sort_values(ascending=False)
            
            # Filtrar apenas etiologias com casos > 0 para melhor visualizaÃ§Ã£o
            casos_por_etiologia = casos_por_etiologia[casos_por_etiologia > 0]
            
            if len(casos_por_etiologia) > 0:
                fig_casos = px.bar(
                    casos_por_etiologia,
                    x=casos_por_etiologia.index,
                    y=casos_por_etiologia.values,
                    title="DistribuiÃ§Ã£o de Casos por Etiologia",
                    color=casos_por_etiologia.values,
                    color_continuous_scale='Blues'
                )
                
                fig_casos.update_layout(
                    xaxis_title="Etiologia",
                    yaxis_title="NÃºmero de Casos",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_casos, use_container_width=True)
                
                # Mostrar estatÃ­sticas
                st.write(f"**Total de etiologias Ãºnicas:** {len(casos_por_etiologia)}")
                st.write(f"**Etiologia com mais casos:** {casos_por_etiologia.index[0]} ({casos_por_etiologia.iloc[0]:,.0f} casos)")
            else:
                st.warning("âš ï¸ Nenhum caso encontrado nos dados de etiologia")
        else:
            st.warning("âš ï¸ Coluna 'Casos' nÃ£o encontrada nos dados de etiologia")
        
        # AnÃ¡lise de letalidade por etiologia
        st.subheader("âš ï¸ **Letalidade por Etiologia**")
        
        # Verificar se as colunas necessÃ¡rias existem
        if 'Casos' in etiologia.columns and 'Obitos' in etiologia.columns:
            # Substituir valores NaN por 0 para anÃ¡lise
            etiologia_analise = etiologia.copy()
            etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
            etiologia_analise['Obitos'] = etiologia_analise['Obitos'].fillna(0)
            
            letalidade_por_etiologia = etiologia_analise.groupby('Etiologia').agg({
                'Casos': 'sum',
                'Obitos': 'sum'
            }).reset_index()
            
            # Calcular letalidade apenas para etiologias com casos > 0
            letalidade_por_etiologia = letalidade_por_etiologia[letalidade_por_etiologia['Casos'] > 0]
            
            if len(letalidade_por_etiologia) > 0:
                letalidade_por_etiologia['Letalidade'] = (
                    letalidade_por_etiologia['Obitos'] / letalidade_por_etiologia['Casos'] * 100
                ).round(2)
                
                # Substituir valores infinitos por 0
                letalidade_por_etiologia['Letalidade'] = letalidade_por_etiologia['Letalidade'].replace([np.inf, -np.inf], 0)
                
                fig_letalidade = px.bar(
                    letalidade_por_etiologia,
                    x='Etiologia',
                    y='Letalidade',
                    title="Letalidade por Etiologia",
                    color='Letalidade',
                    color_continuous_scale='Reds'
                )
                
                fig_letalidade.update_layout(
                    yaxis_title="Taxa de Letalidade (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_letalidade, use_container_width=True)
                
                # Mostrar estatÃ­sticas
                st.write(f"**Total de etiologias com dados vÃ¡lidos:** {len(letalidade_por_etiologia)}")
                st.write(f"**Etiologia com maior letalidade:** {letalidade_por_etiologia.loc[letalidade_por_etiologia['Letalidade'].idxmax(), 'Etiologia']} ({letalidade_por_etiologia['Letalidade'].max():.1f}%)")
            else:
                st.warning("âš ï¸ Nenhuma etiologia com casos vÃ¡lidos encontrada")
        else:
            st.warning("âš ï¸ Colunas 'Casos' e/ou 'Obitos' nÃ£o encontradas nos dados de etiologia")
        
        # AnÃ¡lise de Componentes Principais (PCA)
        st.subheader("ğŸ”¬ **AnÃ¡lise de Componentes Principais (PCA)**")
        
        if len(letalidade_por_etiologia) > 2:
            try:
                from sklearn.decomposition import PCA
                
                # Preparar dados para PCA - tratar valores NaN
                dados_pca = letalidade_por_etiologia[['Casos', 'Letalidade']].copy()
                
                # Substituir valores NaN por 0 para permitir anÃ¡lise PCA
                dados_pca = dados_pca.fillna(0)
                
                # Verificar se ainda hÃ¡ dados vÃ¡lidos apÃ³s tratamento
                if dados_pca.isnull().sum().sum() == 0 and dados_pca.shape[0] > 0:
                    # Normalizar dados
                    scaler = StandardScaler()
                    dados_pca_norm = scaler.fit_transform(dados_pca)
                    
                    # Aplicar PCA
                    pca = PCA(n_components=min(2, dados_pca.shape[1]))
                    componentes = pca.fit_transform(dados_pca_norm)
                    
                    # Criar DataFrame com componentes
                    df_pca = pd.DataFrame(
                        componentes,
                        columns=[f'Componente {i+1}' for i in range(componentes.shape[1])],
                        index=letalidade_por_etiologia['Etiologia']
                    )
                    
                    # GrÃ¡fico de componentes
                    if componentes.shape[1] >= 2:
                        fig_pca = px.scatter(
                            df_pca,
                            x='Componente 1',
                            y='Componente 2',
                            title="AnÃ¡lise de Componentes Principais",
                            text=df_pca.index,
                            size=[10] * len(df_pca)
                        )
                        
                        fig_pca.update_layout(template='plotly_white')
                        st.plotly_chart(fig_pca, use_container_width=True)
                        
                        # ExplicaÃ§Ã£o do grÃ¡fico de PCA 2D
                        st.markdown("""
                        #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de PCA (2 Componentes):**
                        - **Eixo X (Horizontal):** Componente Principal 1 (direÃ§Ã£o de maior variaÃ§Ã£o)
                        - **Eixo Y (Vertical):** Componente Principal 2 (segunda maior direÃ§Ã£o de variaÃ§Ã£o)
                        - **Pontos:** Cada ponto representa uma etiologia no espaÃ§o reduzido
                        - **DistÃ¢ncia entre pontos:** Etiologias prÃ³ximas tÃªm comportamentos similares
                        - **PosiÃ§Ã£o nos quadrantes:** Diferentes combinaÃ§Ãµes de casos e letalidade
                        - **ReduÃ§Ã£o dimensional:** Simplifica anÃ¡lise de mÃºltiplas variÃ¡veis em 2D
                        """)
                    else:
                        # Se sÃ³ temos 1 componente, mostrar como grÃ¡fico de barras
                        fig_pca = px.bar(
                            x=df_pca.index,
                            y=df_pca['Componente 1'],
                            title="AnÃ¡lise de Componentes Principais (1 Componente)",
                            labels={'x': 'Etiologia', 'y': 'Componente 1'}
                        )
                        fig_pca.update_layout(template='plotly_white')
                        st.plotly_chart(fig_pca, use_container_width=True)
                        
                        # ExplicaÃ§Ã£o do grÃ¡fico de PCA 1D
                        st.markdown("""
                        #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de PCA (1 Componente):**
                        - **Eixo X (Horizontal):** Diferentes etiologias
                        - **Eixo Y (Vertical):** Valor do Componente Principal 1
                        - **Altura das barras:** Representa a projeÃ§Ã£o de cada etiologia no componente principal
                        - **Valores positivos/negativos:** Indicam diferentes padrÃµes de casos e letalidade
                        - **Utilidade:** Ordena etiologias por sua similaridade em um eixo principal
                        """)
                    
                    # InformaÃ§Ãµes sobre PCA
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**VariÃ¢ncia Explicada:**")
                        for i, var in enumerate(pca.explained_variance_ratio_):
                            st.write(f"Componente {i+1}: {var:.3f} ({var*100:.1f}%)")
                    
                    with col2:
                        st.write("**Componentes Principais:**")
                        st.write("**Componente 1:** CombinaÃ§Ã£o linear de Casos e Letalidade")
                        if componentes.shape[1] > 1:
                            st.write("**Componente 2:** CombinaÃ§Ã£o ortogonal ao Componente 1")
                    
                    # InterpretaÃ§Ã£o detalhada dos componentes
                    st.markdown(f"""
                    ### ğŸ“š **ExplicaÃ§Ã£o Detalhada do PCA:**
                    
                    #### ğŸ¯ **O que Ã© PCA:**
                    - **AnÃ¡lise de Componentes Principais:** TÃ©cnica de reduÃ§Ã£o dimensional
                    - **Objetivo:** Encontrar direÃ§Ãµes de mÃ¡xima variÃ¢ncia nos dados
                    - **Utilidade:** Simplifica dados complexos mantendo a informaÃ§Ã£o principal
                    
                    #### ğŸ“Š **VariÃ¢ncia Explicada Total:** {sum(pca.explained_variance_ratio_)*100:.1f}%
                    - **Componente 1:** {pca.explained_variance_ratio_[0]*100:.1f}% da variÃ¢ncia
                      - Captura a principal diferenÃ§a entre etiologias
                      - Combina casos e letalidade de forma otimizada
                    """)
                    
                    if componentes.shape[1] > 1:
                        st.markdown(f"""
                    - **Componente 2:** {pca.explained_variance_ratio_[1]*100:.1f}% da variÃ¢ncia
                      - Captura variaÃ§Ã£o restante nÃ£o explicada pelo C1
                      - Perpendicular ao Componente 1 (ortogonal)
                      - Revela padrÃµes secundÃ¡rios nos dados
                    
                    #### ğŸ¯ **InterpretaÃ§Ã£o EpidemiolÃ³gica:**
                    - **Quadrante superior direito:** Etiologias graves (muitos casos + alta letalidade)
                    - **Quadrante inferior esquerdo:** Etiologias menos problemÃ¡ticas
                    - **Outros quadrantes:** PadrÃµes especÃ­ficos que merecem investigaÃ§Ã£o
                        """)
                    else:
                        st.markdown("""
                    #### ğŸ¯ **InterpretaÃ§Ã£o do Componente Ãšnico:**
                    - **Valores altos:** Etiologias com maior impacto epidemiolÃ³gico
                    - **Valores baixos:** Etiologias com menor impacto
                    - **OrdenaÃ§Ã£o:** Permite priorizaÃ§Ã£o de recursos de saÃºde
                        """)
                    
                    # Mostrar cargas dos componentes (loadings)
                    st.markdown("#### ğŸ”¢ **Cargas dos Componentes (Loadings):**")
                    loadings_df = pd.DataFrame(
                        pca.components_.T,
                        columns=[f'Componente {i+1}' for i in range(pca.components_.shape[0])],
                        index=['Casos', 'Letalidade']
                    )
                    st.dataframe(loadings_df.round(3))
                    
                    st.markdown("""
                    **ğŸ“‹ Como interpretar as cargas:**
                    - **Valores positivos:** VariÃ¡vel contribui positivamente para o componente
                    - **Valores negativos:** VariÃ¡vel contribui negativamente para o componente
                    - **Magnitude:** Quanto maior o valor absoluto, maior a importÃ¢ncia da variÃ¡vel
                    """)
                    
                    # Mostrar dados tratados
                    st.write("**Dados utilizados no PCA (NaN substituÃ­dos por 0):**")
                    st.dataframe(dados_pca.round(2))
                    
                else:
                    st.warning("âš ï¸ Dados insuficientes para anÃ¡lise PCA apÃ³s tratamento de valores NaN")
                
            except Exception as e:
                st.warning(f"Erro na anÃ¡lise PCA: {e}")
                st.write(f"Detalhes do erro: {str(e)}")
        
        # Matriz de correlaÃ§Ã£o entre etiologias
        st.subheader("ğŸ”— **Matriz de CorrelaÃ§Ã£o entre Etiologias**")
        
        if 'Ano' in etiologia.columns and 'Casos' in etiologia.columns:
            try:
                # Preparar dados para correlaÃ§Ã£o - tratar valores NaN
                etiologia_analise = etiologia.copy()
                etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
                
                dados_correlacao = etiologia_analise.pivot_table(
                    index='Ano',
                    columns='Etiologia',
                    values='Casos',
                    aggfunc='sum'
                ).fillna(0)
                
                if len(dados_correlacao.columns) > 1 and dados_correlacao.shape[0] > 1:
                    # Calcular correlaÃ§Ã£o
                    matriz_corr = dados_correlacao.corr()
                    
                    # Substituir valores NaN na correlaÃ§Ã£o por 0
                    matriz_corr = matriz_corr.fillna(0)
                    
                    # GrÃ¡fico de heatmap
                    fig_heatmap = px.imshow(
                        matriz_corr,
                        title="Matriz de CorrelaÃ§Ã£o entre Etiologias",
                        color_continuous_scale='RdBu',
                        aspect='auto'
                    )
                    
                    fig_heatmap.update_layout(template='plotly_white')
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                    
                    # ExplicaÃ§Ã£o do heatmap de correlaÃ§Ã£o
                    st.markdown("""
                    #### ğŸ“– **InterpretaÃ§Ã£o do Heatmap de CorrelaÃ§Ã£o:**
                    - **Cores:** Intensidade da correlaÃ§Ã£o entre etiologias ao longo do tempo
                    - **Azul escuro:** CorrelaÃ§Ã£o positiva forte (etiologias variam juntas)
                    - **Vermelho escuro:** CorrelaÃ§Ã£o negativa forte (etiologias variam inversamente)
                    - **Branco/Neutro:** Sem correlaÃ§Ã£o (etiologias independentes)
                    - **Diagonal:** Sempre 1.0 (correlaÃ§Ã£o de cada etiologia consigo mesma)
                    - **Utilidade:** Identifica etiologias com padrÃµes temporais similares ou opostos
                    """)
                    
                    # Tabela de correlaÃ§Ãµes
                    st.write("**Valores de CorrelaÃ§Ã£o:**")
                    st.dataframe(matriz_corr.round(3))
                    
                    # EstatÃ­sticas da correlaÃ§Ã£o
                    st.write(f"**Total de etiologias na correlaÃ§Ã£o:** {len(matriz_corr.columns)}")
                    st.write(f"**PerÃ­odo analisado:** {dados_correlacao.index.min()} - {dados_correlacao.index.max()}")
                else:
                    st.warning("âš ï¸ Dados insuficientes para anÃ¡lise de correlaÃ§Ã£o (mÃ­nimo 2 etiologias e 2 anos)")
            except Exception as e:
                st.warning(f"Erro na anÃ¡lise de correlaÃ§Ã£o: {e}")
        else:
            st.warning("âš ï¸ Colunas 'Ano' e/ou 'Casos' nÃ£o encontradas para anÃ¡lise de correlaÃ§Ã£o")
        

        # AnÃ¡lise de sazonalidade
        st.subheader("ğŸŒ¡ï¸ **AnÃ¡lise de Sazonalidade**")
        
        if 'Mes' in etiologia.columns and 'Casos' in etiologia.columns:
            try:
                # Preparar dados sazonais - tratar valores NaN
                etiologia_analise = etiologia.copy()
                etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
                
                dados_sazonais = etiologia_analise.groupby(['Mes', 'Etiologia'])['Casos'].sum().reset_index()
                
                # Filtrar apenas etiologias com pelo menos um caso
                etiologias_com_casos = dados_sazonais.groupby('Etiologia')['Casos'].sum()
                etiologias_com_casos = etiologias_com_casos[etiologias_com_casos > 0].index
                dados_sazonais = dados_sazonais[dados_sazonais['Etiologia'].isin(etiologias_com_casos)]
                
                if len(dados_sazonais) > 0:
                    # GrÃ¡fico de barras agrupadas
                    fig_sazonal = px.bar(
                        dados_sazonais,
                        x='Mes',
                        y='Casos',
                        color='Etiologia',
                        title="Sazonalidade dos Casos por Etiologia",
                        barmode='group'
                    )
                    
                    fig_sazonal.update_layout(
                        xaxis_title="MÃªs",
                        yaxis_title="NÃºmero de Casos",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_sazonal, use_container_width=True)
                    
                    # DecomposiÃ§Ã£o sazonal para uma etiologia especÃ­fica
                    if len(dados_sazonais) > 12:
                        st.write("**DecomposiÃ§Ã£o Sazonal (Primeira Etiologia):**")
                        
                        primeira_etiologia = dados_sazonais['Etiologia'].iloc[0]
                        dados_etiologia = dados_sazonais[dados_sazonais['Etiologia'] == primeira_etiologia]
                        
                        if len(dados_etiologia) >= 12:
                            # DecomposiÃ§Ã£o sazonal
                            decomposicao = seasonal_decompose(
                                dados_etiologia['Casos'].values,
                                period=12,
                                extrapolate_trend='freq'
                            )
                            
                            # GrÃ¡fico de decomposiÃ§Ã£o
                            fig_decomp = make_subplots(
                                rows=4, cols=1,
                                subplot_titles=['Original', 'TendÃªncia', 'Sazonal', 'ResÃ­duos'],
                                vertical_spacing=0.1
                            )
                            
                            fig_decomp.add_trace(
                                go.Scatter(y=dados_etiologia['Casos'], name='Original'),
                                row=1, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.trend, name='TendÃªncia'),
                                row=2, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.seasonal, name='Sazonal'),
                                row=3, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.resid, name='ResÃ­duos'),
                                row=4, col=1
                            )
                            
                            fig_decomp.update_layout(
                                title=f"DecomposiÃ§Ã£o Sazonal - {primeira_etiologia}",
                                height=600,
                                template='plotly_white'
                            )
                            
                            st.plotly_chart(fig_decomp, use_container_width=True)
                        else:
                            st.warning("âš ï¸ Dados insuficientes para decomposiÃ§Ã£o sazonal (mÃ­nimo 12 meses)")
                    else:
                        st.warning("âš ï¸ Dados insuficientes para anÃ¡lise sazonal (mÃ­nimo 12 meses)")
                else:
                    st.warning("âš ï¸ Nenhum dado sazonal vÃ¡lido encontrado")
                    
            except Exception as e:
                st.warning(f"Erro na anÃ¡lise sazonal: {e}")
        else:
            # Fallback: usar SIH mensal quando nÃ£o houver 'Mes' em dados de etiologia
            if 'sih_meningite' in dados and isinstance(dados['sih_meningite'], pd.DataFrame):
                sih = dados['sih_meningite'].copy()
                if {'MÃªs_Num', 'Casos_Hospitalares'}.issubset(sih.columns):
                    sih['Casos_Hospitalares'] = pd.to_numeric(sih['Casos_Hospitalares'], errors='coerce').fillna(0)
                    mensal = sih.groupby('MÃªs_Num', as_index=False)['Casos_Hospitalares'].sum()
                    nomes_meses = {1:'Jan',2:'Fev',3:'Mar',4:'Abr',5:'Mai',6:'Jun',7:'Jul',8:'Ago',9:'Set',10:'Out',11:'Nov',12:'Dez'}
                    mensal['Mes'] = mensal['MÃªs_Num'].map(nomes_meses)
                    fig_sazonal = px.bar(
                        mensal.sort_values('MÃªs_Num'), x='Mes', y='Casos_Hospitalares',
                        title='Sazonalidade (HospitalizaÃ§Ãµes SIH - proxy)', color='Casos_Hospitalares',
                        color_continuous_scale='Reds'
                    )
                    fig_sazonal.update_layout(template='plotly_white', xaxis_title='MÃªs', yaxis_title='Casos Hospitalares')
                    st.plotly_chart(fig_sazonal, use_container_width=True)
                else:
                    st.warning("âš ï¸ Colunas esperadas em SIH para sazonalidade nÃ£o encontradas (MÃªs_Num, Casos_Hospitalares)")
            else:
                st.warning("âš ï¸ Colunas 'Mes' e/ou 'Casos' nÃ£o encontradas para anÃ¡lise sazonal")
        
        # Resumo das anÃ¡lises
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Resumo das AnÃ¡lises de Etiologia:**
        
        **1. AnÃ¡lise Descritiva:**
        - DistribuiÃ§Ã£o de casos por etiologia
        - PadrÃµes de letalidade
        - ComparaÃ§Ã£o entre diferentes agentes causadores
        
        **2. AnÃ¡lise de Componentes Principais:**
        - ReduÃ§Ã£o de dimensionalidade
        - IdentificaÃ§Ã£o de padrÃµes ocultos
        - Agrupamento de etiologias similares
        
        **3. AnÃ¡lise de CorrelaÃ§Ã£o:**
        - RelaÃ§Ãµes entre diferentes etiologias
        - PadrÃµes de co-ocorrÃªncia
        - IdentificaÃ§Ã£o de surtos simultÃ¢neos
        
        **4. AnÃ¡lise Temporal:**
        - EvoluÃ§Ã£o das etiologias ao longo do tempo
        - PadrÃµes sazonais
        - TendÃªncias de longo prazo
        """)
        
    else:
        st.error("âŒ Dados de etiologia nÃ£o disponÃ­veis")

def show_imunizacao_analysis(dados):
    """Exibe a seÃ§Ã£o "Dados de ImunizaÃ§Ã£o e AnÃ¡lise de Impacto".

    Renderiza uma anÃ¡lise completa sobre a vacinaÃ§Ã£o contra meningite. A funÃ§Ã£o
    apresenta a evoluÃ§Ã£o da cobertura vacinal, a correlaÃ§Ã£o entre vacinaÃ§Ã£o e
    o nÃºmero de casos, a distribuiÃ§Ã£o regional da cobertura, e uma anÃ¡lise
    preditiva usando o modelo ARIMA para prever tendÃªncias futuras de
    doses aplicadas e casos.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves 'imunizacao_ano',
                      'imunizacao_uf', 'imunizacao_2023_2025', 'imunizacao_processada',
                      e 'casos_consolidados'.
    """
    st.header("ğŸ’‰ **Dados de ImunizaÃ§Ã£o e AnÃ¡lise de Impacto**")
    st.markdown("---")
    
    # Carregar dados de imunizaÃ§Ã£o
    imunizacao_ano = dados.get('imunizacao_ano')
    imunizacao_uf = dados.get('imunizacao_uf')
    imunizacao_2023_2025 = dados.get('imunizacao_2023_2025')
    
    if (dados.get('imunizacao_processada') is not None and not dados['imunizacao_processada'].empty) or (imunizacao_ano is not None and not imunizacao_ano.empty):
        # MÃ©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        if dados.get('imunizacao_processada') is not None and not dados['imunizacao_processada'].empty:
            proc = dados['imunizacao_processada']
            with col1:
                total_doses = int(proc['Total_Nacional'].sum()) if 'Total_Nacional' in proc.columns else 0
                st.metric("ğŸ’‰ Total de Doses", f"{total_doses:,}")
            with col2:
                # Cobertura mÃ©dia pode nÃ£o existir; usar proxy: mÃ©dia anual normalizada por 1e6 para legibilidade
                if 'Total_Nacional' in proc.columns:
                    cobertura_media_proxy = proc.groupby('Ano')['Total_Nacional'].sum().mean() / 1_000_000
                    st.metric("ğŸ“Š MÃ©dia Anual de Doses (mi)", f"{cobertura_media_proxy:.2f}")
                else:
                    st.metric("ğŸ“Š MÃ©dia Anual de Doses (mi)", "N/A")
            with col3:
                n_anos = proc['Ano'].nunique() if 'Ano' in proc.columns else 0
                st.metric("ğŸ“… Anos de Dados", n_anos)
        else:
            with col1:
                total_doses = imunizacao_ano['Doses'].sum() if 'Doses' in imunizacao_ano.columns else 0
                st.metric("ğŸ’‰ Total de Doses", f"{total_doses:,}")
            with col2:
                total_cobertura = imunizacao_ano['Cobertura'].mean() if 'Cobertura' in imunizacao_ano.columns else 0
                st.metric("ğŸ“Š Cobertura MÃ©dia", f"{total_cobertura:.1f}%")
            with col3:
                n_anos = imunizacao_ano['Ano'].nunique() if 'Ano' in imunizacao_ano.columns else 0
                st.metric("ğŸ“… Anos de Dados", n_anos)
        
        with col4:
            n_ufs = imunizacao_uf['UF'].nunique() if imunizacao_uf is not None and not imunizacao_uf.empty else 0
            st.metric("ğŸ—ºï¸ UFs Cobertas", n_ufs)
        
        # AnÃ¡lise de impacto da vacinaÃ§Ã£o
        st.subheader("ğŸ“Š **AnÃ¡lise de Impacto da VacinaÃ§Ã£o**")
        
        # Preferir base processada se existir
        if dados.get('imunizacao_processada') is not None:
            base_ano = dados['imunizacao_processada'][['Ano', 'Total_Nacional']].dropna()
            base_ano = base_ano.groupby('Ano', as_index=False)['Total_Nacional'].sum()
            base_ano.rename(columns={'Total_Nacional': 'Cobertura'}, inplace=True)
        else:
            base_ano = imunizacao_ano if ('Ano' in imunizacao_ano.columns and 'Cobertura' in imunizacao_ano.columns) else None

        if base_ano is not None and 'Ano' in base_ano.columns and 'Cobertura' in base_ano.columns:
            # Limpar anos invÃ¡lidos
            base_ano['Ano'] = pd.to_numeric(base_ano['Ano'], errors='coerce')
            base_ano = base_ano.dropna(subset=['Ano'])
            base_ano = base_ano[(base_ano['Ano'] >= 1900) & (base_ano['Ano'] <= 2100)]
            base_ano['Ano'] = base_ano['Ano'].astype(int)
            # Preparar dados para anÃ¡lise de impacto
            dados_impacto = base_ano.groupby('Ano').agg({
                'Cobertura': 'mean',
                **({'Doses': 'sum'} if ('Doses' in imunizacao_ano.columns) else {})
            }).reset_index()
            
            # GrÃ¡fico de evoluÃ§Ã£o
            fig_cobertura = px.line(dados_impacto.assign(AnoDT=pd.to_datetime(dados_impacto['Ano'].astype(int), format='%Y', errors='coerce').dropna()), x='AnoDT', y='Cobertura',
                                    title=("EvoluÃ§Ã£o do Total de Doses Aplicadas" if dados.get('imunizacao_processada') is not None else "EvoluÃ§Ã£o da Cobertura Vacinal ao Longo do Tempo"),
                                    markers=True)
            
            fig_cobertura.update_layout(xaxis_title="Ano", yaxis_title=("Total de Doses" if dados.get('imunizacao_processada') is not None else "Cobertura Vacinal (%)"), template='plotly_white')
            fig_cobertura.update_xaxes(tickformat='%Y')
            st.plotly_chart(fig_cobertura, use_container_width=True)
            
            # ExplicaÃ§Ã£o do grÃ¡fico de evoluÃ§Ã£o da cobertura vacinal
            st.markdown("""
            #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de EvoluÃ§Ã£o da Cobertura Vacinal:**
            - **Eixo X (Horizontal):** Anos do perÃ­odo analisado
            - **Eixo Y (Vertical):** Cobertura vacinal (%) ou nÃºmero total de doses aplicadas
            - **Linha com marcadores:** EvoluÃ§Ã£o temporal da vacinaÃ§Ã£o contra meningite
            - **TendÃªncia crescente:** Melhoria na cobertura vacinal ao longo do tempo
            - **TendÃªncia decrescente:** PossÃ­vel reduÃ§Ã£o na adesÃ£o ou mudanÃ§as nas polÃ­ticas
            - **VariaÃ§Ãµes abruptas:** Podem indicar mudanÃ§as em campanhas, disponibilidade de vacinas ou eventos especÃ­ficos
            - **ImportÃ¢ncia epidemiolÃ³gica:** Cobertura alta (>95%) Ã© essencial para imunidade coletiva
            - **Meta de saÃºde pÃºblica:** Monitoramento da eficÃ¡cia das campanhas de vacinaÃ§Ã£o
            """)
            
            # AnÃ¡lise de correlaÃ§Ã£o com casos de meningite
            if 'casos_consolidados' in dados and dados['casos_consolidados'] is not None:
                st.write("**ğŸ”— CorrelaÃ§Ã£o entre Cobertura Vacinal e Casos de Meningite:**")
                
                casos_por_ano = dados['casos_consolidados'].groupby('Ano')['Casos_Notificados'].sum().reset_index()
                # Renomear para 'Casos' para compatibilidade com a anÃ¡lise
                casos_por_ano = casos_por_ano.rename(columns={'Casos_Notificados': 'Casos'})
                
                # Mesclar dados
                dados_correlacao = dados_impacto.merge(casos_por_ano, on='Ano', how='inner')
                
                if len(dados_correlacao) > 2:
                    # Calcular correlaÃ§Ã£o
                    corr_cobertura_casos, p_valor = stats.pearsonr(
                        dados_correlacao['Cobertura'],
                        dados_correlacao['Casos']
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("ğŸ“ˆ CorrelaÃ§Ã£o", f"{corr_cobertura_casos:.3f}")
                        st.write(f"P-valor: {p_valor:.4f}")
                    
                    with col2:
                        if p_valor < 0.05:
                            if corr_cobertura_casos < 0:
                                st.success("âœ… CorrelaÃ§Ã£o significativa negativa")
                                st.write("Maior cobertura = Menos casos")
                            else:
                                st.warning("âš ï¸ CorrelaÃ§Ã£o significativa positiva")
                                st.write("Maior cobertura = Mais casos")
                        else:
                            st.info("â„¹ï¸ Sem correlaÃ§Ã£o significativa")
                    
                    # GrÃ¡fico de dispersÃ£o
                    fig_dispersao = px.scatter(
                        dados_correlacao,
                        x='Cobertura',
                        y='Casos',
                        title="RelaÃ§Ã£o entre Cobertura Vacinal e Casos de Meningite",
                        text='Ano',
                        size='Cobertura'
                    )
                    
                    fig_dispersao.update_layout(
                        xaxis_title="Cobertura Vacinal (%)",
                        yaxis_title="NÃºmero de Casos",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_dispersao, use_container_width=True)
                    
                    # ExplicaÃ§Ã£o da anÃ¡lise de correlaÃ§Ã£o
                    st.markdown(f"""
                    #### ğŸ“š **ExplicaÃ§Ã£o da AnÃ¡lise de CorrelaÃ§Ã£o Cobertura vs Casos:**
                    
                    ##### ğŸ“Š **CorrelaÃ§Ã£o de Pearson = {corr_cobertura_casos:.3f}**
                    - **O que mede:** ForÃ§a da relaÃ§Ã£o linear entre cobertura vacinal e casos de meningite
                    - **InterpretaÃ§Ã£o esperada:** CorrelaÃ§Ã£o negativa (mais vacinaÃ§Ã£o = menos casos)
                    - **Resultado atual:** {"CorrelaÃ§Ã£o negativa - conforme esperado!" if corr_cobertura_casos < 0 else "CorrelaÃ§Ã£o positiva - necessita investigaÃ§Ã£o!" if corr_cobertura_casos > 0 else "Sem correlaÃ§Ã£o clara"}
                    
                    ##### ğŸ¯ **SignificÃ¢ncia EstatÃ­stica (p = {p_valor:.4f})**
                    - **p < 0.05:** RelaÃ§Ã£o estatisticamente significativa
                    - **p â‰¥ 0.05:** RelaÃ§Ã£o pode ser devida ao acaso
                    - **Resultado:** {"RelaÃ§Ã£o significativa e confiÃ¡vel" if p_valor < 0.05 else "RelaÃ§Ã£o nÃ£o significativa"}
                    
                    ##### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de DispersÃ£o:**
                    - **Eixo X:** Cobertura vacinal (% ou doses)
                    - **Eixo Y:** NÃºmero de casos de meningite
                    - **Pontos:** Cada ponto representa um ano especÃ­fico
                    - **Tamanho dos pontos:** Proporcional Ã  cobertura vacinal
                    - **PadrÃ£o ideal:** Pontos formando linha descendente (mais vacinaÃ§Ã£o = menos casos)
                    
                    ##### âš ï¸ **ConsideraÃ§Ãµes Importantes:**
                    - **Defasagem temporal:** Efeito da vacinaÃ§Ã£o pode aparecer com atraso
                    - **Fatores confundidores:** Outros fatores podem influenciar a incidÃªncia
                    - **Imunidade coletiva:** Efeito mais pronunciado com cobertura >95%
                    - **Tipos de meningite:** Nem todas sÃ£o prevenÃ­veis por vacina
                    """)
        
        # AnÃ¡lise regional da cobertura
        st.subheader("ğŸ—ºï¸ **AnÃ¡lise Regional da Cobertura**")
        
        if dados.get('imunizacao_processada') is not None:
            # Derivar cobertura por UF a partir do dataset processado se possÃ­vel (soma no perÃ­odo)
            proc = dados['imunizacao_processada']
            uf_cols = [c for c in proc.columns if c not in ['Ano', 'Ignorado', 'Total', 'Total_Nacional', 'Casos_Notificados']]
            if uf_cols:
                cobertura_por_uf = proc[uf_cols].sum().sort_values(ascending=False)
                fig_regional = px.bar(
                    x=[c.split(' ', 1)[1] if ' ' in c else c for c in cobertura_por_uf.index],
                    y=cobertura_por_uf.values,
                    title="Cobertura/AplicaÃ§Ã£o por UF (soma no perÃ­odo)",
                    color=cobertura_por_uf.values,
                    color_continuous_scale='Greens'
                )
                fig_regional.update_layout(
                    xaxis_title="Unidade Federativa",
                    yaxis_title="Total de Doses",
                    template='plotly_white'
                )
                st.plotly_chart(fig_regional, use_container_width=True)
        elif imunizacao_uf is not None and not imunizacao_uf.empty:
            # Preparar dados regionais
            if 'Cobertura' in imunizacao_uf.columns:
                cobertura_por_uf = imunizacao_uf.groupby('UF')['Cobertura'].mean().sort_values(ascending=False)
                
                fig_regional = px.bar(
                    x=cobertura_por_uf.index,
                    y=cobertura_por_uf.values,
                    title="Cobertura Vacinal por UF",
                    color=cobertura_por_uf.values,
                    color_continuous_scale='Greens'
                )
                
                fig_regional.update_layout(
                    xaxis_title="Unidade Federativa",
                    yaxis_title="Cobertura Vacinal MÃ©dia (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_regional, use_container_width=True)
                
                # AnÃ¡lise de desigualdades regionais
                st.write("**ğŸ“Š AnÃ¡lise de Desigualdades Regionais:**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    cobertura_media = cobertura_por_uf.mean()
                    cobertura_std = cobertura_por_uf.std()
                    st.metric("ğŸ“Š Cobertura MÃ©dia", f"{cobertura_media:.1f}%")
                    st.metric("ğŸ“ˆ Desvio PadrÃ£o", f"{cobertura_std:.1f}%")
                
                with col2:
                    cobertura_min = cobertura_por_uf.min()
                    cobertura_max = cobertura_por_uf.max()
                    st.metric("ğŸ“‰ Cobertura MÃ­nima", f"{cobertura_min:.1f}%")
                    st.metric("ğŸ“ˆ Cobertura MÃ¡xima", f"{cobertura_max:.1f}%")
                
                # Coeficiente de variaÃ§Ã£o
                cv = (cobertura_std / cobertura_media) * 100
                st.write(f"**ğŸ“Š Coeficiente de VariaÃ§Ã£o:** {cv:.1f}%")
                
                if cv > 20:
                    st.warning("âš ï¸ Alta desigualdade regional na cobertura vacinal")
                elif cv > 10:
                    st.info("â„¹ï¸ Desigualdade moderada na cobertura vacinal")
                else:
                    st.success("âœ… Baixa desigualdade regional na cobertura vacinal")
        
        # AnÃ¡lise temporal avanÃ§ada
        st.subheader("ğŸ“ˆ **AnÃ¡lise Temporal AvanÃ§ada**")
        
        if dados.get('imunizacao_processada') is not None:
            # Usar a sÃ©rie anual de Total_Nacional para tendÃªncia
            serie_anual = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum()
            serie_anual['Ano'] = pd.to_numeric(serie_anual['Ano'], errors='coerce')
            serie_anual = serie_anual.dropna(subset=['Ano'])
            serie_anual = serie_anual[(serie_anual['Ano'] >= 1900) & (serie_anual['Ano'] <= 2100)]
            fig_tendencia = go.Figure()
            fig_tendencia.add_trace(go.Scatter(
                x=pd.to_datetime(serie_anual['Ano'].astype(int), format='%Y', errors='coerce'),
                y=serie_anual['Total_Nacional'],
                mode='markers+lines', name='Total de Doses', marker=dict(size=8)
            ))
            fig_tendencia.update_layout(title="TendÃªncia de AplicaÃ§Ãµes (Total Nacional)", xaxis_title="Ano", yaxis_title="Total de Doses", template='plotly_white')
            fig_tendencia.update_xaxes(tickformat='%Y')
            st.plotly_chart(fig_tendencia, use_container_width=True)
        elif imunizacao_2023_2025 is not None and not imunizacao_2023_2025.empty:
            # Preparar dados temporais
            if 'Ano' in imunizacao_2023_2025.columns:
                dados_temporais = imunizacao_2023_2025.groupby('Ano').agg({
                    'Cobertura': 'mean' if 'Cobertura' in imunizacao_2023_2025.columns else 'count',
                    'Doses': 'sum' if 'Doses' in imunizacao_2023_2025.columns else 'count'
                }).reset_index()
                
                # GrÃ¡fico de tendÃªncia
                fig_tendencia = go.Figure()
                
                fig_tendencia.add_trace(go.Scatter(
                    x=dados_temporais['Ano'],
                    y=dados_temporais['Cobertura'] if 'Cobertura' in dados_temporais.columns else dados_temporais['Doses'],
                    mode='markers+lines',
                    name='Cobertura/Doses',
                    marker=dict(size=8)
                ))
                
                fig_tendencia.update_layout(
                    title="TendÃªncia da Cobertura Vacinal (2023-2025)",
                    xaxis_title="Ano",
                    yaxis_title="Cobertura (%) / Doses",
                    template='plotly_white'
                )
                
                fig_tendencia.update_xaxes(tickformat='d')
                st.plotly_chart(fig_tendencia, use_container_width=True)
                
                # AnÃ¡lise de eficÃ¡cia
                if len(dados_temporais) > 1:
                    st.write("**ğŸ“Š AnÃ¡lise de EficÃ¡cia:**")
                    
                    # Calcular mudanÃ§a percentual
                    if 'Cobertura' in dados_temporais.columns:
                        cobertura_inicial = dados_temporais['Cobertura'].iloc[0]
                        cobertura_final = dados_temporais['Cobertura'].iloc[-1]
                        mudanca_percentual = ((cobertura_final - cobertura_inicial) / cobertura_inicial) * 100
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("ğŸ“Š Cobertura Inicial", f"{cobertura_inicial:.1f}%")
                            st.metric("ğŸ“Š Cobertura Final", f"{cobertura_final:.1f}%")
                        
                        with col2:
                            st.metric("ğŸ“ˆ MudanÃ§a", f"{mudanca_percentual:+.1f}%")
                            
                            if mudanca_percentual > 0:
                                st.success("âœ… Melhoria na cobertura")
                            elif mudanca_percentual < 0:
                                st.warning("âš ï¸ ReduÃ§Ã£o na cobertura")
                            else:
                                st.info("â„¹ï¸ Cobertura estÃ¡vel")
        
        # AnÃ¡lise preditiva com ARIMA
        st.subheader("ğŸ”® **AnÃ¡lise Preditiva (ARIMA)**")
        
        # Construir sÃ©rie para ARIMA (doses)
        dados_arima = None
        if dados.get('imunizacao_processada') is not None:
            dados_arima = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum().rename(columns={'Total_Nacional': 'Valor'})
        elif imunizacao_ano is not None and {'Ano','Cobertura'}.issubset(imunizacao_ano.columns):
            dados_arima = imunizacao_ano.groupby('Ano', as_index=False)['Cobertura'].mean().rename(columns={'Cobertura':'Valor'})

        if dados_arima is not None and len(dados_arima) > 3:
            try:
                serie = dados_arima.copy()
                serie['Ano'] = pd.to_numeric(serie['Ano'], errors='coerce')
                serie = serie.dropna(subset=['Ano'])
                serie = serie[(serie['Ano'] >= 1900) & (serie['Ano'] <= 2100)]
                serie['Ano'] = pd.to_datetime(serie['Ano'].astype(int), format='%Y', errors='coerce')
                serie = serie.set_index('Ano')
                if not STATSMODELS_AVAILABLE:
                    st.warning("âš ï¸ AnÃ¡lise ARIMA nÃ£o disponÃ­vel: statsmodels nÃ£o instalado corretamente")
                else:
                    modelo_arima = ARIMA(serie['Valor'], order=(1, 1, 1)).fit()
                    previsao = modelo_arima.forecast(steps=3)
                    anos_futuros = pd.date_range(start=serie.index[-1] + pd.DateOffset(years=1), periods=3, freq='Y')

                    fig_previsao = go.Figure()
                    fig_previsao.add_trace(go.Scatter(x=serie.index, y=serie['Valor'], mode='markers+lines', name='Observado'))
                    fig_previsao.add_trace(go.Scatter(x=anos_futuros, y=previsao, mode='markers+lines', name='PrevisÃ£o', line=dict(dash='dash', color='red')))
                    fig_previsao.update_layout(title='PrevisÃ£o de Doses (ARIMA)', xaxis_title='Ano', yaxis_title='Total de Doses', template='plotly_white')
                    st.plotly_chart(fig_previsao, use_container_width=True)

            except Exception as e:
                st.warning(f"Erro na previsÃ£o ARIMA (doses): {e}")

        # ARIMA para nÃºmero de casos (quando disponÃ­vel)
        if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
            casos_series = dados['casos_consolidados'].groupby('Ano', as_index=False)['Casos_Notificados'].sum()
            if len(casos_series) > 3:
                try:
                    cs = casos_series.copy()
                    cs['Ano'] = pd.to_numeric(cs['Ano'], errors='coerce')
                    cs = cs.dropna(subset=['Ano'])
                    cs = cs[(cs['Ano'] >= 1900) & (cs['Ano'] <= 2100)]
                    cs['Ano'] = pd.to_datetime(cs['Ano'].astype(int), format='%Y', errors='coerce')
                    cs = cs.set_index('Ano')
                    if STATSMODELS_AVAILABLE:
                        model_cases = ARIMA(cs['Casos_Notificados'], order=(1, 1, 1)).fit()
                    else:
                        st.warning("âš ï¸ AnÃ¡lise ARIMA nÃ£o disponÃ­vel: statsmodels nÃ£o instalado corretamente")
                        return
                    fc_cases = model_cases.forecast(steps=3)
                    anos_fut = pd.date_range(start=cs.index[-1] + pd.DateOffset(years=1), periods=3, freq='Y')

                    fig_cases = go.Figure()
                    fig_cases.add_trace(go.Scatter(x=cs.index, y=cs['Casos_Notificados'], mode='markers+lines', name='Casos Observados'))
                    fig_cases.add_trace(go.Scatter(x=anos_fut, y=fc_cases, mode='markers+lines', name='PrevisÃ£o de Casos', line=dict(dash='dash', color='orange')))
                    fig_cases.update_layout(title='PrevisÃ£o de Casos (ARIMA)', xaxis_title='Ano', yaxis_title='Casos', template='plotly_white')
                    st.plotly_chart(fig_cases, use_container_width=True)
                except Exception as e:
                    st.warning(f"Erro na previsÃ£o ARIMA (casos): {e}")
        
        # Resumo das anÃ¡lises
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Resumo das AnÃ¡lises de ImunizaÃ§Ã£o:**
        
        **1. AnÃ¡lise de Impacto:**
        - CorrelaÃ§Ã£o entre cobertura vacinal e casos de meningite
        - Efetividade das campanhas de vacinaÃ§Ã£o
        - RelaÃ§Ã£o dose-resposta
        
        **2. AnÃ¡lise Regional:**
        - Desigualdades na cobertura entre UFs
        - IdentificaÃ§Ã£o de regiÃµes prioritÃ¡rias
        - PadrÃµes geogrÃ¡ficos de imunizaÃ§Ã£o
        
        **3. AnÃ¡lise Temporal:**
        - EvoluÃ§Ã£o da cobertura ao longo do tempo
        - TendÃªncias e sazonalidade
        - EficÃ¡cia das intervenÃ§Ãµes
        
        **4. AnÃ¡lise Preditiva:**
        - Modelagem ARIMA para previsÃµes
        - Planejamento de campanhas futuras
        - AvaliaÃ§Ã£o de metas de cobertura
        """)
        
    else:
        st.error("âŒ Dados de imunizaÃ§Ã£o nÃ£o disponÃ­veis")

def show_advanced_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lises AvanÃ§adas e Machine Learning".

    Esta funÃ§Ã£o apresenta anÃ¡lises estatÃ­sticas e de machine learning mais complexas.
    Inclui uma decomposiÃ§Ã£o de sÃ©rie temporal avanÃ§ada (STL), teste de estacionariedade (ADF),
    anÃ¡lise de correlaÃ§Ã£o cruzada entre sorogrupos, um modelo de regressÃ£o mÃºltipla
    para identificar fatores preditivos de casos, e clustering hierÃ¡rquico para
    agrupamento de sorogrupos.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves 'casos_consolidados',
                      'sorogrupos_consolidados', 'etiologias_consolidadas', e
                      'imunizacao_processada'.
    """
    st.header("ğŸ”¬ **AnÃ¡lises AvanÃ§adas e Machine Learning**")
    st.markdown("---")
    
    # Carregar dados
    casos = dados['casos_consolidados']
    sorogrupos = dados['sorogrupos_consolidados']
    etiologia = dados['etiologias_consolidadas']
    
    if casos is not None and not casos.empty:
        # AnÃ¡lise de sÃ©ries temporais avanÃ§ada
        st.subheader("ğŸ“ˆ **AnÃ¡lise de SÃ©ries Temporais AvanÃ§ada**")
        
        # Preparar dados temporais
        dados_tempo = casos.groupby('Ano')['Casos_Notificados'].sum().reset_index()
        dados_tempo['Ano'] = pd.to_datetime(dados_tempo['Ano'], format='%Y')
        dados_tempo = dados_tempo.set_index('Ano')
        
        if len(dados_tempo) > 3:
            # DecomposiÃ§Ã£o sazonal avanÃ§ada
            try:
                # DecomposiÃ§Ã£o STL (mais robusta)
                if not STATSMODELS_AVAILABLE:
                    st.warning("âš ï¸ AnÃ¡lise STL nÃ£o disponÃ­vel: statsmodels nÃ£o instalado corretamente")
                else:
                    from statsmodels.tsa.seasonal import STL
                    
                    stl = STL(dados_tempo['Casos_Notificados'], period=min(3, len(dados_tempo)//2))
                    resultado_stl = stl.fit()
                    
                    # GrÃ¡fico de decomposiÃ§Ã£o STL
                    fig_stl = make_subplots(
                        rows=4, cols=1,
                        subplot_titles=['Original', 'TendÃªncia', 'Sazonal', 'ResÃ­duos'],
                        vertical_spacing=0.1
                    )
                    
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=dados_tempo['Casos_Notificados'], name='Original'), row=1, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.trend, name='TendÃªncia'), row=2, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.seasonal, name='Sazonal'), row=3, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.resid, name='ResÃ­duos'), row=4, col=1)
                    
                    fig_stl.update_layout(
                        title="DecomposiÃ§Ã£o STL AvanÃ§ada",
                        height=600,
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_stl, use_container_width=True)
                    
                    # ExplicaÃ§Ã£o detalhada da decomposiÃ§Ã£o STL
                    st.markdown("""
                    #### ğŸ“š **ExplicaÃ§Ã£o da DecomposiÃ§Ã£o STL (Seasonal and Trend decomposition using Loess):**
                    
                    ##### ğŸ¯ **O que Ã© a decomposiÃ§Ã£o STL:**
                    - **TÃ©cnica estatÃ­stica avanÃ§ada** que separa uma sÃ©rie temporal em componentes
                    - **STL = Seasonal and Trend decomposition using Loess**
                    - **Mais robusta** que mÃ©todos clÃ¡ssicos para dados irregulares
                    - **FlexÃ­vel** para diferentes tipos de sazonalidade
                    
                    ##### ğŸ“Š **Os 4 componentes visualizados:**
                    
                    **1. ğŸ“ˆ SÃ©rie Original (1Âº grÃ¡fico):**
                    - Dados brutos de casos de meningite ao longo do tempo
                    - Mostra a sÃ©rie completa sem decomposiÃ§Ã£o
                    
                    **2. ğŸ“‰ TendÃªncia (2Âº grÃ¡fico):**
                    - **DireÃ§Ã£o geral** da sÃ©rie ao longo do tempo
                    - Remove flutuaÃ§Ãµes de curto prazo
                    - **Crescente:** Aumento sustentado de casos
                    - **Decrescente:** ReduÃ§Ã£o sustentada de casos
                    - **EstÃ¡vel:** Sem mudanÃ§a direcional clara
                    
                    **3. ğŸ”„ Componente Sazonal (3Âº grÃ¡fico):**
                    - **PadrÃµes repetitivos** em perÃ­odos fixos
                    - Mostra variaÃ§Ãµes sistemÃ¡ticas (anuais, mensais)
                    - **Picos regulares:** Ã‰pocas de maior incidÃªncia
                    - **Vales regulares:** Ã‰pocas de menor incidÃªncia
                    
                    **4. ğŸ² ResÃ­duos (4Âº grÃ¡fico):**
                    - **VariaÃ§Ãµes aleatÃ³rias** nÃ£o explicadas
                    - DiferenÃ§a entre sÃ©rie real e componentes
                    - **PrÃ³ximo a zero:** Boa decomposiÃ§Ã£o
                    - **PadrÃµes nos resÃ­duos:** Componentes nÃ£o capturados
                    
                    ##### ğŸ”¬ **ImportÃ¢ncia epidemiolÃ³gica:**
                    - **TendÃªncia:** Avalia eficÃ¡cia de polÃ­ticas de longo prazo
                    - **Sazonalidade:** Identifica perÃ­odos de risco para planejamento
                    - **ResÃ­duos:** Detecta eventos atÃ­picos (surtos, mudanÃ§as sÃºbitas)
                    - **PrevisÃ£o:** Base para modelos preditivos
                    """)
                    
                    # AnÃ¡lise de estacionariedade
                    st.markdown("**ğŸ“Š Teste de Estacionariedade (ADF):**")
                    from statsmodels.tsa.stattools import adfuller
                    
                    resultado_adf = adfuller(dados_tempo['Casos_Notificados'])
                    st.write(f"**EstatÃ­stica ADF:** {resultado_adf[0]:.4f}")
                    st.write(f"**P-valor:** {resultado_adf[1]:.4f}")
                    st.write(f"**EstacionÃ¡rio:** {'Sim' if resultado_adf[1] < 0.05 else 'NÃ£o'}")
                    
                    # ExplicaÃ§Ã£o detalhada do teste ADF
                    st.markdown(f"""
                    #### ğŸ“š **ExplicaÃ§Ã£o do Teste ADF (Augmented Dickey-Fuller):**
                    
                    ##### ğŸ¯ **O que Ã© estacionariedade:**
                    - **SÃ©rie estacionÃ¡ria:** Propriedades estatÃ­sticas nÃ£o mudam ao longo do tempo
                    - **MÃ©dia constante:** NÃ£o hÃ¡ tendÃªncia crescente ou decrescente
                    - **VariÃ¢ncia constante:** FlutuaÃ§Ãµes similares em todo perÃ­odo
                    - **AutocorrelaÃ§Ã£o estÃ¡vel:** PadrÃµes de dependÃªncia temporal consistentes
                    
                    ##### ğŸ“Š **Teste ADF - Resultados atuais:**
                    - **EstatÃ­stica ADF:** {resultado_adf[0]:.4f}
                      - Valores mais negativos indicam maior evidÃªncia de estacionariedade
                      - Compara com valores crÃ­ticos (-3.43, -2.86, -2.57)
                    
                    - **P-valor:** {resultado_adf[1]:.4f}
                      - p < 0.05: Rejeita hipÃ³tese nula (sÃ©rie Ã‰ estacionÃ¡ria)
                      - p â‰¥ 0.05: NÃ£o rejeita hipÃ³tese nula (sÃ©rie NÃƒO Ã© estacionÃ¡ria)
                    
                    - **InterpretaÃ§Ã£o:** {"SÃ©rie ESTACIONÃRIA" if resultado_adf[1] < 0.05 else "SÃ©rie NÃƒO-ESTACIONÃRIA"}
                    
                    ##### ğŸ”¬ **ImportÃ¢ncia para anÃ¡lise:**
                    - **SÃ©rie estacionÃ¡ria:** Ideal para modelagem e previsÃ£o
                    - **SÃ©rie nÃ£o-estacionÃ¡ria:** Necessita transformaÃ§Ãµes (diferenciaÃ§Ã£o, log)
                    - **AplicaÃ§Ã£o epidemiolÃ³gica:** Determina se tendÃªncias sÃ£o temporÃ¡rias ou persistentes
                    - **Modelos ARIMA:** Requer estacionariedade para funcionar adequadamente
                    
                    ##### âš ï¸ **ImplicaÃ§Ãµes prÃ¡ticas:**
                    {"- **Dados adequados** para previsÃ£o direta" if resultado_adf[1] < 0.05 else "- **Dados necessitam transformaÃ§Ã£o** antes da modelagem"}
                    {"- **FlutuaÃ§Ãµes em torno de mÃ©dia estÃ¡vel**" if resultado_adf[1] < 0.05 else "- **PresenÃ§a de tendÃªncias ou mudanÃ§as estruturais**"}
                    {"- **Modelos mais simples sÃ£o aplicÃ¡veis**" if resultado_adf[1] < 0.05 else "- **Modelos mais complexos sÃ£o necessÃ¡rios**"}
                    """)
                    
                
            except Exception as e:
                st.warning(f"Erro na decomposiÃ§Ã£o STL: {e}")
        
        # AnÃ¡lise de correlaÃ§Ã£o cruzada
        st.subheader("ğŸ”— **AnÃ¡lise de CorrelaÃ§Ã£o Cruzada**")
        
        if sorogrupos is not None and not sorogrupos.empty:
            # Preparar dados para correlaÃ§Ã£o cruzada
            dados_cruzada = sorogrupos.pivot_table(
                index='Ano', 
                columns='Sorogrupo', 
                values='Casos', 
                aggfunc='sum'
            ).fillna(0)
            
            # Calcular correlaÃ§Ã£o cruzada
            
            st.markdown("**CorrelaÃ§Ãµes Cruzadas entre Sorogrupos:**")
            
            correlacoes_cruzadas = []
            for i, sorogrupo1 in enumerate(dados_cruzada.columns):
                for j, sorogrupo2 in enumerate(dados_cruzada.columns):
                    if i < j:  # Evitar duplicatas
                        corr, p_valor = stats.pearsonr(dados_cruzada[sorogrupo1], dados_cruzada[sorogrupo2])
                        correlacoes_cruzadas.append({
                            'Sorogrupo 1': sorogrupo1,
                            'Sorogrupo 2': sorogrupo2,
                            'CorrelaÃ§Ã£o': corr,
                            'P-valor': p_valor
                        })
            
            if correlacoes_cruzadas:
                df_cruzada = pd.DataFrame(correlacoes_cruzadas)
                df_cruzada = df_cruzada = df_cruzada.sort_values('CorrelaÃ§Ã£o', key=abs, ascending=False)
                
                # GrÃ¡fico de correlaÃ§Ãµes cruzadas
                fig_cruzada = px.bar(
                    df_cruzada,
                    x='Sorogrupo 1',
                    y='CorrelaÃ§Ã£o',
                    color='Sorogrupo 2',
                    title='CorrelaÃ§Ãµes Cruzadas entre Sorogrupos',
                    barmode='group'
                )
                
                fig_cruzada.update_layout(template='plotly_white')
                st.plotly_chart(fig_cruzada, use_container_width=True)
                
                # ExplicaÃ§Ã£o detalhada da correlaÃ§Ã£o cruzada
                st.markdown("""
                #### ğŸ“š **ExplicaÃ§Ã£o da AnÃ¡lise de CorrelaÃ§Ã£o Cruzada:**
                
                ##### ğŸ¯ **O que Ã© correlaÃ§Ã£o cruzada:**
                - **Medida de associaÃ§Ã£o** entre diferentes sorogrupos ao longo do tempo
                - **Identifica padrÃµes sincronizados** ou opostos entre sorogrupos
                - **AnÃ¡lise multivariada** que examina relacionamentos complexos
                
                ##### ğŸ“Š **InterpretaÃ§Ã£o do grÃ¡fico:**
                - **Eixo X:** Primeiro sorogrupo de cada par
                - **Eixo Y:** Valor da correlaÃ§Ã£o (-1 a +1)
                - **Cores:** Segundo sorogrupo do par
                - **Barras positivas:** Sorogrupos variam na mesma direÃ§Ã£o
                - **Barras negativas:** Sorogrupos variam em direÃ§Ãµes opostas
                
                ##### ğŸ”¬ **Significado epidemiolÃ³gico:**
                
                **CorrelaÃ§Ã£o Positiva (+):**
                - Sorogrupos aumentam/diminuem juntos
                - PossÃ­veis fatores comuns (clima, polÃ­ticas, vigilÃ¢ncia)
                - Resposta similar a intervenÃ§Ãµes
                
                **CorrelaÃ§Ã£o Negativa (-):**
                - Um sorogrupo aumenta quando outro diminui
                - PossÃ­vel competiÃ§Ã£o ou substituiÃ§Ã£o
                - DiferenÃ§as na eficÃ¡cia de vacinas especÃ­ficas
                
                **CorrelaÃ§Ã£o prÃ³xima a zero:**
                - Sorogrupos evoluem independentemente
                - Fatores de risco diferentes
                - DinÃ¢micas epidemiolÃ³gicas distintas
                
                ##### ğŸ“ˆ **AplicaÃ§Ãµes prÃ¡ticas:**
                - **Planejamento de vacinas:** Priorizar sorogrupos correlacionados
                - **VigilÃ¢ncia:** Monitorar sorogrupos em conjunto
                - **PrevisÃ£o:** Usar comportamento de um para prever outro
                - **InvestigaÃ§Ã£o:** Identificar fatores de risco comuns
                """)
                
                # Tabela de correlaÃ§Ãµes
                st.markdown("#### ğŸ“‹ **Tabela Detalhada de CorrelaÃ§Ãµes:**")
                st.dataframe(df_cruzada.round(3))
        
        # AnÃ¡lise de regressÃ£o mÃºltipla (revista)
        st.subheader("ğŸ“Š **RegressÃ£o MÃºltipla: Fatores que explicam os Casos**")
        try:
            # Construir base anual integrada: Casos vs Doses (Total_Nacional)
            base_casos = None
            if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
                base_casos = dados['casos_consolidados'].groupby('Ano', as_index=False)['Casos_Notificados'].sum()
            if base_casos is not None and (len(base_casos) >= 5):
                # Doses
                if 'imunizacao_processada' in dados and isinstance(dados['imunizacao_processada'], pd.DataFrame):
                    base_doses = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum()
                else:
                    base_doses = None

                df_int = base_casos.copy()
                if base_doses is not None:
                    df_int = df_int.merge(base_doses, on='Ano', how='left')
                df_int = df_int.sort_values('Ano')
                # Features de defasagem
                df_int['Casos_Lag1'] = df_int['Casos_Notificados'].shift(1)
                if 'Total_Nacional' in df_int.columns:
                    df_int['Doses_Lag1'] = df_int['Total_Nacional'].shift(1)
                # TendÃªncia temporal
                df_int['Trend'] = pd.to_numeric(df_int['Ano'], errors='coerce')
                # Limpar
                df_int = df_int.dropna()
                # Preparar X, y
                feature_cols = ['Trend']
                if 'Total_Nacional' in df_int.columns:
                    feature_cols += ['Total_Nacional']
                if 'Doses_Lag1' in df_int.columns:
                    feature_cols += ['Doses_Lag1']
                feature_cols += ['Casos_Lag1']

                from sklearn.linear_model import LinearRegression
                from sklearn.metrics import r2_score, mean_squared_error
                X = df_int[feature_cols]
                y = df_int['Casos_Notificados']

                modelo_reg = LinearRegression()
                modelo_reg.fit(X, y)
                y_pred = modelo_reg.predict(X)
                # RÂ² seguro (evita NaN se variÃ¢ncia de y ~ 0)
                r2 = float(r2_score(y, y_pred)) if np.var(y) > 1e-9 else 0.0
                rmse = float(np.sqrt(mean_squared_error(y, y_pred)))

                # GrÃ¡fico previsto vs real
                fig_reg = go.Figure()
                fig_reg.add_trace(go.Scatter(x=y, y=y_pred, mode='markers', name='Previsto vs Real', marker=dict(color='blue')))
                min_val = float(min(y.min(), y_pred.min()))
                max_val = float(max(y.max(), y_pred.max()))
                fig_reg.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', name='Identidade', line=dict(dash='dash', color='red')))
                fig_reg.update_layout(title='RegressÃ£o: Casos vs Fatores (Doses, TendÃªncia, Defasagens)', xaxis_title='Casos Reais', yaxis_title='Casos Previstos', template='plotly_white')
                st.plotly_chart(fig_reg, use_container_width=True)
                
                # ExplicaÃ§Ã£o do grÃ¡fico de regressÃ£o
                st.markdown("""
                #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de RegressÃ£o:**
                - **Eixo X (Horizontal):** Casos reais observados
                - **Eixo Y (Vertical):** Casos previstos pelo modelo
                - **Pontos azuis:** Cada ponto representa um ano (casos reais vs. previstos)
                - **Linha tracejada vermelha:** Linha de identidade (previsÃ£o perfeita)
                - **Proximidade Ã  linha:** Quanto mais prÃ³ximos os pontos estÃ£o da linha, melhor o modelo
                - **DispersÃ£o:** Pontos muito espalhados indicam baixa precisÃ£o do modelo
                """)
                
                # Mostrar mÃ©tricas de qualidade do ajuste
                st.markdown("### ğŸ“Š **MÃ©tricas de Qualidade do Modelo:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric('RÂ² (in-sample)', f"{r2:.3f}")
                    
                with col2:
                    st.metric('RMSE (in-sample)', f"{rmse:.0f}")
                
                # ExplicaÃ§Ã£o detalhada das mÃ©tricas
                st.markdown(f"""
                #### ğŸ“š **ExplicaÃ§Ã£o das MÃ©tricas de RegressÃ£o:**
                
                ##### ğŸ“ˆ **RÂ² = {r2:.3f}**
                - **O que Ã©:** Coeficiente de determinaÃ§Ã£o, mede o quanto o modelo explica a variaÃ§Ã£o nos dados
                - **Escala:** 0 a 1 (pode ser negativo se o modelo for muito ruim)
                - **InterpretaÃ§Ã£o atual:** O modelo explica {r2*100:.1f}% da variaÃ§Ã£o nos casos de meningite
                - **Qualidade:**
                  - RÂ² > 0.8: Excelente
                  - RÂ² 0.6-0.8: Bom
                  - RÂ² 0.4-0.6: Moderado
                  - RÂ² < 0.4: Fraco
                  - **Seu modelo:** {"Excelente" if r2 > 0.8 else "Bom" if r2 > 0.6 else "Moderado" if r2 > 0.4 else "Fraco"}
                
                ##### ğŸ“ **RMSE = {rmse:.0f}**
                - **O que Ã©:** Raiz do Erro QuadrÃ¡tico MÃ©dio, mede o erro tÃ­pico das previsÃµes
                - **Unidade:** NÃºmero de casos (mesma unidade dos dados)
                - **InterpretaÃ§Ã£o:** Em mÃ©dia, o modelo erra {rmse:.0f} casos para mais ou para menos
                - **Utilidade:** Quanto menor, melhor a precisÃ£o das previsÃµes
                """)
                
                # Mostrar importÃ¢ncia das variÃ¡veis
                if hasattr(modelo_reg, 'coef_') and hasattr(modelo_reg, 'feature_names_in_'):
                    st.markdown("#### ğŸ¯ **ImportÃ¢ncia das VariÃ¡veis:**")
                    coefs = pd.DataFrame({
                        'VariÃ¡vel': feature_cols,
                        'Coeficiente': modelo_reg.coef_,
                        'ImportÃ¢ncia_Abs': np.abs(modelo_reg.coef_)
                    }).sort_values('ImportÃ¢ncia_Abs', ascending=False)
                    st.dataframe(coefs)
                    
                    st.markdown("""
                    **ğŸ“Š InterpretaÃ§Ã£o dos Coeficientes:**
                    - **Coeficiente positivo:** Aumento na variÃ¡vel leva a aumento nos casos
                    - **Coeficiente negativo:** Aumento na variÃ¡vel leva Ã  diminuiÃ§Ã£o nos casos
                    - **Magnitude:** Quanto maior o valor absoluto, maior o impacto da variÃ¡vel
                    """)

                # ValidaÃ§Ã£o temporal e diagnÃ³stico
                st.subheader('ğŸ“ ValidaÃ§Ã£o Temporal (TimeSeriesSplit)')
                try:
                    from sklearn.model_selection import TimeSeriesSplit
                    n_splits = min(5, max(2, len(df_int) - 3))
                    tscv = TimeSeriesSplit(n_splits=n_splits)
                    cv_rows = []
                    for i, (train_idx, test_idx) in enumerate(tscv.split(df_int)):
                        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
                        m = LinearRegression().fit(X_train, y_train)
                        y_hat = m.predict(X_test)
                        # RÂ² somente se houver pelo menos 2 amostras e variÃ¢ncia
                        if len(y_test) >= 2 and np.var(y_test) > 1e-9:
                            cv_r2 = float(r2_score(y_test, y_hat))
                        else:
                            cv_r2 = None
                        cv_rmse = float(np.sqrt(mean_squared_error(y_test, y_hat)))
                        cv_rows.append({'fold': i + 1, 'R2': cv_r2, 'RMSE': cv_rmse, 'n_test': int(len(test_idx))})
                    if cv_rows:
                        cv_df = pd.DataFrame(cv_rows)
                        st.dataframe(cv_df)
                        r2_valid = cv_df['R2'].dropna()
                        r2_cv_mean = r2_valid.mean() if not r2_valid.empty else 0.0
                        rmse_cv_mean = cv_df['RMSE'].mean()
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric('RÂ² mÃ©dio (CV)', f"{r2_cv_mean:.3f}")
                        with col2:
                            st.metric('RMSE mÃ©dio (CV)', f"{rmse_cv_mean:.0f}")
                            
                        # ExplicaÃ§Ã£o da validaÃ§Ã£o cruzada temporal
                        st.markdown(f"""
                        #### ğŸ“š **ExplicaÃ§Ã£o da ValidaÃ§Ã£o Cruzada Temporal:**
                        
                        **ğŸ”„ O que Ã©:** TÃ©cnica que avalia a capacidade do modelo de prever dados futuros
                        
                        **ğŸ•’ Como funciona:**
                        - Divide os dados em sequÃªncias temporais
                        - Treina com dados do passado, testa com dados do futuro
                        - Repete o processo vÃ¡rias vezes
                        
                        **ğŸ“Š MÃ©tricas obtidas:**
                        - **RÂ² mÃ©dio (CV) = {r2_cv_mean:.3f}**
                          - Performance mÃ©dia em dados nÃ£o vistos
                          - {"Melhor que in-sample" if r2_cv_mean > r2 else "Pior que in-sample" if r2_cv_mean < r2 else "Similar ao in-sample"} (in-sample = {r2:.3f})
                        
                        - **RMSE mÃ©dio (CV) = {rmse_cv_mean:.0f}**
                          - Erro mÃ©dio em dados nÃ£o vistos
                          - {"Melhor que in-sample" if rmse_cv_mean < rmse else "Pior que in-sample" if rmse_cv_mean > rmse else "Similar ao in-sample"} (in-sample = {rmse:.0f})
                        
                        **ğŸ¯ InterpretaÃ§Ã£o:**
                        - Se CV â‰ˆ in-sample: modelo generaliza bem
                        - Se CV << in-sample: possÃ­vel overfitting
                        - Se CV >> in-sample: possÃ­vel underfitting ou dados inadequados
                        """)
                except Exception as _:
                    st.info('â„¹ï¸ NÃ£o foi possÃ­vel calcular a validaÃ§Ã£o temporal nesta amostra.')

                # ResÃ­duos ao longo do tempo
                st.subheader('ğŸ©º DiagnÃ³stico de ResÃ­duos')
                residuos = (y - y_pred).reset_index(drop=True)
                anos_plot = df_int['Ano'].reset_index(drop=True) if 'Ano' in df_int.columns else pd.Series(range(len(residuos)))
                fig_res = px.line(x=anos_plot, y=residuos, markers=True, title='ResÃ­duos ao longo do tempo')
                fig_res.update_layout(xaxis_title='Ano', yaxis_title='ResÃ­duo (Casos)', template='plotly_white')
                st.plotly_chart(fig_res, use_container_width=True)
                
                # ExplicaÃ§Ã£o do grÃ¡fico de resÃ­duos
                st.markdown("""
                #### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico de ResÃ­duos:**
                - **Eixo X (Horizontal):** Anos
                - **Eixo Y (Vertical):** ResÃ­duos (diferenÃ§a entre casos reais e previstos)
                - **Linha:** Mostra os erros do modelo ao longo do tempo
                - **PadrÃµes a observar:**
                  - **Linha horizontal prÃ³xima a zero:** Modelo bem ajustado
                  - **TendÃªncias sistemÃ¡ticas:** Modelo pode estar perdendo padrÃµes importantes
                  - **Variabilidade constante:** Boa qualidade dos resÃ­duos
                  - **Variabilidade crescente/decrescente:** PossÃ­vel heteroscedasticidade
                - **InterpretaÃ§Ã£o epidemiolÃ³gica:** ResÃ­duos grandes podem indicar anos com eventos especiais (surtos, mudanÃ§as de polÃ­tica)
                """)
            else:
                st.info('â„¹ï¸ Dados anuais insuficientes para regressÃ£o mÃºltipla.')
        except Exception as e:
            st.warning(f"Erro na regressÃ£o mÃºltipla: {e}")
        
        # AnÃ¡lise de clustering hierÃ¡rquico
        st.subheader("ğŸ¯ **Clustering HierÃ¡rquico**")
        
        if sorogrupos is not None and not sorogrupos.empty:
            try:
                from scipy.cluster.hierarchy import dendrogram, linkage
                from scipy.spatial.distance import pdist
                
                # Preparar dados para clustering
                dados_cluster = sorogrupos.groupby('Sorogrupo').agg({
                    'Casos': 'sum',
                    'Obitos': 'sum'
                }).reset_index()
                
                dados_cluster['Letalidade'] = (
                    dados_cluster['Obitos'] / dados_cluster['Casos'] * 100
                ).round(2)
                
                # Selecionar variÃ¡veis para clustering
                features = ['Casos', 'Letalidade']
                X_cluster = dados_cluster[features].values
                
                # Normalizar dados
                scaler = StandardScaler()
                X_cluster_norm = scaler.fit_transform(X_cluster)
                
                # Calcular matriz de distÃ¢ncia
                dist_matrix = pdist(X_cluster_norm)
                
                # Aplicar clustering hierÃ¡rquico
                linkage_matrix = linkage(dist_matrix, method='ward')
                
                # GrÃ¡fico de dendrograma
                fig_dendro = go.Figure()
                
                # Criar dendrograma manualmente
                fig_dendro.add_trace(go.Scatter(
                    x=list(range(len(linkage_matrix) + 1)),
                    y=linkage_matrix[:, 2],
                    mode='lines+markers',
                    name='Dendrograma',
                    line=dict(color='blue'),
                    marker=dict(size=6)
                ))
                
                fig_dendro.update_layout(
                    title="Dendrograma HierÃ¡rquico dos Sorogrupos",
                    xaxis_title="Ãndice",
                    yaxis_title="DistÃ¢ncia",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_dendro, use_container_width=True)
                
                # NÃºmero de clusters sugerido
                st.write("**ğŸ“Š AnÃ¡lise do Dendrograma:**")
                st.write("**MÃ©todo:** Ward (mÃ­nima variÃ¢ncia)")
                st.write("**DistÃ¢ncia:** Euclidiana normalizada")
                
                # Sugerir nÃºmero de clusters
                n_clusters_sugerido = st.slider("NÃºmero de Clusters:", 2, min(5, len(dados_cluster)), 3)
                
                if st.button("ğŸ¯ Aplicar Clustering"):
                    try:
                        from scipy.cluster.hierarchy import fcluster
                        
                        # Aplicar clustering
                        clusters = fcluster(linkage_matrix, n_clusters_sugerido, criterion='maxclust')
                        
                        # Adicionar clusters aos dados
                        dados_cluster['Cluster'] = clusters
                        
                        # GrÃ¡fico de clusters
                        fig_cluster_hier = px.scatter(
                            dados_cluster,
                            x='Casos',
                            y='Letalidade',
                            color='Cluster',
                            title=f"Clustering HierÃ¡rquico (K={n_clusters_sugerido})",
                            text='Sorogrupo',
                            size='Casos'
                        )
                        
                        fig_cluster_hier.update_layout(
                            xaxis_title="NÃºmero de Casos",
                            yaxis_title="Taxa de Letalidade (%)",
                            template='plotly_white'
                        )
                        
                        st.plotly_chart(fig_cluster_hier, use_container_width=True)
                        
                        # ExplicaÃ§Ã£o do grÃ¡fico de clustering hierÃ¡rquico
                        st.markdown(f"""
                        #### ğŸ“– **InterpretaÃ§Ã£o do Clustering HierÃ¡rquico:**
                        - **Eixo X (Horizontal):** NÃºmero de casos por sorogrupo
                        - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
                        - **Cores diferentes:** Cada cor representa um cluster hierÃ¡rquico
                        - **MÃ©todo Ward:** Minimiza a variÃ¢ncia intra-cluster
                        - **Vantagem:** NÃ£o requer definir nÃºmero de clusters a priori
                        
                        #### ğŸŒ³ **DiferenÃ§a do K-Means:**
                        - **HierÃ¡rquico:** Cria Ã¡rvore de relacionamentos (dendrograma)
                        - **DeterminÃ­stico:** Sempre produz o mesmo resultado
                        - **FlexÃ­vel:** Permite escolher nÃºmero de clusters apÃ³s anÃ¡lise
                        - **Interpretabilidade:** Mostra hierarquia de similaridades
                        """)
                        
                        # Resumo dos clusters
                        st.write("**ğŸ“‹ Resumo dos Clusters:**")
                        for i in range(1, n_clusters_sugerido + 1):
                            cluster_data = dados_cluster[dados_cluster['Cluster'] == i]
                            st.write(f"**Cluster {i}:** {len(cluster_data)} sorogrupos")
                            for idx in cluster_data.index:
                                sorogrupo = cluster_data.loc[idx, 'Sorogrupo']
                                casos = cluster_data.loc[idx, 'Casos']
                                letalidade = cluster_data.loc[idx, 'Letalidade']
                                st.write(f"  - {sorogrupo}: {casos} casos, {letalidade:.1f}% letalidade")
                        
                    except Exception as e:
                        st.error(f"Erro no clustering: {e}")
                
            except Exception as e:
                st.warning(f"Erro no clustering hierÃ¡rquico: {e}")
        
        # Resumo das anÃ¡lises avanÃ§adas
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Resumo das AnÃ¡lises AvanÃ§adas:**
        
        **1. DecomposiÃ§Ã£o STL:**
        - AnÃ¡lise robusta de sÃ©ries temporais
        - SeparaÃ§Ã£o de tendÃªncia, sazonalidade e resÃ­duos
        - IdentificaÃ§Ã£o de padrÃµes complexos
        
        **2. Teste de Estacionariedade:**
        - AvaliaÃ§Ã£o da estabilidade temporal
        - Necessidade de diferenciaÃ§Ã£o
        - ValidaÃ§Ã£o de modelos temporais
        
        **3. CorrelaÃ§Ã£o Cruzada:**
        - RelaÃ§Ãµes entre diferentes sorogrupos
        - PadrÃµes de co-ocorrÃªncia
        - IdentificaÃ§Ã£o de surtos simultÃ¢neos
        
        **4. RegressÃ£o MÃºltipla:**
        - Modelagem preditiva da letalidade
        - IdentificaÃ§Ã£o de fatores influentes
        - AvaliaÃ§Ã£o da qualidade do modelo
        
        **5. Clustering HierÃ¡rquico:**
        - Agrupamento hierÃ¡rquico de sorogrupos
        - AnÃ¡lise de similaridades epidemiolÃ³gicas
        - IdentificaÃ§Ã£o de padrÃµes ocultos
        """)
        
    else:
        st.error("âŒ Dados nÃ£o disponÃ­veis para anÃ¡lise avanÃ§ada")

def show_regional_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise Regional - DistribuiÃ§Ã£o GeogrÃ¡fica".

    Renderiza uma anÃ¡lise focada nas cinco grandes regiÃµes do Brasil. A funÃ§Ã£o
    mostra a evoluÃ§Ã£o temporal da vacinaÃ§Ã£o por regiÃ£o, compara o total de doses
    e a cobertura mÃ©dia entre as regiÃµes, e analisa a correlaÃ§Ã£o entre o
    nÃºmero de doses aplicadas e os casos notificados em nÃ­vel regional.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves 'analise_regional'
                      e 'imunizacao_regional'. TambÃ©m tenta carregar
                      'data/processed/analise_regional.csv' para correlaÃ§Ã£o.
    """
    st.header("ğŸ—ºï¸ **AnÃ¡lise Regional - DistribuiÃ§Ã£o GeogrÃ¡fica**")
    st.markdown("---")
    
    if dados and 'analise_regional' in dados and 'imunizacao_regional' in dados:
        # Dados regionais
        analise_regional = dados['analise_regional']
        imunizacao_regional = dados['imunizacao_regional']
        
        # MÃ©tricas regionais
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_regioes = len(analise_regional)
            st.metric("ğŸŒ RegiÃµes Analisadas", total_regioes)
        
        with col2:
            total_ufs = analise_regional['Total_UFs'].sum()
            st.metric("ğŸ™ï¸ Total de UFs", total_ufs)
        
        with col3:
            media_cobertura = analise_regional['Cobertura_Media'].mean()
            st.metric("ğŸ’‰ Cobertura MÃ©dia", f"{media_cobertura:.1f}%")
        
        # GrÃ¡fico de evoluÃ§Ã£o temporal por regiÃ£o
        st.subheader("ğŸ“ˆ **EvoluÃ§Ã£o Temporal por RegiÃ£o**")
        
        fig_temporal_regional = go.Figure()
        
        for regiao in imunizacao_regional['Regiao'].unique():
            dados_regiao = imunizacao_regional[imunizacao_regional['Regiao'] == regiao]
            fig_temporal_regional.add_trace(go.Scatter(
                x=dados_regiao['Ano'],
                y=dados_regiao['Total_Doses'],
                mode='lines+markers',
                name=regiao,
                line=dict(width=3),
                marker=dict(size=8)
            ))
        
        fig_temporal_regional.update_layout(
            title="EvoluÃ§Ã£o da Cobertura Vacinal por RegiÃ£o (2023-2025)",
            xaxis_title="Ano",
            yaxis_title="Total de Doses",
            template='plotly_white',
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig_temporal_regional, use_container_width=True)
        
        # ExplicaÃ§Ã£o detalhada do grÃ¡fico de evoluÃ§Ã£o temporal
        st.markdown("""
        #### ğŸ“š **ExplicaÃ§Ã£o da EvoluÃ§Ã£o Temporal por RegiÃ£o:**
        
        ##### ğŸ¯ **O que este grÃ¡fico mostra:**
        - **Cada linha colorida** representa uma regiÃ£o do Brasil
        - **Eixo X:** Anos do perÃ­odo analisado
        - **Eixo Y:** Total de doses aplicadas
        - **Marcadores:** Dados especÃ­ficos por ano
        
        ##### ğŸ“Š **Como interpretar:**
        - **Linhas ascendentes:** Aumento na vacinaÃ§Ã£o na regiÃ£o
        - **Linhas descendentes:** ReduÃ§Ã£o na vacinaÃ§Ã£o (possÃ­vel problema)
        - **Linhas paralelas:** RegiÃµes com comportamento similar
        - **DivergÃªncia:** DiferenÃ§as crescentes entre regiÃµes
        
        ##### ğŸ” **ImportÃ¢ncia epidemiolÃ³gica:**
        - **IdentificaÃ§Ã£o de desigualdades regionais** na cobertura vacinal
        - **Monitoramento da eficÃ¡cia** das polÃ­ticas regionais
        - **Planejamento de recursos** baseado em tendÃªncias
        - **DetecÃ§Ã£o precoce** de problemas regionais especÃ­ficos
        
        ##### âš ï¸ **Sinais de alerta a observar:**
        - RegiÃµes com **tendÃªncia decrescente** persistente
        - **Grandes disparidades** entre regiÃµes
        - **EstagnaÃ§Ã£o** em nÃ­veis baixos de cobertura
        - **Variabilidade excessiva** ano a ano
        """)
        
        # EstatÃ­sticas regionais
        st.subheader("ğŸ“Š **EstatÃ­sticas Regionais**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # GrÃ¡fico de barras por regiÃ£o
            fig_barras_regional = px.bar(
                analise_regional,
                x='Regiao',
                y='Total_Doses',
                title="Total de Doses por RegiÃ£o",
                color='Regiao',
                text='Total_Doses'
            )
            
            fig_barras_regional.update_layout(
                xaxis_title="RegiÃ£o",
                yaxis_title="Total de Doses",
                template='plotly_white',
                showlegend=False
            )
            
            fig_barras_regional.update_traces(
                texttemplate='%{text:,}',
                textposition='outside'
            )
            
            st.plotly_chart(fig_barras_regional, use_container_width=True)
            
            # ExplicaÃ§Ã£o do grÃ¡fico de total de doses por regiÃ£o
            st.markdown("""
            **ğŸ“– GrÃ¡fico de Total de Doses por RegiÃ£o:**
            - **Barras:** Altura representa total acumulado
            - **Cores:** Diferencia as regiÃµes visualmente
            - **NÃºmeros:** Valores exatos sobre as barras
            - **InterpretaÃ§Ã£o:** Identifica regiÃµes com maior/menor volume total
            - **AplicaÃ§Ã£o:** AlocaÃ§Ã£o proporcional de recursos
            """)
        
        with col2:
            # GrÃ¡fico de cobertura mÃ©dia
            fig_cobertura_regional = px.bar(
                analise_regional,
                x='Regiao',
                y='Cobertura_Media',
                title="Cobertura MÃ©dia por RegiÃ£o (%)",
                color='Cobertura_Media',
                text='Cobertura_Media'
            )
            
            fig_cobertura_regional.update_layout(
                xaxis_title="RegiÃ£o",
                yaxis_title="Cobertura MÃ©dia (%)",
                template='plotly_white',
                showlegend=False
            )
            
            fig_cobertura_regional.update_traces(
                texttemplate='%{text:.1f}%',
                textposition='outside'
            )
            
            st.plotly_chart(fig_cobertura_regional, use_container_width=True)
            
            # ExplicaÃ§Ã£o do grÃ¡fico de cobertura mÃ©dia por regiÃ£o
            st.markdown("""
            **ğŸ“– GrÃ¡fico de Cobertura MÃ©dia por RegiÃ£o:**
            - **Barras:** Altura representa percentual de cobertura
            - **Escala de cores:** Intensidade proporcional Ã  cobertura
            - **Meta ideal:** >95% para imunidade coletiva
            - **InterpretaÃ§Ã£o:** Avalia eficÃ¡cia regional
            - **AplicaÃ§Ã£o:** PriorizaÃ§Ã£o de intervenÃ§Ãµes
            """)
        
        # AnÃ¡lise comparativa detalhada das duas mÃ©tricas
        st.markdown(f"""
        #### ğŸ”¬ **AnÃ¡lise Comparativa Total vs Cobertura:**
        
        ##### ğŸ“Š **Por que analisar ambas as mÃ©tricas:**
        - **Total de doses:** Mede **volume absoluto** de vacinaÃ§Ã£o
        - **Cobertura mÃ©dia:** Mede **eficiÃªncia relativa** Ã  populaÃ§Ã£o
        
        ##### ğŸ¯ **InterpretaÃ§Ãµes possÃ­veis:**
        - **Alto total + Alta cobertura:** RegiÃ£o populosa bem atendida
        - **Alto total + Baixa cobertura:** RegiÃ£o populosa com lacunas
        - **Baixo total + Alta cobertura:** RegiÃ£o pequena bem atendida
        - **Baixo total + Baixa cobertura:** RegiÃ£o que necessita atenÃ§Ã£o
        
        ##### ğŸ“ˆ **Cobertura atual por regiÃ£o:**
        {f"- **MÃ©dia geral:** {media_cobertura:.1f}%" if 'media_cobertura' in locals() else ""}
        - **Meta OMS:** >95% para controle efetivo
        - **SituaÃ§Ã£o crÃ­tica:** RegiÃµes <70%
        - **SituaÃ§Ã£o boa:** RegiÃµes >95%
        """)
        
        # ComparaÃ§Ã£o dos Ãºltimos 3 anos
        st.subheader("ğŸ”„ **ComparaÃ§Ã£o dos Ãšltimos 3 Anos por RegiÃ£o**")
        
        # Preparar dados para comparaÃ§Ã£o
        anos_unicos = sorted(imunizacao_regional['Ano'].unique())
        if len(anos_unicos) >= 3:
            anos_recentes = anos_unicos[-3:]
            
            dados_comparacao = imunizacao_regional[imunizacao_regional['Ano'].isin(anos_recentes)]
            
            fig_comparacao = px.bar(
                dados_comparacao,
                x='Regiao',
                y='Total_Doses',
                color='Ano',
                title=f"ComparaÃ§Ã£o Regional ({anos_recentes[0]}-{anos_recentes[-1]})",
                barmode='group'
            )
            
            fig_comparacao.update_layout(
                xaxis_title="RegiÃ£o",
                yaxis_title="Total de Doses",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_comparacao, use_container_width=True)
            
            # ExplicaÃ§Ã£o do grÃ¡fico de comparaÃ§Ã£o temporal
            st.markdown(f"""
            #### ğŸ“– **InterpretaÃ§Ã£o da ComparaÃ§Ã£o dos Ãšltimos 3 Anos:**
            
            ##### ğŸ¯ **O que este grÃ¡fico mostra:**
            - **Barras agrupadas** por regiÃ£o, cada cor representa um ano
            - **EvoluÃ§Ã£o temporal** recente da vacinaÃ§Ã£o regional
            - **ComparaÃ§Ã£o direta** entre regiÃµes no mesmo perÃ­odo
            
            ##### ğŸ“Š **Como analisar:**
            - **Barras crescentes:** Melhoria ao longo dos anos
            - **Barras decrescentes:** ReduÃ§Ã£o preocupante
            - **PadrÃµes uniformes:** PolÃ­tica nacional consistente
            - **PadrÃµes divergentes:** DiferenÃ§as regionais especÃ­ficas
            
            ##### ğŸ” **Indicadores importantes:**
            - **TendÃªncia geral:** {"Crescimento" if anos_recentes else "A ser avaliada"}
            - **Homogeneidade:** RegiÃµes com comportamento similar
            - **Outliers:** RegiÃµes com comportamento atÃ­pico
            - **Sustentabilidade:** ManutenÃ§Ã£o dos nÃ­veis ano a ano
            
            ##### ğŸ“ˆ **AplicaÃ§Ãµes prÃ¡ticas:**
            - **IdentificaÃ§Ã£o de best practices** regionais
            - **DetecÃ§Ã£o de problemas emergentes**
            - **Planejamento de recursos** para prÃ³ximos anos
            - **AvaliaÃ§Ã£o de polÃ­ticas** implementadas
            """)
        
        # AnÃ¡lise de correlaÃ§Ã£o regional
        st.subheader("ğŸ”— **AnÃ¡lise de CorrelaÃ§Ã£o Regional**")

        try:
            # Preferir base consolidada por regiÃ£o (sem UF)
            regional_cases_path = os.path.join('data', 'processed', 'analise_regional.csv')
            if os.path.exists(regional_cases_path):
                casos_regiao_total = pd.read_csv(regional_cases_path)
                # Espera colunas: Regiao, Casos
                base_merge = analise_regional[['Regiao', 'Total_Doses']].merge(
                    casos_regiao_total[['Regiao', 'Casos']], on='Regiao', how='inner'
                )

                if not base_merge.empty:
                    corr, p_valor = stats.pearsonr(base_merge['Total_Doses'], base_merge['Casos'])
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ğŸ“ˆ CorrelaÃ§Ã£o (RegiÃµes)", f"{corr:.3f}")
                    with col2:
                        st.metric("p-valor", f"{p_valor:.4f}")

                    fig_disp = px.scatter(
                        base_merge,
                        x='Total_Doses',
                        y='Casos',
                        text='Regiao',
                        title='Casos vs Total de Doses por RegiÃ£o'
                    )
                    
                    # Adicionar linha de tendÃªncia manual
                    if len(base_merge) > 1:
                        x_vals = base_merge['Total_Doses'].values
                        y_vals = base_merge['Casos'].values
                        
                        # Remover NaN values
                        mask = ~(np.isnan(x_vals) | np.isnan(y_vals))
                        x_clean = x_vals[mask]
                        y_clean = y_vals[mask]
                        
                        if len(x_clean) > 1:
                            # Calcular regressÃ£o linear usando numpy
                            coeffs = np.polyfit(x_clean, y_clean, 1)
                            x_trend = np.linspace(x_clean.min(), x_clean.max(), 100)
                            y_trend = coeffs[0] * x_trend + coeffs[1]
                            
                            # Adicionar linha de tendÃªncia
                            fig_disp.add_trace(go.Scatter(
                                x=x_trend,
                                y=y_trend,
                                mode='lines',
                                name='Linha de TendÃªncia',
                                line=dict(color='red', dash='dash')
                            ))
                    fig_disp.update_traces(textposition='top center')
                    fig_disp.update_layout(template='plotly_white')
                    st.plotly_chart(fig_disp, use_container_width=True)

                    st.write("**ğŸ“‹ Tabela (RegiÃµes):**")
                    st.dataframe(base_merge[['Regiao', 'Total_Doses', 'Casos']])
            else:
                st.info("Dados regionais agregados nÃ£o encontrados em data/processed/analise_regional.csv. Pulei a correlaÃ§Ã£o regional.")
        except Exception as e:
            st.warning(f"NÃ£o foi possÃ­vel calcular a correlaÃ§Ã£o regional: {e}")
        
        # Resumo da anÃ¡lise regional
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Resumo da AnÃ¡lise Regional:**
        
        **1. DistribuiÃ§Ã£o GeogrÃ¡fica:**
        - AnÃ¡lise por 5 regiÃµes brasileiras
        - Cobertura vacinal por regiÃ£o
        - EvoluÃ§Ã£o temporal regional
        
        **2. ComparaÃ§Ãµes Regionais:**
        - Ranking de cobertura por regiÃ£o
        - AnÃ¡lise de disparidades geogrÃ¡ficas
        - TendÃªncias regionais especÃ­ficas
        
        **3. CorrelaÃ§Ãµes Regionais:**
        - RelaÃ§Ã£o entre vacinaÃ§Ã£o e casos por regiÃ£o
        - IdentificaÃ§Ã£o de padrÃµes regionais
        - Efetividade da vacinaÃ§Ã£o por Ã¡rea geogrÃ¡fica
        """)
        
    else:
        st.error("âŒ Dados regionais nÃ£o disponÃ­veis")

def show_epidemiological_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise EpidemiolÃ³gica - Indicadores de SaÃºde PÃºblica".

    Esta funÃ§Ã£o foca em indicadores epidemiolÃ³gicos chave, como a letalidade.
    Ela mostra a evoluÃ§Ã£o da taxa de letalidade por etiologia ao longo do tempo,
    apresenta um heatmap para visualizaÃ§Ã£o intuitiva desses dados, e analisa
    a evoluÃ§Ã£o da letalidade mÃ©dia anual.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza as chaves 'letalidade_etiologia'
                      e 'casos_2017_2022', alÃ©m de outras tabelas de casos para
                      cÃ¡lculos de fallback.
    """
    st.header("ğŸ¦  **AnÃ¡lise EpidemiolÃ³gica - Indicadores de SaÃºde PÃºblica**")
    st.markdown("---")
    
    if dados and 'letalidade_etiologia' in dados and 'casos_2017_2022' in dados:
        # Dados de letalidade
        letalidade_etiologia = dados['letalidade_etiologia']
        casos_2017_2022 = dados['casos_2017_2022']
        
        # MÃ©tricas epidemiolÃ³gicas
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_casos = casos_2017_2022['Casos_Notificados'].sum()
            st.metric("ğŸ“Š Total de Casos", f"{total_casos:,}")
        
        with col2:
            # Usar a coluna correta Taxa_Letalidade
            if 'Taxa_Letalidade' in letalidade_etiologia.columns:
                media_letalidade = letalidade_etiologia['Taxa_Letalidade'].mean()
                st.metric("ğŸ’€ Letalidade MÃ©dia", f"{media_letalidade:.1f}%")
            else:
                st.metric("ğŸ’€ Letalidade MÃ©dia", "N/A")
        
        with col3:
            # Total de Ã³bitos com fallback entre bases disponÃ­veis
            total_obitos = 0
            if 'Obitos' in casos_2017_2022.columns:
                total_obitos = pd.to_numeric(casos_2017_2022['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('casos_consolidados' in dados) and isinstance(dados['casos_consolidados'], pd.DataFrame) and ('Obitos' in dados['casos_consolidados'].columns):
                total_obitos = pd.to_numeric(dados['casos_consolidados']['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('bacterianas_2024' in dados) and isinstance(dados['bacterianas_2024'], pd.DataFrame) and ('Obitos' in dados['bacterianas_2024'].columns):
                total_obitos = pd.to_numeric(dados['bacterianas_2024']['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('etiologia_2024' in dados) and isinstance(dados['etiologia_2024'], pd.DataFrame) and ('Obitos' in dados['etiologia_2024'].columns):
                total_obitos = pd.to_numeric(dados['etiologia_2024']['Obitos'], errors='coerce').fillna(0).sum()
            st.metric("âš°ï¸ Total de Ã“bitos", f"{int(total_obitos):,}" if total_obitos else "N/A")
        
        # AnÃ¡lise de letalidade por etiologia (melhor visualizaÃ§Ã£o)
        st.subheader("ğŸ“ˆ **Letalidade por Etiologia ao Longo do Tempo**")
        
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            let_df = letalidade_etiologia.copy()
            let_df['Taxa_Letalidade'] = pd.to_numeric(let_df['Taxa_Letalidade'], errors='coerce').fillna(0)
            # Garantir nÃ£o-negatividade
            let_df['Taxa_Letalidade'] = let_df['Taxa_Letalidade'].clip(lower=0)
            fig_letalidade = px.bar(
                let_df,
                x='Ano',
                y='Taxa_Letalidade',
                color='Etiologia',
                barmode='group',
                title="Taxa de Letalidade (%) por Etiologia e Ano"
            )
            fig_letalidade.update_layout(
                xaxis_title="Ano",
                yaxis_title="Taxa de Letalidade (%)",
                template='plotly_white'
            )
            fig_letalidade.update_xaxes(tickformat='d')
            st.plotly_chart(fig_letalidade, use_container_width=True)
        else:
            st.warning("âš ï¸ Coluna de letalidade nÃ£o encontrada nos dados")
        
        # Nova anÃ¡lise: Heatmap de letalidade por etiologia e ano (mais intuitivo, sem escalas negativas)
        st.subheader("ğŸ—ºï¸ **Mapa de Calor: Letalidade por Etiologia e Ano**")
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            let_hm = letalidade_etiologia.copy()
            let_hm['Taxa_Letalidade'] = pd.to_numeric(let_hm['Taxa_Letalidade'], errors='coerce').fillna(0).clip(lower=0)
            matriz = let_hm.pivot_table(index='Ano', columns='Etiologia', values='Taxa_Letalidade', aggfunc='mean')
            fig_hm = px.imshow(
                matriz.sort_index(),
                color_continuous_scale='Reds',
                aspect='auto',
                labels=dict(color='Letalidade (%)'),
                title='Letalidade (%) por Etiologia e Ano'
            )
            fig_hm.update_layout(template='plotly_white')
            st.plotly_chart(fig_hm, use_container_width=True)
        else:
            st.info("â„¹ï¸ Sem dados de letalidade por etiologia para o heatmap")
        
        # AnÃ¡lise de letalidade por ano
        st.subheader("ğŸ“Š **Letalidade por Ano e Etiologia**")
        
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            # Agrupar por ano e calcular mÃ©dia de letalidade
            letalidade_por_ano = letalidade_etiologia.groupby('Ano')['Taxa_Letalidade'].mean().reset_index()
            
            fig_letalidade_ano = px.line(
                letalidade_por_ano,
                x='Ano',
                y='Taxa_Letalidade',
                title="EvoluÃ§Ã£o da Letalidade MÃ©dia por Ano (2007-2020)",
                markers=True
            )
            
            fig_letalidade_ano.update_layout(
                xaxis_title="Ano",
                yaxis_title="Letalidade MÃ©dia (%)",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_letalidade_ano, use_container_width=True)
            
            # EstatÃ­sticas de letalidade
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**EstatÃ­sticas de Letalidade por Etiologia:**")
                st.dataframe(letalidade_etiologia.groupby('Etiologia')['Taxa_Letalidade'].describe())
            
            with col2:
                st.write("**Letalidade por Ano:**")
                st.dataframe(letalidade_por_ano)
        else:
            st.warning("âš ï¸ Dados de letalidade nÃ£o disponÃ­veis para anÃ¡lise detalhada")
        
        # InformaÃ§Ãµes sobre a anÃ¡lise
        st.subheader("â„¹ï¸ **Sobre a AnÃ¡lise EpidemiolÃ³gica**")
        st.markdown("""
        **Esta anÃ¡lise mostra:**
        - Taxas de letalidade por etiologia
        - EvoluÃ§Ã£o temporal de casos e Ã³bitos
        - PadrÃµes de letalidade ao longo do tempo
        - ComparaÃ§Ã£o entre diferentes agentes causadores
        
        **ImportÃ¢ncia:**
        - Identificar agentes mais letais
        - Monitorar tendÃªncias de letalidade
        - Planejar estratÃ©gias de tratamento
        - Avaliar efetividade de intervenÃ§Ãµes
        """)
    else:
        st.warning("âš ï¸ Dados epidemiolÃ³gicos nÃ£o disponÃ­veis")

def show_attack_rate_analysis(dados):
    """Exibe a seÃ§Ã£o "AnÃ¡lise de Taxa de Ataque e ForÃ§a de InfecÃ§Ã£o".

    Calcula e exibe a taxa de ataque (casos por 100.000 habitantes) e a forÃ§a de
    infecÃ§Ã£o (taxa instantÃ¢nea de aquisiÃ§Ã£o da doenÃ§a). A funÃ§Ã£o mostra a evoluÃ§Ã£o
    anual dessas mÃ©tricas, a sazonalidade baseada em dados de hospitalizaÃ§Ã£o (SIH),
    e a correlaÃ§Ã£o entre a taxa de ataque e a letalidade.

    Args:
        dados (dict): O dicionÃ¡rio global de dados. Utiliza 'casos_2017_2022',
                      'casos_consolidados', e 'sih_meningite'.
    """
    st.header("âš¡ **AnÃ¡lise de Taxa de Ataque e ForÃ§a de InfecÃ§Ã£o**")
    st.markdown("---")
    
    if dados and ('casos_2017_2022' in dados or 'casos_consolidados' in dados):
        # Unificar casos anuais a partir de todas as tabelas disponÃ­veis
        frames = []
        if 'casos_2017_2022' in dados and isinstance(dados['casos_2017_2022'], pd.DataFrame):
            frames.append(dados['casos_2017_2022'][['Ano', 'Casos_Notificados'] + (["Obitos"] if 'Obitos' in dados['casos_2017_2022'].columns else [])])
        if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
            frames.append(dados['casos_consolidados'][['Ano', 'Casos_Notificados'] + (["Obitos"] if 'Obitos' in dados['casos_consolidados'].columns else [])])
        if not frames:
            st.warning("âš ï¸ Nenhuma tabela de casos encontrada para taxa de ataque")
            return
        casos_anuais = pd.concat(frames, ignore_index=True).groupby('Ano', as_index=False).sum(numeric_only=True)
        
        # MÃ©tricas de taxa de ataque
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_casos = casos_anuais['Casos_Notificados'].sum()
            st.metric("ğŸ“Š Total de Casos", f"{total_casos:,}")
        
        with col2:
            # Verificar se a coluna Obitos existe
            if 'Obitos' in casos_anuais.columns:
                total_obitos = casos_anuais['Obitos'].sum()
                st.metric("ğŸ’€ Total de Ã“bitos", f"{total_obitos:,}")
            else:
                st.metric("ğŸ’€ Total de Ã“bitos", "N/A")
        
        with col3:
            taxa_ataque_geral = (total_casos / 214000000) * 100000  # PopulaÃ§Ã£o estimada Brasil
            st.metric("ğŸ¯ Taxa de Ataque", f"{taxa_ataque_geral:.1f}/100k")
        
        # AnÃ¡lise de taxa de ataque por ano
        st.subheader("ğŸ“ˆ **Taxa de Ataque por Ano**")
        
        # Calcular taxa de ataque anual
        taxa_ataque_anual = casos_anuais.copy()
        
        # Calcular taxa de letalidade anual (se houver Ã³bitos)
        if 'Obitos' in taxa_ataque_anual.columns:
            taxa_ataque_anual['Taxa_Letalidade'] = (taxa_ataque_anual['Obitos'] / taxa_ataque_anual['Casos_Notificados']) * 100
        
        # PopulaÃ§Ã£o: se nÃ£o houver fonte no projeto, aplicar aproximaÃ§Ã£o com preenchimento progressivo
        populacao_anos = {
            2017: 209_000_000,
            2018: 210_000_000,
            2019: 211_000_000,
            2020: 212_000_000,
            2021: 213_000_000,
            2022: 214_000_000,
        }
        taxa_ataque_anual['Populacao'] = taxa_ataque_anual['Ano'].map(populacao_anos)
        # Preencher anos sem populaÃ§Ã£o com Ãºltimo valor conhecido
        taxa_ataque_anual = taxa_ataque_anual.sort_values('Ano')
        taxa_ataque_anual['Populacao'] = taxa_ataque_anual['Populacao'].ffill().bfill()
        taxa_ataque_anual['Taxa_Ataque'] = (taxa_ataque_anual['Casos_Notificados'] / taxa_ataque_anual['Populacao']) * 100000
        
        # GrÃ¡fico de taxa de ataque
        fig_taxa_ataque = px.line(
            taxa_ataque_anual,
            x='Ano',
            y='Taxa_Ataque',
            title="Taxa de Ataque de Meningite por Ano (por 100.000 habitantes)",
            markers=True,
            line_shape='linear'
        )
        
        fig_taxa_ataque.update_layout(
            xaxis_title="Ano",
            yaxis_title="Taxa de Ataque (por 100.000 habitantes)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_taxa_ataque, use_container_width=True)
        
        # ExplicaÃ§Ã£o do conceito de taxa de ataque e do grÃ¡fico
        st.markdown(f"""
        #### ğŸ“š **ExplicaÃ§Ã£o da Taxa de Ataque:**
        
        ##### ğŸ¯ **O que Ã© Taxa de Ataque:**
        - **DefiniÃ§Ã£o:** ProporÃ§Ã£o de pessoas que desenvolvem a doenÃ§a em uma populaÃ§Ã£o especÃ­fica durante um perÃ­odo determinado
        - **Unidade:** Casos por 100.000 habitantes por ano
        - **CÃ¡lculo:** (NÃºmero de casos / PopulaÃ§Ã£o total) Ã— 100.000
        - **Utilidade:** Padroniza a incidÃªncia para comparaÃ§Ã£o entre diferentes populaÃ§Ãµes e perÃ­odos
        
        ##### ğŸ“Š **InterpretaÃ§Ã£o do GrÃ¡fico:**
        - **Eixo X:** Anos do perÃ­odo analisado
        - **Eixo Y:** Taxa de ataque por 100.000 habitantes
        - **Linha com marcadores:** EvoluÃ§Ã£o temporal da incidÃªncia padronizada
        - **TendÃªncia crescente:** Aumento da incidÃªncia na populaÃ§Ã£o
        - **TendÃªncia decrescente:** ReduÃ§Ã£o da incidÃªncia (possivelmente devido a vacinaÃ§Ã£o)
        - **VariaÃ§Ãµes anuais:** Podem refletir surtos, mudanÃ§as epidemiolÃ³gicas ou melhorias na vigilÃ¢ncia
        
        ##### ğŸ“ˆ **Taxa de Ataque Atual: {taxa_ataque_geral:.1f}/100k habitantes**
        - **Baixa:** < 1,0/100k (situaÃ§Ã£o controlada)
        - **Moderada:** 1,0-5,0/100k (vigilÃ¢ncia necessÃ¡ria)
        - **Alta:** > 5,0/100k (situaÃ§Ã£o de alerta)
        - **ClassificaÃ§Ã£o atual:** {"Baixa - situaÃ§Ã£o controlada" if taxa_ataque_geral < 1.0 else "Moderada - vigilÃ¢ncia necessÃ¡ria" if taxa_ataque_geral < 5.0 else "Alta - situaÃ§Ã£o de alerta"}
        
        ##### ğŸŒ **Contexto EpidemiolÃ³gico:**
        - **OMS recomenda:** Taxa < 2,0/100k como meta de controle
        - **PaÃ­ses desenvolvidos:** Geralmente < 1,0/100k
        - **Imunidade coletiva:** Taxa diminui com alta cobertura vacinal
        - **VigilÃ¢ncia epidemiolÃ³gica:** Monitoramento contÃ­nuo Ã© essencial
        """)
        
        # AnÃ¡lise de forÃ§a de infecÃ§Ã£o
        st.subheader("ğŸ¦  **AnÃ¡lise de ForÃ§a de InfecÃ§Ã£o**")
        
        # Calcular forÃ§a de infecÃ§Ã£o (simulado)
        # ForÃ§a de infecÃ§Ã£o = -ln(1 - taxa de ataque)
        taxa_ataque_anual['Forca_Infeccao'] = -np.log(1 - (taxa_ataque_anual['Taxa_Ataque'] / 100000))
        
        # GrÃ¡fico de forÃ§a de infecÃ§Ã£o
        fig_forca_infeccao = px.line(
            taxa_ataque_anual,
            x='Ano',
            y='Forca_Infeccao',
            title="ForÃ§a de InfecÃ§Ã£o de Meningite por Ano",
            markers=True,
            line_shape='linear'
        )
        
        fig_forca_infeccao.update_layout(
            xaxis_title="Ano",
            yaxis_title="ForÃ§a de InfecÃ§Ã£o",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_forca_infeccao, use_container_width=True)
        
        # ExplicaÃ§Ã£o da forÃ§a de infecÃ§Ã£o
        st.markdown("""
        #### ğŸ“š **ExplicaÃ§Ã£o da ForÃ§a de InfecÃ§Ã£o:**
        
        ##### ğŸ¦  **O que Ã© ForÃ§a de InfecÃ§Ã£o:**
        - **DefiniÃ§Ã£o:** Taxa instantÃ¢nea na qual indivÃ­duos suscetÃ­veis adquirem infecÃ§Ã£o
        - **FÃ³rmula:** Î» = -ln(1 - taxa de ataque)
        - **InterpretaÃ§Ã£o:** Intensidade da transmissÃ£o da doenÃ§a na populaÃ§Ã£o
        - **Unidade:** Por unidade de tempo (geralmente por ano)
        
        ##### ğŸ“Š **InterpretaÃ§Ã£o do GrÃ¡fico:**
        - **Eixo X:** Anos do perÃ­odo analisado
        - **Eixo Y:** ForÃ§a de infecÃ§Ã£o (Î»)
        - **Linha:** Intensidade da transmissÃ£o ao longo do tempo
        - **Valores altos:** Maior intensidade de transmissÃ£o
        - **Valores baixos:** Menor intensidade de transmissÃ£o
        
        ##### ğŸ”¬ **ImportÃ¢ncia EpidemiolÃ³gica:**
        - **Modelagem matemÃ¡tica:** Base para modelos de transmissÃ£o
        - **Planejamento de intervenÃ§Ãµes:** Identifica perÃ­odos de alta transmissÃ£o
        - **AvaliaÃ§Ã£o de controle:** Monitora eficÃ¡cia das medidas de prevenÃ§Ã£o
        - **ComparaÃ§Ã£o temporal:** Permite comparar diferentes perÃ­odos epidemiolÃ³gicos
        """)
        
        # AnÃ¡lise de sazonalidade da taxa de ataque usando SIH (dados reais)
        st.subheader("ğŸ“… **Sazonalidade da Taxa de Ataque (SIH)**")
        if 'sih_meningite' in dados and isinstance(dados['sih_meningite'], pd.DataFrame):
            sih = dados['sih_meningite'].copy()
            if {'MÃªs_Num', 'Casos_Hospitalares'}.issubset(sih.columns):
                sih['Casos_Hospitalares'] = pd.to_numeric(sih['Casos_Hospitalares'], errors='coerce').fillna(0)
                mensal = sih.groupby('MÃªs_Num', as_index=False)['Casos_Hospitalares'].sum()
                # Nome dos meses na ordem
                nomes_meses = {1:'Jan',2:'Fev',3:'Mar',4:'Abr',5:'Mai',6:'Jun',7:'Jul',8:'Ago',9:'Set',10:'Out',11:'Nov',12:'Dez'}
                mensal['Mes'] = mensal['MÃªs_Num'].map(nomes_meses)
                # Base populacional: usar mediana das populaÃ§Ãµes anuais calculadas
                pop_base = float(taxa_ataque_anual['Populacao'].median()) if 'Populacao' in taxa_ataque_anual.columns else 214_000_000.0
                mensal['Taxa_Ataque_Mensal'] = (mensal['Casos_Hospitalares'] / pop_base) * 100000
                mensal = mensal.sort_values('MÃªs_Num')

                fig_sazonal = px.bar(
                    mensal,
                    x='Mes',
                    y='Taxa_Ataque_Mensal',
                    title='Sazonalidade da Taxa de Ataque (HospitalizaÃ§Ãµes SIH)',
                    color='Taxa_Ataque_Mensal',
                    color_continuous_scale='Reds'
                )
                fig_sazonal.update_layout(
                    xaxis_title='MÃªs',
                    yaxis_title='Taxa de Ataque (por 100.000 hab.)',
                    template='plotly_white'
                )
                st.plotly_chart(fig_sazonal, use_container_width=True)
                
                # ExplicaÃ§Ã£o do grÃ¡fico de sazonalidade
                st.markdown("""
                #### ğŸ“– **InterpretaÃ§Ã£o da Sazonalidade da Taxa de Ataque:**
                - **Eixo X:** Meses do ano (Jan a Dez)
                - **Eixo Y:** Taxa de ataque mensal por 100.000 habitantes
                - **Barras coloridas:** Intensidade da cor reflete a magnitude da taxa
                - **Dados:** Baseados em hospitalizaÃ§Ãµes do SIH (proxy para casos graves)
                
                ##### ğŸŒ¡ï¸ **PadrÃµes Sazonais Esperados:**
                - **Inverno (Jun-Ago):** Maior incidÃªncia devido a:
                  - AglomeraÃ§Ã£o em ambientes fechados
                  - ReduÃ§Ã£o da umidade relativa
                  - Menor ventilaÃ§Ã£o
                - **VerÃ£o (Dez-Fev):** Menor incidÃªncia devido a:
                  - Maior dispersÃ£o populacional
                  - Melhor ventilaÃ§Ã£o dos ambientes
                  - CondiÃ§Ãµes climÃ¡ticas desfavorÃ¡veis ao patÃ³geno
                
                ##### ğŸ“Š **Utilidade da AnÃ¡lise:**
                - **Planejamento de recursos:** Antecipar picos de demanda hospitalar
                - **Campanhas preventivas:** Intensificar aÃ§Ãµes nos meses de risco
                - **VigilÃ¢ncia epidemiolÃ³gica:** Monitoramento direcionado
                - **PolÃ­ticas de saÃºde:** AdequaÃ§Ã£o de estratÃ©gias por perÃ­odo
                """)
            else:
                st.info("â„¹ï¸ Estrutura de SIH nÃ£o possui colunas esperadas para sazonalidade (MÃªs_Num, Casos_Hospitalares)")
        else:
            st.info("â„¹ï¸ Dados SIH nÃ£o encontrados para anÃ¡lise sazonal")
        
        # AnÃ¡lise de correlaÃ§Ã£o entre taxa de ataque e letalidade
        st.subheader("ğŸ”— **CorrelaÃ§Ã£o Taxa de Ataque vs Letalidade**")
        
        if 'Taxa_Letalidade' in taxa_ataque_anual.columns:
            # Calcular correlaÃ§Ã£o
            correlacao = taxa_ataque_anual['Taxa_Ataque'].corr(taxa_ataque_anual['Taxa_Letalidade'])
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("ğŸ“Š CorrelaÃ§Ã£o", f"{correlacao:.3f}")
                
                if abs(correlacao) > 0.7:
                    st.success("ğŸ”— **Forte correlaÃ§Ã£o**")
                elif abs(correlacao) > 0.3:
                    st.info("ğŸ”— **CorrelaÃ§Ã£o moderada**")
                else:
                    st.warning("ğŸ”— **CorrelaÃ§Ã£o fraca**")
            
            with col2:
                # GrÃ¡fico de dispersÃ£o
                fig_correlacao = px.scatter(
                    taxa_ataque_anual,
                    x='Taxa_Ataque',
                    y='Taxa_Letalidade',
                    title="CorrelaÃ§Ã£o: Taxa de Ataque vs Letalidade"
                )
                
                # Adicionar linha de tendÃªncia manual usando numpy
                if len(taxa_ataque_anual) > 1:
                    x_vals = taxa_ataque_anual['Taxa_Ataque'].values
                    y_vals = taxa_ataque_anual['Taxa_Letalidade'].values
                    
                    # Remover NaN values
                    mask = ~(np.isnan(x_vals) | np.isnan(y_vals))
                    x_clean = x_vals[mask]
                    y_clean = y_vals[mask]
                    
                    if len(x_clean) > 1:
                        # Calcular regressÃ£o linear usando numpy
                        coeffs = np.polyfit(x_clean, y_clean, 1)
                        x_trend = np.linspace(x_clean.min(), x_clean.max(), 100)
                        y_trend = coeffs[0] * x_trend + coeffs[1]
                        
                        # Adicionar linha de tendÃªncia
                        fig_correlacao.add_trace(go.Scatter(
                            x=x_trend,
                            y=y_trend,
                            mode='lines',
                            name='Linha de TendÃªncia',
                            line=dict(color='red', dash='dash')
                        ))
                
                fig_correlacao.update_layout(
                    xaxis_title="Taxa de Ataque (por 100.000 habitantes)",
                    yaxis_title="Taxa de Letalidade (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_correlacao, use_container_width=True)
                
                # ExplicaÃ§Ã£o da correlaÃ§Ã£o taxa de ataque vs letalidade
                st.markdown(f"""
                #### ğŸ“š **ExplicaÃ§Ã£o da CorrelaÃ§Ã£o Taxa de Ataque vs Letalidade:**
                
                ##### ğŸ“Š **CorrelaÃ§Ã£o de Pearson = {correlacao:.3f}**
                - **O que mede:** RelaÃ§Ã£o linear entre incidÃªncia e gravidade da doenÃ§a
                - **InterpretaÃ§Ã£o:**
                  - **CorrelaÃ§Ã£o positiva:** Maior incidÃªncia associada a maior letalidade
                  - **CorrelaÃ§Ã£o negativa:** Maior incidÃªncia associada a menor letalidade
                  - **Sem correlaÃ§Ã£o:** IncidÃªncia e letalidade independentes
                
                ##### ğŸ“– **InterpretaÃ§Ã£o do GrÃ¡fico:**
                - **Eixo X:** Taxa de ataque (incidÃªncia por 100.000 hab.)
                - **Eixo Y:** Taxa de letalidade (%)
                - **Pontos:** Cada ponto representa um ano especÃ­fico
                - **Linha tracejada:** TendÃªncia linear da relaÃ§Ã£o
                
                ##### ğŸ”¬ **Significado EpidemiolÃ³gico:**
                - **CorrelaÃ§Ã£o positiva pode indicar:**
                  - Surtos com cepas mais virulentas
                  - Sobrecarregamento do sistema de saÃºde
                  - DiagnÃ³stico tardio em perÃ­odos de alta incidÃªncia
                  
                - **CorrelaÃ§Ã£o negativa pode indicar:**
                  - Melhoria na detecÃ§Ã£o precoce
                  - Aumento de casos leves diagnosticados
                  - Efeito de diluiÃ§Ã£o com mais casos benignos
                  
                - **AusÃªncia de correlaÃ§Ã£o pode indicar:**
                  - Letalidade constante independente da incidÃªncia
                  - Qualidade consistente do atendimento mÃ©dico
                  - DistribuiÃ§Ã£o uniforme da virulÃªncia das cepas
                
                ##### ğŸ¯ **ClassificaÃ§Ã£o Atual: {"Forte" if abs(correlacao) > 0.7 else "Moderada" if abs(correlacao) > 0.3 else "Fraca"}**
                - **Fraca:** |r| < 0.3 - RelaÃ§Ã£o pouco evidente
                - **Moderada:** 0.3 â‰¤ |r| < 0.7 - RelaÃ§Ã£o moderada
                - **Forte:** |r| â‰¥ 0.7 - RelaÃ§Ã£o bem definida
                """)
        else:
            st.info("â„¹ï¸ Dados de letalidade nÃ£o disponÃ­veis para anÃ¡lise de correlaÃ§Ã£o")
        
        # Resumo estatÃ­stico
        st.subheader("ğŸ“‹ **Resumo EstatÃ­stico**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**EstatÃ­sticas da Taxa de Ataque:**")
            st.dataframe(taxa_ataque_anual['Taxa_Ataque'].describe())
        
        with col2:
            st.write("**Dados de Taxa de Ataque por Ano:**")
            st.dataframe(taxa_ataque_anual[['Ano', 'Taxa_Ataque', 'Forca_Infeccao']].round(4))
        
        # InformaÃ§Ãµes sobre a anÃ¡lise
        st.subheader("â„¹ï¸ **Sobre a AnÃ¡lise de Taxa de Ataque**")
        st.markdown("""
        **Esta anÃ¡lise mostra:**
        - Taxa de ataque por ano (casos por 100.000 habitantes)
        - ForÃ§a de infecÃ§Ã£o ao longo do tempo
        - PadrÃµes sazonais da doenÃ§a
        - CorrelaÃ§Ã£o entre incidÃªncia e letalidade
        
        **ImportÃ¢ncia:**
        - Medir o risco populacional
        - Identificar perÃ­odos de maior risco
        - Planejar aÃ§Ãµes de prevenÃ§Ã£o
        - Avaliar efetividade de intervenÃ§Ãµes
        """)
    else:
        st.warning("âš ï¸ Dados de casos nÃ£o disponÃ­veis")

def show_free_exploration(dados):
    """Exibe a seÃ§Ã£o "ExploraÃ§Ã£o Livre dos Dados".

    Cria uma interface interativa que permite ao usuÃ¡rio selecionar qualquer um dos
    datasets carregados, visualizar suas informaÃ§Ãµes (linhas, colunas, tipos de dados,
    valores nulos), analisar colunas individuais com histogramas e grÃ¡ficos de barras,
    e explorar correlaÃ§Ãµes. Oferece tambÃ©m filtros personalizados e a opÃ§Ã£o de
    fazer o download dos dados filtrados.

    Args:
        dados (dict): O dicionÃ¡rio global contendo todos os DataFrames disponÃ­veis
                      para exploraÃ§Ã£o.
    """
    st.header("ğŸ” **ExploraÃ§Ã£o Livre dos Dados**")
    st.markdown("---")
    
    if dados:
        st.info("ğŸ’¡ **Use esta seÃ§Ã£o para explorar os dados de forma personalizada**")
        
        # SeleÃ§Ã£o de dados
        st.subheader("ğŸ“Š **SeleÃ§Ã£o de Dados**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            datasets_disponiveis = list(dados.keys())
            dataset_selecionado = st.selectbox(
                "Selecione o Dataset:",
                datasets_disponiveis,
                help="Escolha qual conjunto de dados analisar"
            )
        
        with col2:
            if dataset_selecionado:
                dataset = dados[dataset_selecionado]
                if isinstance(dataset, pd.DataFrame):
                    st.metric("ğŸ“ˆ Linhas", len(dataset))
                    st.metric("ğŸ“‹ Colunas", len(dataset.columns))
        
        # VisualizaÃ§Ã£o dos dados
        if dataset_selecionado and dataset_selecionado in dados:
            dataset = dados[dataset_selecionado]
            
            if isinstance(dataset, pd.DataFrame):
                st.subheader("ğŸ“‹ **VisualizaÃ§Ã£o dos Dados**")
                
                # Mostrar primeiras linhas
                st.write("**Primeiras 10 linhas:**")
                st.dataframe(dataset.head(10))
                
                # InformaÃ§Ãµes do dataset
                st.write("**InformaÃ§Ãµes do Dataset:**")
                buffer = st.empty()
                
                if st.button("ğŸ“Š Mostrar InformaÃ§Ãµes"):
                    with buffer.container():
                        st.write(f"**Forma:** {dataset.shape}")
                        st.write(f"**Tipos de dados:**")
                        st.write(dataset.dtypes)
                        st.write(f"**Valores nulos:**")
                        st.write(dataset.isnull().sum())
                        st.write(f"**EstatÃ­sticas descritivas:**")
                        st.write(dataset.describe())
                
                # AnÃ¡lise de colunas
                st.subheader("ğŸ” **AnÃ¡lise de Colunas**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    colunas_numericas = dataset.select_dtypes(include=[np.number]).columns.tolist()
                    if colunas_numericas:
                        coluna_analise = st.selectbox(
                            "Selecione uma coluna numÃ©rica:",
                            colunas_numericas
                        )
                        
                        if coluna_analise:
                            # Histograma
                            fig_hist = px.histogram(
                                dataset,
                                x=coluna_analise,
                                title=f"DistribuiÃ§Ã£o de {coluna_analise}",
                                nbins=20
                            )
                            fig_hist.update_layout(template='plotly_white')
                            st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    colunas_categoricas = dataset.select_dtypes(include=['object']).columns.tolist()
                    if colunas_categoricas:
                        coluna_cat = st.selectbox(
                            "Selecione uma coluna categÃ³rica:",
                            colunas_categoricas
                        )
                        
                        if coluna_cat:
                            # Contagem de valores
                            contagem = dataset[coluna_cat].value_counts().head(10)
                            fig_bar = px.bar(
                                x=contagem.index,
                                y=contagem.values,
                                title=f"Top 10 valores de {coluna_cat}"
                            )
                            fig_bar.update_layout(
                                xaxis_title=coluna_cat,
                                yaxis_title="Contagem",
                                template='plotly_white'
                            )
                            st.plotly_chart(fig_bar, use_container_width=True)
                
                # AnÃ¡lise de correlaÃ§Ã£o
                if len(colunas_numericas) > 1:
                    st.subheader("ğŸ”— **AnÃ¡lise de CorrelaÃ§Ã£o**")
                    
                    # SeleÃ§Ã£o de colunas para correlaÃ§Ã£o
                    colunas_correlacao = st.multiselect(
                        "Selecione colunas para anÃ¡lise de correlaÃ§Ã£o:",
                        colunas_numericas,
                        default=colunas_numericas[:5] if len(colunas_numericas) >= 5 else colunas_numericas
                    )
                    
                    if len(colunas_correlacao) > 1:
                        # Calcular correlaÃ§Ã£o
                        correlacao = dataset[colunas_correlacao].corr()
                        
                        # Heatmap de correlaÃ§Ã£o
                        fig_corr = px.imshow(
                            correlacao,
                            title="Matriz de CorrelaÃ§Ã£o",
                            color_continuous_scale='RdBu',
                            aspect='auto'
                        )
                        fig_corr.update_layout(template='plotly_white')
                        st.plotly_chart(fig_corr, use_container_width=True)
                        
                        # Tabela de correlaÃ§Ã£o
                        st.write("**Matriz de CorrelaÃ§Ã£o:**")
                        st.dataframe(correlacao.round(3))
                
                # Filtros personalizados
                st.subheader("ğŸ”§ **Filtros Personalizados**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if colunas_numericas:
                        coluna_filtro = st.selectbox(
                            "Coluna para filtro:",
                            colunas_numericas
                        )
                        
                        if coluna_filtro:
                            valor_min = float(dataset[coluna_filtro].min())
                            valor_max = float(dataset[coluna_filtro].max())

                            # Garantir intervalo vÃ¡lido para o slider
                            if valor_min == valor_max:
                                # Expande um pouco o range para evitar erro do Streamlit
                                valor_min_adj = valor_min - 1.0
                                valor_max_adj = valor_max + 1.0
                                default_range = (valor_min_adj, valor_max_adj)
                            else:
                                valor_min_adj = valor_min
                                valor_max_adj = valor_max
                                default_range = (valor_min, valor_max)

                            filtro_min, filtro_max = st.slider(
                                f"Faixa de {coluna_filtro}:",
                                min_value=valor_min_adj,
                                max_value=valor_max_adj,
                                value=default_range
                            )
                
                with col2:
                    if colunas_categoricas:
                        coluna_cat_filtro = st.selectbox(
                            "Coluna categÃ³rica para filtro:",
                            colunas_categoricas
                        )
                        
                        if coluna_cat_filtro:
                            valores_unicos = dataset[coluna_cat_filtro].unique()
                            valores_selecionados = st.multiselect(
                                f"Valores de {coluna_cat_filtro}:",
                                valores_unicos,
                                default=valores_unicos[:5] if len(valores_unicos) >= 5 else valores_unicos
                            )
                
                # Aplicar filtros
                if st.button("ğŸ” Aplicar Filtros"):
                    dataset_filtrado = dataset.copy()
                    
                    if 'coluna_filtro' in locals() and 'filtro_min' in locals() and 'filtro_max' in locals():
                        dataset_filtrado = dataset_filtrado[
                            (dataset_filtrado[coluna_filtro] >= filtro_min) &
                            (dataset_filtrado[coluna_filtro] <= filtro_max)
                        ]
                    
                    if 'coluna_cat_filtro' in locals() and 'valores_selecionados' in locals():
                        dataset_filtrado = dataset_filtrado[
                            dataset_filtrado[coluna_cat_filtro].isin(valores_selecionados)
                        ]
                    
                    st.success(f"âœ… Filtros aplicados! Dataset filtrado: {dataset_filtrado.shape}")
                    st.write("**Dados filtrados:**")
                    st.dataframe(dataset_filtrado.head(10))
                    
                    # Download dos dados filtrados
                    csv_filtrado = dataset_filtrado.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ Download dos Dados Filtrados (CSV)",
                        data=csv_filtrado,
                        file_name=f"{dataset_selecionado}_filtrado.csv",
                        mime="text/csv"
                    )
                
                # EstatÃ­sticas personalizadas
                st.subheader("ğŸ“Š **EstatÃ­sticas Personalizadas**")
                
                if st.button("ğŸ“ˆ Calcular EstatÃ­sticas"):
                    with st.spinner("Calculando estatÃ­sticas..."):
                        # EstatÃ­sticas gerais
                        st.write("**EstatÃ­sticas Gerais:**")
                        st.write(f"Total de registros: {len(dataset)}")
                        st.write(f"Total de colunas: {len(dataset.columns)}")
                        st.write(f"MemÃ³ria utilizada: {dataset.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
                        
                        # EstatÃ­sticas por tipo de coluna
                        st.write("**EstatÃ­sticas por Tipo de Coluna:**")
                        for dtype in dataset.dtypes.unique():
                            colunas_tipo = dataset.select_dtypes(include=[dtype]).columns
                            st.write(f"- {dtype}: {len(colunas_tipo)} colunas")
                        
                        # Valores Ãºnicos por coluna
                        st.write("**Valores Ãšnicos por Coluna:**")
                        for col in dataset.columns:
                            if dataset[col].dtype == 'object':
                                valores_unicos = dataset[col].nunique()
                                st.write(f"- {col}: {valores_unicos} valores Ãºnicos")
        
        else:
            st.warning("âš ï¸ Selecione um dataset vÃ¡lido para comeÃ§ar a exploraÃ§Ã£o")
        
        # Resumo da exploraÃ§Ã£o livre
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Funcionalidades da ExploraÃ§Ã£o Livre:**
        
        **1. VisualizaÃ§Ã£o de Dados:**
        - SeleÃ§Ã£o de datasets
        - VisualizaÃ§Ã£o de primeiras linhas
        - InformaÃ§Ãµes sobre estrutura dos dados
        
        **2. AnÃ¡lise ExploratÃ³ria:**
        - Histogramas para variÃ¡veis numÃ©ricas
        - GrÃ¡ficos de barras para variÃ¡veis categÃ³ricas
        - AnÃ¡lise de correlaÃ§Ã£o
        
        **3. Filtros Personalizados:**
        - Filtros por faixa de valores
        - Filtros por valores categÃ³ricos
        - Download de dados filtrados
        
        **4. EstatÃ­sticas Personalizadas:**
        - EstatÃ­sticas descritivas
        - InformaÃ§Ãµes sobre tipos de dados
        - AnÃ¡lise de valores Ãºnicos
        """)
        
    else:
        st.error("âŒ Nenhum dado disponÃ­vel para exploraÃ§Ã£o")

def show_reports(dados):
    """Exibe a seÃ§Ã£o "RelatÃ³rios e Downloads".

    Esta funÃ§Ã£o oferece ferramentas para que o usuÃ¡rio possa gerar e baixar
    informaÃ§Ãµes consolidadas. Ela permite a criaÃ§Ã£o de relatÃ³rios automÃ¡ticos
    (de casos, imunizaÃ§Ã£o, sorogrupos), o download dos principais datasets em
    formato CSV, e a geraÃ§Ã£o de relatÃ³rios personalizados com seleÃ§Ã£o de
    datasets, perÃ­odo e tipo de relatÃ³rio.

    Args:
        dados (dict): O dicionÃ¡rio global de dados, usado para gerar os relatÃ³rios
                      e fornecer os arquivos para download.
    """
    st.header("ğŸ“‹ **RelatÃ³rios e Downloads**")
    st.markdown("---")
    
    if dados:
        st.info("ğŸ’¡ **Gere relatÃ³rios personalizados e faÃ§a download dos dados**")
        
        # RelatÃ³rios automÃ¡ticos
        st.subheader("ğŸ“Š **RelatÃ³rios AutomÃ¡ticos**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ“ˆ RelatÃ³rio de Casos"):
                with st.spinner("Gerando relatÃ³rio de casos..."):
                    if 'casos_2017_2022' in dados:
                        casos = dados['casos_2017_2022']
                        
                        # Resumo de casos
                        total_casos = casos['Casos_Notificados'].sum()
                        total_obitos = casos['Ã“bitos'].sum()
                        media_casos_ano = casos.groupby('Ano')['Casos_Notificados'].sum().mean()
                        media_obitos_ano = casos.groupby('Ano')['Ã“bitos'].sum().mean()
                        
                        # Criar relatÃ³rio
                        relatorio_casos = f"""
                        # RELATÃ“RIO DE CASOS DE MENINGITE (2017-2022)
                        
                        ## Resumo Executivo
                        - **Total de Casos:** {total_casos:,}
                        - **Total de Ã“bitos:** {total_obitos:,}
                        - **MÃ©dia Anual de Casos:** {media_casos_ano:.0f}
                        - **MÃ©dia Anual de Ã“bitos:** {media_obitos_ano:.0f}
                        
                        ## AnÃ¡lise por Ano
                        """
                        
                        # Adicionar dados por ano
                        casos_por_ano = casos.groupby('Ano').agg({
                            'Casos_Notificados': 'sum',
                            'Ã“bitos': 'sum'
                        }).reset_index()
                        
                        for _, row in casos_por_ano.iterrows():
                            relatorio_casos += f"\n- **{row['Ano']}:** {row['Casos_Notificados']:,} casos, {row['Ã“bitos']:,} Ã³bitos"
                        
                        # Download do relatÃ³rio
                        st.download_button(
                            label="ğŸ“¥ Download RelatÃ³rio de Casos (MD)",
                            data=relatorio_casos,
                            file_name="relatorio_casos_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("âœ… RelatÃ³rio de casos gerado com sucesso!")
                    else:
                        st.error("âŒ Dados de casos nÃ£o disponÃ­veis")
        
        with col2:
            if st.button("ğŸ’‰ RelatÃ³rio de ImunizaÃ§Ã£o"):
                with st.spinner("Gerando relatÃ³rio de imunizaÃ§Ã£o..."):
                    if 'imunizacao_ano' in dados:
                        imunizacao = dados['imunizacao_ano']
                        
                        # Resumo de imunizaÃ§Ã£o
                        total_doses = imunizacao['Total_Doses'].sum()
                        media_doses_ano = imunizacao['Total_Doses'].mean()
                        periodo_cobertura = f"{imunizacao['Ano'].min()}-{imunizacao['Ano'].max()}"
                        
                        # Criar relatÃ³rio
                        relatorio_imunizacao = f"""
                        # RELATÃ“RIO DE IMUNIZAÃ‡ÃƒO (1994-2022)
                        
                        ## Resumo Executivo
                        - **Total de Doses:** {total_doses:,}
                        - **MÃ©dia Anual:** {media_doses_ano:.0f} doses
                        - **PerÃ­odo de Cobertura:** {periodo_cobertura}
                        
                        ## EvoluÃ§Ã£o Temporal
                        """
                        
                        # Adicionar dados por ano
                        for _, row in imunizacao.iterrows():
                            relatorio_imunizacao += f"\n- **{row['Ano']}:** {row['Total_Doses']:,} doses"
                        
                        # Download do relatÃ³rio
                        st.download_button(
                            label="ğŸ“¥ Download RelatÃ³rio de ImunizaÃ§Ã£o (MD)",
                            data=relatorio_imunizacao,
                            file_name="relatorio_imunizacao_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("âœ… RelatÃ³rio de imunizaÃ§Ã£o gerado com sucesso!")
                    else:
                        st.error("âŒ Dados de imunizaÃ§Ã£o nÃ£o disponÃ­veis")
        
        with col3:
            if st.button("ğŸ¦  RelatÃ³rio de Sorogrupos"):
                with st.spinner("Gerando relatÃ³rio de sorogrupos..."):
                    if 'sorogrupos_consolidados' in dados:
                        sorogrupos = dados['sorogrupos_consolidados']
                        
                        # Resumo de sorogrupos
                        total_sorogrupos = len(sorogrupos)
                        periodo_sorogrupos = f"{sorogrupos['Ano'].min()}-{sorogrupos['Ano'].max()}"
                        
                        # Criar relatÃ³rio
                        relatorio_sorogrupos = f"""
                        # RELATÃ“RIO DE SOROGRUPOS (2007-2024)
                        
                        ## Resumo Executivo
                        - **Total de Sorogrupos:** {total_sorogrupos}
                        - **PerÃ­odo de AnÃ¡lise:** {periodo_sorogrupos}
                        
                        ## Principais Sorogrupos
                        """
                        
                        # Adicionar dados de sorogrupos
                        for _, row in sorogrupos.head(10).iterrows():
                            relatorio_sorogrupos += f"\n- **{row['Sorogrupo']} ({row['Ano']}):** {row['Casos']:,} casos"
                        
                        # Download do relatÃ³rio
                        st.download_button(
                            label="ğŸ“¥ Download RelatÃ³rio de Sorogrupos (MD)",
                            data=relatorio_sorogrupos,
                            file_name="relatorio_sorogrupos_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("âœ… RelatÃ³rio de sorogrupos gerado com sucesso!")
                    else:
                        st.error("âŒ Dados de sorogrupos nÃ£o disponÃ­veis")
        
        # Downloads de dados
        st.subheader("ğŸ“¥ **Downloads de Dados**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“Š Datasets Principais:**")
            
            # Lista de datasets para download
            datasets_download = [
                ('casos_consolidados', 'Casos Consolidados (2017-2024)'),
                ('sorogrupos_consolidados', 'Sorogrupos Consolidados (2007-2024)'),
                ('etiologias_consolidadas', 'Etiologias Consolidadas (2007-2024)'),
                ('imunizacao_ano', 'ImunizaÃ§Ã£o por Ano (1994-2022)'),
                ('imunizacao_uf', 'ImunizaÃ§Ã£o por UF'),
                ('imunizacao_faixa_etaria', 'ImunizaÃ§Ã£o por Faixa EtÃ¡ria')
            ]
            
            for key, nome in datasets_download:
                if key in dados and isinstance(dados[key], pd.DataFrame):
                    csv_data = dados[key].to_csv(index=False)
                    st.download_button(
                        label=f"ğŸ“¥ {nome}",
                        data=csv_data,
                        file_name=f"{key}.csv",
                        mime="text/csv"
                    )
        
        with col2:
            st.write("**ğŸ”¬ AnÃ¡lises Especializadas:**")
            
            # AnÃ¡lises especializadas
            if 'analise_regional' in dados:
                csv_regional = dados['analise_regional'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ AnÃ¡lise Regional",
                    data=csv_regional,
                    file_name="analise_regional.csv",
                    mime="text/csv"
                )
            
            if 'matriz_correlacao' in dados:
                csv_correlacao = dados['matriz_correlacao'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ Matriz de CorrelaÃ§Ã£o",
                    data=csv_correlacao,
                    file_name="matriz_correlacao.csv",
                    mime="text/csv"
                )
            
            if 'analise_temporal' in dados:
                csv_temporal = dados['analise_temporal'].to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ AnÃ¡lise Temporal",
                    data=csv_temporal,
                    file_name="analise_temporal.csv",
                    mime="text/csv"
                )
        
        # RelatÃ³rio personalizado
        st.subheader("âœï¸ **RelatÃ³rio Personalizado**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # SeleÃ§Ã£o de datasets para o relatÃ³rio
            datasets_relatorio = st.multiselect(
                "Selecione datasets para incluir no relatÃ³rio:",
                list(dados.keys()),
                default=list(dados.keys())[:5]
            )
            
            # Tipo de relatÃ³rio
            tipo_relatorio = st.selectbox(
                "Tipo de relatÃ³rio:",
                ["Resumo Executivo", "RelatÃ³rio Detalhado", "RelatÃ³rio TÃ©cnico"]
            )
        
        with col2:
            # PerÃ­odo do relatÃ³rio
            ano_inicio = st.number_input("Ano de inÃ­cio:", min_value=1990, max_value=2024, value=2017)
            ano_fim = st.number_input("Ano de fim:", min_value=1990, max_value=2024, value=2024)
            
            # Incluir grÃ¡ficos
            incluir_graficos = st.checkbox("Incluir grÃ¡ficos (HTML)", value=True)
        
        # Gerar relatÃ³rio personalizado
        if st.button("ğŸ“‹ Gerar RelatÃ³rio Personalizado"):
            with st.spinner("Gerando relatÃ³rio personalizado..."):
                try:
                    # Criar relatÃ³rio personalizado
                    relatorio_personalizado = f"""
                    # RELATÃ“RIO PERSONALIZADO DE MENINGITE BRASIL
                    
                    ## InformaÃ§Ãµes Gerais
                    - **Tipo:** {tipo_relatorio}
                    - **PerÃ­odo:** {ano_inicio}-{ano_fim}
                    - **Datasets incluÃ­dos:** {len(datasets_relatorio)}
                    - **Data de geraÃ§Ã£o:** {datetime.now().strftime('%d/%m/%Y %H:%M')}
                    
                    ## Datasets Analisados
                    """
                    
                    for dataset in datasets_relatorio:
                        if dataset in dados and isinstance(dados[dataset], pd.DataFrame):
                            df = dados[dataset]
                            relatorio_personalizado += f"""
                            
                            ### {dataset.replace('_', ' ').title()}
                            - **Forma:** {df.shape[0]} linhas Ã— {df.shape[1]} colunas
                            - **Colunas:** {', '.join(df.columns.tolist())}
                            - **PerÃ­odo:** {df.select_dtypes(include=[np.number]).min().min() if df.select_dtypes(include=[np.number]).shape[1] > 0 else 'N/A'} - {df.select_dtypes(include=[np.number]).max().max() if df.select_dtypes(include=[np.number]).shape[1] > 0 else 'N/A'}
                            """
                    
                    # Adicionar resumo estatÃ­stico
                    relatorio_personalizado += """
                    
                    ## Resumo EstatÃ­stico
                    """
                    
                    for dataset in datasets_relatorio:
                        if dataset in dados and isinstance(dados[dataset], pd.DataFrame):
                            df = dados[dataset]
                            colunas_numericas = df.select_dtypes(include=[np.number]).columns
                            if len(colunas_numericas) > 0:
                                relatorio_personalizado += f"""
                                
                                ### {dataset.replace('_', ' ').title()}
                                """
                                for col in colunas_numericas[:5]:  # Limitar a 5 colunas
                                    stats = df[col].describe()
                                    relatorio_personalizado += f"""
                                    **{col}:**
                                    - MÃ©dia: {stats['mean']:.2f}
                                    - Mediana: {stats['50%']:.2f}
                                    - Desvio padrÃ£o: {stats['std']:.2f}
                                    - MÃ­nimo: {stats['min']:.2f}
                                    - MÃ¡ximo: {stats['max']:.2f}
                                    """
                    
                    # Download do relatÃ³rio
                    st.download_button(
                        label="ğŸ“¥ Download RelatÃ³rio Personalizado (MD)",
                        data=relatorio_personalizado,
                        file_name=f"relatorio_personalizado_{ano_inicio}_{ano_fim}.md",
                        mime="text/markdown"
                    )
                    
                    st.success("âœ… RelatÃ³rio personalizado gerado com sucesso!")
                    
                except Exception as e:
                    st.error(f"âŒ Erro ao gerar relatÃ³rio: {e}")
        
        # Resumo dos relatÃ³rios
        st.markdown("---")
        st.markdown("""
        **ğŸ“‹ Funcionalidades de RelatÃ³rios:**
        
        **1. RelatÃ³rios AutomÃ¡ticos:**
        - RelatÃ³rio de casos (2017-2022)
        - RelatÃ³rio de imunizaÃ§Ã£o (1994-2022)
        - RelatÃ³rio de sorogrupos (2007-2024)
        
        **2. Downloads de Dados:**
        - Datasets principais em CSV
        - AnÃ¡lises especializadas
        - Dados processados
        
        **3. RelatÃ³rios Personalizados:**
        - SeleÃ§Ã£o de datasets
        - PerÃ­odo personalizado
        - Tipo de relatÃ³rio configurÃ¡vel
        - InclusÃ£o de grÃ¡ficos
        
        **4. Formatos DisponÃ­veis:**
        - Markdown (.md)
        - CSV (.csv)
        - HTML (grÃ¡ficos interativos)
        """)
        
    else:
        st.error("âŒ Nenhum dado disponÃ­vel para relatÃ³rios")

def show_technical_exposition(dados):
    """Exibe a seÃ§Ã£o "Expositivo TÃ©cnico - Arquitetura e Metodologia".

    Esta funÃ§Ã£o renderiza uma pÃ¡gina detalhada que serve como documentaÃ§Ã£o tÃ©cnica
    do sistema. Ela descreve a arquitetura de dados, o fluxo de automaÃ§Ã£o, a
    estrutura das tabelas, as metodologias estatÃ­sticas e de machine learning
    implementadas, as tecnologias de visualizaÃ§Ã£o, e as estratÃ©gias de otimizaÃ§Ã£o.
    TambÃ©m apresenta estatÃ­sticas ao vivo sobre os dados carregados.

    Args:
        dados (dict): O dicionÃ¡rio global de dados, usado para exibir estatÃ­sticas
                      em tempo real sobre os datasets carregados.
    """
    st.header("âš™ï¸ **Expositivo TÃ©cnico - Arquitetura e Metodologia**")
    st.markdown("---")
    
    # IntroduÃ§Ã£o
    st.markdown("""
    ## ğŸ¯ **VisÃ£o Geral do Sistema**
    
    Este dashboard representa um sistema completo de anÃ¡lise epidemiolÃ³gica de meningite no Brasil, 
    integrando coleta automatizada de dados, processamento estatÃ­stico avanÃ§ado e visualizaÃ§Ã£o interativa.
    """)
    
    # SeÃ§Ã£o 1: Arquitetura de Dados
    st.header("ğŸ—ï¸ **1. Arquitetura de Dados e AutomaÃ§Ã£o**")
    
    # Diagrama de fluxo de dados
    st.subheader("ğŸ“Š **Fluxo de Dados do Sistema**")
    
    # Criar diagrama Mermaid do fluxo de dados
    diagram_code = """
    graph TD
        A[APIs Oficiais<br/>DataSUS, SIPNI, SIH] --> B[Sistema de AutomaÃ§Ã£o<br/>Web Scraping + APIs]
        B --> C[ExtraÃ§Ã£o Automatizada<br/>Python + Requests]
        C --> D[ValidaÃ§Ã£o e Limpeza<br/>Pandas + NumPy]
        D --> E[Armazenamento<br/>Pasta TABELAS/*.csv]
        E --> F[Carregamento no Dashboard<br/>load_all_data()]
        F --> G[Processamento EstatÃ­stico<br/>SciPy + Scikit-learn]
        G --> H[VisualizaÃ§Ã£o Interativa<br/>Plotly + Streamlit]
        H --> I[Dashboard Final<br/>AnÃ¡lises EpidemiolÃ³gicas]
        
        style A fill:#e1f5fe
        style E fill:#f3e5f5
        style G fill:#e8f5e8
        style I fill:#fff3e0
    """
    
    st.markdown("#### ğŸ”„ **Diagrama de Fluxo de Dados:**")
    
    # Mostrar diagrama de fluxo como cÃ³digo
    st.code(diagram_code, language='mermaid')
    
    # ExplicaÃ§Ã£o detalhada da automaÃ§Ã£o
    st.markdown("""
    ### ğŸ¤– **Sistema de AutomaÃ§Ã£o de Dados**
    
    #### ğŸ“¡ **Fontes de Dados Oficiais:**
    - **DataSUS (DATASUS):** Sistema de InformaÃ§Ãµes em SaÃºde
    - **SIPNI:** Sistema de InformaÃ§Ãµes do Programa Nacional de ImunizaÃ§Ãµes  
    - **SIH:** Sistema de InformaÃ§Ãµes Hospitalares
    - **SINAN:** Sistema de InformaÃ§Ã£o de Agravos de NotificaÃ§Ã£o
    
    #### ğŸ”§ **Tecnologias de AutomaÃ§Ã£o Utilizadas:**
    
    **Python Libraries:**
    - `requests`: RequisiÃ§Ãµes HTTP para APIs
    - `beautifulsoup4`: Web scraping de pÃ¡ginas HTML
    - `selenium`: AutomaÃ§Ã£o de navegadores web
    - `pandas`: ManipulaÃ§Ã£o e anÃ¡lise de dados
    - `numpy`: ComputaÃ§Ã£o numÃ©rica
    
    **Processo Automatizado:**
    1. **Monitoramento**: Scripts verificam atualizaÃ§Ãµes nas fontes
    2. **ExtraÃ§Ã£o**: Dados sÃ£o coletados via APIs e web scraping
    3. **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de integridade e consistÃªncia
    4. **Limpeza**: RemoÃ§Ã£o de duplicatas e tratamento de missing values
    5. **PadronizaÃ§Ã£o**: FormataÃ§Ã£o uniforme das tabelas
    6. **Armazenamento**: Salvamento em formato CSV na pasta TABELAS/
    """)
    
    # SeÃ§Ã£o 2: Estrutura das Tabelas
    st.header("ğŸ“‹ **2. Estrutura e UtilizaÃ§Ã£o das Tabelas**")
    
    # Categorizar as tabelas por tipo
    st.subheader("ğŸ—‚ï¸ **CategorizaÃ§Ã£o das Tabelas de Dados**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### ğŸ“Š **Dados EpidemiolÃ³gicos:**
        - `casos_consolidados_2017_2024.csv`: Casos notificados agregados
        - `casos_notificados_2017_2022.csv`: Dados brutos de notificaÃ§Ã£o
        - `dados_gerais_2024.csv`: EstatÃ­sticas gerais do ano atual
        - `data_meninatu.csv`: Dados especÃ­ficos de meningite tuberculosa
        - `tabela_unificada.csv`: Base consolidada principal
        
        #### ğŸ¦  **Dados por Sorogrupo:**
        - `sorogrupos_2024.csv`: Sorogrupos do ano atual
        - `sorogrupos_consolidados_2007_2024.csv`: SÃ©rie histÃ³rica
        - `df_sorogrupos_2007_2020.csv`: Dados histÃ³ricos especÃ­ficos
        - `df_sorogrupos_2024.csv`: Dados processados 2024
        - `df_sorogrupos_completo.csv`: Base completa consolidada
        """)
    
    with col2:
        st.markdown("""
        #### ğŸ”¬ **Dados de Etiologia:**
        - `etiologia_2024.csv`: Etiologias identificadas
        - `etiologias_consolidadas_2007_2024.csv`: SÃ©rie temporal
        - `df_etiologia_2024.csv`: Dados processados
        - `bacterianas_2024.csv`: Meningites bacterianas
        - `df_bacterianas_2024.csv`: Dados bacterianos processados
        
        #### ğŸ’‰ **Dados de ImunizaÃ§Ã£o:**
        - `imunizacoesmenin.csv`: Dados brutos de vacinaÃ§Ã£o
        - `cleaned_imunizacoesmenin.csv`: Dados limpos
        - `imunizacoesmenin_fixed.csv`: Dados corrigidos
        - `dados_imunizacao_processados.csv`: Base processada
        - `imunobiologicosem2023a2025.csv`: ImunobiolÃ³gicos perÃ­odo
        """)
    
    # AnÃ¡lise especÃ­fica por tipo
    st.subheader("ğŸ” **AnÃ¡lise EspecÃ­fica por Categoria**")
    
    # Dados de hospitalizaÃ§Ã£o
    st.markdown("""
    #### ğŸ¥ **Dados Hospitalares (SIH):**
    - `sih_meningite_hospitalar.csv`: InternaÃ§Ãµes por meningite
    - `sih_meningite_long.csv`: Formato longo para anÃ¡lises temporais
    - `sih_meningite_wide.csv`: Formato largo para anÃ¡lises transversais
    
    **Tratamentos Aplicados:**
    - ConversÃ£o entre formatos long/wide para diferentes anÃ¡lises
    - CÃ¡lculo de taxas de hospitalizaÃ§Ã£o
    - AnÃ¡lise de sazonalidade nas internaÃ§Ãµes
    - CorrelaÃ§Ã£o com dados de notificaÃ§Ã£o
    """)
    
    # Dados de letalidade
    st.markdown("""
    #### âš°ï¸ **Dados de Letalidade:**
    - `df_letalidade_2007_2020.csv`: Taxas de letalidade histÃ³ricas
    - `letalidade_etiologia_2007_2020.csv`: Letalidade por etiologia
    
    **Tratamentos Aplicados:**
    - CÃ¡lculo de taxas de letalidade: (Ã“bitos/Casos) Ã— 100
    - EstratificaÃ§Ã£o por etiologia e sorogrupo
    - AnÃ¡lise temporal da letalidade
    - IdentificaÃ§Ã£o de fatores de risco
    """)
    
    # Dados de imunizaÃ§Ã£o detalhados
    st.markdown("""
    #### ğŸ’‰ **Dados de ImunizaÃ§Ã£o Estratificados:**
    - `imunizacao_por_ano.csv`: EvoluÃ§Ã£o anual da cobertura
    - `imunizacao_por_faixa_etaria.csv`: Cobertura por idade
    - `imunizacao_por_sorogrupo.csv`: VacinaÃ§Ã£o especÃ­fica
    - `imunizacao_por_uf.csv`: DistribuiÃ§Ã£o geogrÃ¡fica
    - `doses_todosimunosate2022.csv`: Doses aplicadas por regiÃ£o
    
    **Tratamentos Aplicados:**
    - PadronizaÃ§Ã£o de faixas etÃ¡rias
    - CÃ¡lculo de coberturas vacinais
    - AnÃ¡lise de disparidades regionais
    - CorrelaÃ§Ã£o cobertura Ã— incidÃªncia
    """)
    
    # SeÃ§Ã£o 3: Metodologias EstatÃ­sticas
    st.header("ğŸ“ˆ **3. Metodologias EstatÃ­sticas Implementadas**")
    
    st.subheader("ğŸ”¢ **EstatÃ­stica Descritiva**")
    st.markdown("""
    #### ğŸ“Š **Medidas de TendÃªncia Central e DispersÃ£o:**
    - **MÃ©dia, Mediana, Moda**: TendÃªncias centrais dos dados
    - **Desvio PadrÃ£o, VariÃ¢ncia**: Medidas de dispersÃ£o
    - **Quartis e Percentis**: DistribuiÃ§Ã£o dos dados
    - **Coeficiente de VariaÃ§Ã£o**: Variabilidade relativa
    
    **ImplementaÃ§Ã£o:**
    ```python
    # Exemplo de cÃ¡lculo de estatÃ­sticas descritivas
    stats_descritivas = dados.describe()
    cv = dados.std() / dados.mean() * 100  # Coeficiente de VariaÃ§Ã£o
    ```
    """)
    
    st.subheader("ğŸ“‰ **AnÃ¡lise de CorrelaÃ§Ã£o**")
    st.markdown("""
    #### ğŸ”— **Tipos de CorrelaÃ§Ã£o Implementados:**
    
    **1. CorrelaÃ§Ã£o de Pearson:**
    - Mede relaÃ§Ãµes lineares entre variÃ¡veis
    - Usado para: casos vs letalidade, cobertura vs incidÃªncia
    - Formula: r = Î£((x-xÌ„)(y-È³)) / âˆš(Î£(x-xÌ„)Â²Î£(y-È³)Â²)
    
    **2. CorrelaÃ§Ã£o de Spearman:**
    - Mede relaÃ§Ãµes monotÃ´nicas (nÃ£o necessariamente lineares)
    - Robusto a outliers
    - Baseado em rankings dos dados
    
    **3. CorrelaÃ§Ã£o Cruzada:**
    - AnÃ¡lise entre mÃºltiplas variÃ¡veis simultaneamente
    - Identifica padrÃµes complexos entre sorogrupos
    
    **ImplementaÃ§Ã£o:**
    ```python
    from scipy.stats import pearsonr, spearmanr
    
    # CorrelaÃ§Ã£o de Pearson
    corr_pearson, p_pearson = pearsonr(x, y)
    
    # CorrelaÃ§Ã£o de Spearman  
    corr_spearman, p_spearman = spearmanr(x, y)
    ```
    """)
    
    st.subheader("ğŸ“Š **AnÃ¡lise de RegressÃ£o**")
    st.markdown("""
    #### ğŸ“ˆ **Modelos de RegressÃ£o Utilizados:**
    
    **1. RegressÃ£o Linear Simples:**
    - Modelo: Y = Î²â‚€ + Î²â‚X + Îµ
    - Usado para: tendÃªncias temporais, relaÃ§Ãµes bivariadas
    - MÃ©tricas: RÂ², RMSE, p-valor
    
    **2. RegressÃ£o Linear MÃºltipla:**
    - Modelo: Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ + ... + Î²â‚™Xâ‚™ + Îµ
    - Usado para: anÃ¡lise multivariada de fatores
    - ValidaÃ§Ã£o: Time Series Split para dados temporais
    
    **3. RegressÃ£o Polinomial:**
    - Captura relaÃ§Ãµes nÃ£o-lineares
    - Usado para: relaÃ§Ãµes complexas entre variÃ¡veis
    
    **ImplementaÃ§Ã£o:**
    ```python
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.metrics import r2_score, mean_squared_error
    
    # Modelo de regressÃ£o
    modelo = LinearRegression()
    modelo.fit(X_train, y_train)
    
    # MÃ©tricas de avaliaÃ§Ã£o
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    ```
    """)
    
    st.subheader("â±ï¸ **AnÃ¡lise de SÃ©ries Temporais**")
    st.markdown("""
    #### ğŸ“… **TÃ©cnicas de SÃ©ries Temporais:**
    
    **1. DecomposiÃ§Ã£o STL (Seasonal and Trend decomposition using Loess):**
    - Separa sÃ©rie em: TendÃªncia + Sazonalidade + ResÃ­duos
    - Mais robusta que decomposiÃ§Ã£o clÃ¡ssica
    - Permite anÃ¡lise de componentes individuais
    
    **2. Teste de Estacionariedade (ADF):**
    - Augmented Dickey-Fuller Test
    - Verifica se a sÃ©rie Ã© estacionÃ¡ria
    - Fundamental para modelagem ARIMA
    
    **3. AnÃ¡lise de AutocorrelaÃ§Ã£o:**
    - Identifica padrÃµes de dependÃªncia temporal
    - Usado para detectar sazonalidade
    
    **ImplementaÃ§Ã£o:**
    ```python
    from statsmodels.tsa.seasonal import STL
    from statsmodels.tsa.stattools import adfuller
    
    # DecomposiÃ§Ã£o STL
    stl = STL(serie_temporal, period=12)
    resultado = stl.fit()
    
    # Teste ADF
    adf_stat, p_value = adfuller(serie_temporal)[:2]
    ```
    """)
    
    st.subheader("ğŸ¤– **Machine Learning e Clustering**")
    st.markdown("""
    #### ğŸ”¬ **Algoritmos de Machine Learning:**
    
    **1. K-Means Clustering:**
    - Agrupa sorogrupos por caracterÃ­sticas similares
    - Identifica padrÃµes epidemiolÃ³gicos
    - Usado para: segmentaÃ§Ã£o de sorogrupos
    
    **2. Clustering HierÃ¡rquico:**
    - Cria dendrograma de relacionamentos
    - MÃ©todo Ward para minimizar variÃ¢ncia
    - Complementa anÃ¡lise K-Means
    
    **3. PCA (Principal Component Analysis):**
    - ReduÃ§Ã£o dimensional preservando variÃ¢ncia
    - Identifica componentes principais
    - Usado para: visualizaÃ§Ã£o de dados multidimensionais
    
    **ImplementaÃ§Ã£o:**
    ```python
    from sklearn.cluster import KMeans
    from sklearn.decomposition import PCA
    from scipy.cluster.hierarchy import dendrogram, linkage
    
    # K-Means
    kmeans = KMeans(n_clusters=3, random_state=42)
    clusters = kmeans.fit_predict(dados_scaled)
    
    # PCA
    pca = PCA(n_components=2)
    dados_pca = pca.fit_transform(dados_scaled)
    ```
    """)
    
    # SeÃ§Ã£o 4: Processo de VisualizaÃ§Ã£o
    st.header("ğŸ¨ **4. Processo de VisualizaÃ§Ã£o e Interface**")
    
    st.subheader("ğŸ“Š **Biblioteca Plotly - GrÃ¡ficos Interativos**")
    st.markdown("""
    #### ğŸ¯ **Tipos de GrÃ¡ficos Implementados:**
    
    **1. GrÃ¡ficos de Linha (Time Series):**
    - EvoluÃ§Ã£o temporal de casos
    - TendÃªncias de vacinaÃ§Ã£o
    - AnÃ¡lise de sazonalidade
    
    **2. GrÃ¡ficos de DispersÃ£o (Scatter):**
    - CorrelaÃ§Ãµes entre variÃ¡veis
    - RegressÃµes lineares e polinomiais
    - AnÃ¡lise multivariada
    
    **3. GrÃ¡ficos de Barras:**
    - DistribuiÃ§Ãµes por categoria
    - ComparaÃ§Ãµes regionais
    - Rankings de incidÃªncia
    
    **4. Heatmaps:**
    - Matrizes de correlaÃ§Ã£o
    - DistribuiÃ§Ã£o geogrÃ¡fica
    - PadrÃµes sazonais
    
    **5. GrÃ¡ficos de Subplots:**
    - DecomposiÃ§Ã£o de sÃ©ries temporais
    - AnÃ¡lises comparativas
    - DiagnÃ³sticos de modelos
    """)
    
    st.subheader("ğŸ–¥ï¸ **Streamlit - Framework de Interface**")
    st.markdown("""
    #### âš™ï¸ **Componentes de Interface Utilizados:**
    
    **NavegaÃ§Ã£o:**
    - `st.sidebar.selectbox()`: Menu principal de navegaÃ§Ã£o
    - `st.tabs()`: Abas dentro de seÃ§Ãµes
    - `st.columns()`: Layout responsivo em colunas
    
    **VisualizaÃ§Ã£o:**
    - `st.plotly_chart()`: GrÃ¡ficos interativos
    - `st.dataframe()`: Tabelas interativas
    - `st.metric()`: KPIs e mÃ©tricas principais
    
    **Interatividade:**
    - `st.selectbox()`: SeleÃ§Ã£o de parÃ¢metros
    - `st.slider()`: Controles numÃ©ricos
    - `st.checkbox()`: Filtros booleanos
    
    **FormataÃ§Ã£o:**
    - `st.markdown()`: Texto formatado e explicaÃ§Ãµes
    - `st.latex()`: FÃ³rmulas matemÃ¡ticas
    - `st.code()`: CÃ³digo de exemplo
    """)
    
    # SeÃ§Ã£o 5: Performance e OtimizaÃ§Ã£o
    st.header("âš¡ **5. Performance e OtimizaÃ§Ã£o**")
    
    st.markdown("""
    #### ğŸš€ **EstratÃ©gias de OtimizaÃ§Ã£o Implementadas:**
    
    **1. Cache de Dados:**
    ```python
    @st.cache_data
    def load_all_data():
        # Carregamento otimizado com cache
        return dados_processados
    ```
    
    **2. Processamento Eficiente:**
    - Uso de `pandas.groupby()` para agregaÃ§Ãµes
    - VetorizaÃ§Ã£o com `numpy` para cÃ¡lculos
    - Lazy loading de dados nÃ£o utilizados
    
    **3. GestÃ£o de MemÃ³ria:**
    - Limpeza de DataFrames temporÃ¡rios
    - Uso de `dtype` apropriados
    - Garbage collection automÃ¡tico
    
    **4. Tratamento de Erros:**
    - Try-catch para imports condicionais
    - ValidaÃ§Ã£o de dados de entrada
    - Fallbacks para funcionalidades avanÃ§adas
    """)
    
    # SeÃ§Ã£o 6: MÃ©tricas EpidemiolÃ³gicas
    st.header("ğŸ¥ **6. MÃ©tricas EpidemiolÃ³gicas Calculadas**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### ğŸ“Š **IncidÃªncia e PrevalÃªncia:**
        
        **Taxa de Ataque:**
        ```
        Taxa = (Casos / PopulaÃ§Ã£o) Ã— 100.000
        ```
        
        **ForÃ§a de InfecÃ§Ã£o:**
        ```
        Î» = -ln(1 - taxa_ataque)
        ```
        
        **Taxa de Letalidade:**
        ```
        Letalidade = (Ã“bitos / Casos) Ã— 100
        ```
        """)
    
    with col2:
        st.markdown("""
        #### ğŸ’‰ **Cobertura Vacinal:**
        
        **Cobertura por Dose:**
        ```
        Cobertura = (Doses / Pop_Alvo) Ã— 100
        ```
        
        **Efetividade Vacinal:**
        ```
        EV = 1 - (Taxa_Vacinados / Taxa_NÃ£o_Vacinados)
        ```
        
        **Imunidade Coletiva:**
        ```
        Limiar = 1 - (1/Râ‚€)
        ```
        """)
    
    # SeÃ§Ã£o 7: ValidaÃ§Ã£o e Qualidade
    st.header("âœ… **7. ValidaÃ§Ã£o e Controle de Qualidade**")
    
    st.markdown("""
    #### ğŸ” **Processos de ValidaÃ§Ã£o Implementados:**
    
    **1. ValidaÃ§Ã£o de Dados:**
    - VerificaÃ§Ã£o de tipos de dados (dtype validation)
    - DetecÃ§Ã£o de valores missing e outliers
    - ConsistÃªncia temporal (datas vÃ¡lidas)
    - Integridade referencial entre tabelas
    
    **2. ValidaÃ§Ã£o EstatÃ­stica:**
    - Teste de normalidade (Shapiro-Wilk)
    - DetecÃ§Ã£o de multicolinearidade (VIF)
    - ValidaÃ§Ã£o cruzada para modelos
    - AnÃ¡lise de resÃ­duos
    
    **3. ValidaÃ§Ã£o EpidemiolÃ³gica:**
    - CoerÃªncia de taxas calculadas
    - ComparaÃ§Ã£o com literatura cientÃ­fica
    - ValidaÃ§Ã£o de tendÃªncias esperadas
    - VerificaÃ§Ã£o de sazonalidade conhecida
    
    **4. Monitoramento ContÃ­nuo:**
    - Logs de processamento de dados
    - Alertas para anomalias detectadas
    - Versionamento de dados
    - Backup automatizado
    """)
    
    # SeÃ§Ã£o 8: ConsideraÃ§Ãµes TÃ©cnicas
    st.header("âš ï¸ **8. LimitaÃ§Ãµes e ConsideraÃ§Ãµes TÃ©cnicas**")
    
    st.markdown("""
    #### ğŸš§ **LimitaÃ§Ãµes Conhecidas:**
    
    **1. Dados:**
    - DependÃªncia da qualidade dos dados oficiais
    - PossÃ­vel subnotificaÃ§Ã£o em algumas regiÃµes
    - Atraso na disponibilizaÃ§Ã£o de dados recentes
    - MudanÃ§as metodolÃ³gicas nas fontes
    
    **2. EstatÃ­sticas:**
    - Modelos assumem distribuiÃ§Ãµes especÃ­ficas
    - CorrelaÃ§Ã£o nÃ£o implica causalidade
    - SÃ©ries temporais curtas limitam anÃ¡lises
    - PossÃ­vel autocorrelaÃ§Ã£o residual
    
    **3. TÃ©cnicas:**
    - Alguns pacotes podem ter incompatibilidades
    - AnÃ¡lises avanÃ§adas requerem dados suficientes
    - Clustering Ã© sensÃ­vel Ã  escala dos dados
    - PCA pode perder interpretabilidade
    
    **4. Performance:**
    - Processamento intensivo para grandes datasets
    - LimitaÃ§Ãµes de memÃ³ria para anÃ¡lises complexas
    - Tempo de carregamento para primeira execuÃ§Ã£o
    - DependÃªncia de conexÃ£o para dados atualizados
    """)
    
    # SeÃ§Ã£o 9: EstatÃ­sticas dos Dados Atuais
    st.header("ğŸ“Š **9. EstatÃ­sticas dos Dados Atualmente Carregados**")
    
    if dados:
        st.subheader("ğŸ“ˆ **Resumo dos Datasets DisponÃ­veis**")
        
        # Criar tabela com informaÃ§Ãµes dos datasets
        datasets_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame):
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': f"{value.shape[0]:,}",
                    'Colunas': value.shape[1],
                    'MemÃ³ria (MB)': f"{value.memory_usage(deep=True).sum() / 1024**2:.2f}",
                    'PerÃ­odo': 'VariÃ¡vel',
                    'Tipo': 'DataFrame'
                })
            else:
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': '-',
                    'Colunas': '-',
                    'MemÃ³ria (MB)': '-',
                    'PerÃ­odo': '-',
                    'Tipo': type(value).__name__
                })
        
        df_info = pd.DataFrame(datasets_info)
        st.dataframe(df_info, use_container_width=True)
        
        # EstatÃ­sticas gerais
        total_linhas = sum([v.shape[0] for v in dados.values() if isinstance(v, pd.DataFrame)])
        total_memoria = sum([v.memory_usage(deep=True).sum() for v in dados.values() if isinstance(v, pd.DataFrame)])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š Total de Datasets", len(dados))
        with col2:
            st.metric("ğŸ“ Total de Registros", f"{total_linhas:,}")
        with col3:
            st.metric("ğŸ’¾ MemÃ³ria Total", f"{total_memoria/1024**2:.1f} MB")
        with col4:
            st.metric("ğŸ—‚ï¸ Tabelas CSV", len([f for f in os.listdir('TABELAS') if f.endswith('.csv')]))
        
        # AnÃ¡lise de qualidade dos dados
        st.subheader("ğŸ” **AnÃ¡lise de Qualidade dos Dados**")
        
        qualidade_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame) and not value.empty:
                missing_percent = (value.isnull().sum().sum() / (value.shape[0] * value.shape[1])) * 100
                duplicatas = value.duplicated().sum()
                
                qualidade_info.append({
                    'Dataset': key,
                    'Missing Values (%)': f"{missing_percent:.2f}%",
                    'Duplicatas': duplicatas,
                    'Completude': f"{100-missing_percent:.1f}%",
                    'Status': "âœ… Boa" if missing_percent < 5 and duplicatas < 10 else "âš ï¸ AtenÃ§Ã£o" if missing_percent < 15 else "âŒ CrÃ­tica"
                })
        
        if qualidade_info:
            df_qualidade = pd.DataFrame(qualidade_info)
            st.dataframe(df_qualidade, use_container_width=True)
    
    else:
        st.warning("âš ï¸ Nenhum dado carregado para anÃ¡lise")
    
    # Footer tÃ©cnico
    st.markdown("---")
    st.markdown("""
    ### ğŸ¯ **ConclusÃ£o TÃ©cnica**
    
    Este sistema representa uma implementaÃ§Ã£o completa de anÃ¡lise epidemiolÃ³gica moderna, integrando:
    - **AutomaÃ§Ã£o de dados** com tecnologias Python
    - **AnÃ¡lises estatÃ­sticas robustas** com mÃºltiplas metodologias
    - **VisualizaÃ§Ã£o interativa** para exploraÃ§Ã£o de dados
    - **Interface intuitiva** para diferentes perfis de usuÃ¡rios
    - **ValidaÃ§Ã£o rigorosa** para garantir qualidade cientÃ­fica
    
    **Tecnologias Principais:** Python, Pandas, NumPy, SciPy, Scikit-learn, Plotly, Streamlit, Statsmodels
    
    **PadrÃµes Seguidos:** PEP 8, DocumentaÃ§Ã£o docstring, Type hints, Git workflow, Code review
    """)


def main():
    """FunÃ§Ã£o principal que executa a aplicaÃ§Ã£o Streamlit.

    Esta funÃ§Ã£o inicializa a pÃ¡gina do dashboard, configura a barra lateral de navegaÃ§Ã£o,
    chama a funÃ§Ã£o `load_all_data()` para carregar todos os dados, e gerencia a
    exibiÃ§Ã£o da seÃ§Ã£o selecionada pelo usuÃ¡rio. Se o carregamento de dados falhar,
    exibe uma mensagem de erro com instruÃ§Ãµes.
    """
    st.title("ğŸ¦  **Dashboard Completo de Meningite Brasil**")
    st.markdown("---")
    
    # Sidebar para navegaÃ§Ã£o
    st.sidebar.title("ğŸ§­ **NavegaÃ§Ã£o**")
    
    # Carregar dados
    dados = load_all_data()
    
    if dados:
        # Menu de navegaÃ§Ã£o
        opcao = st.sidebar.selectbox(
            "Escolha uma seÃ§Ã£o:",
            [
                "ğŸ  VisÃ£o Geral 2024",
                "ğŸ“Š AnÃ¡lise de Casos",
                "ğŸ¦  AnÃ¡lise de Sorogrupos",
                "ğŸ”¬ AnÃ¡lise de Etiologia",
                "ğŸ’‰ AnÃ¡lise de ImunizaÃ§Ã£o",
                "ğŸ—ºï¸ AnÃ¡lise Regional",
                "ğŸ”¬ AnÃ¡lises AvanÃ§adas",
                "ğŸ¦  AnÃ¡lise EpidemiolÃ³gica",
                "âš¡ Taxa de Ataque",
                "ğŸ” ExploraÃ§Ã£o Livre",
                "ğŸ“‹ RelatÃ³rios",
                "âš™ï¸ Expositivo TÃ©cnico"
            ]
        )
        
        # NavegaÃ§Ã£o para as seÃ§Ãµes
        if opcao == "ğŸ  VisÃ£o Geral 2024":
            show_overview_2024(dados)
        elif opcao == "ğŸ“Š AnÃ¡lise de Casos":
            show_cases_analysis(dados)
        elif opcao == "ğŸ¦  AnÃ¡lise de Sorogrupos":
            show_sorogrupos_analysis(dados)
        elif opcao == "ğŸ”¬ AnÃ¡lise de Etiologia":
            show_etiologia_analysis(dados)
        elif opcao == "ğŸ’‰ AnÃ¡lise de ImunizaÃ§Ã£o":
            show_imunizacao_analysis(dados)
        elif opcao == "ğŸ—ºï¸ AnÃ¡lise Regional":
            show_regional_analysis(dados)
        elif opcao == "ğŸ”¬ AnÃ¡lises AvanÃ§adas":
            show_advanced_analysis(dados)
        elif opcao == "ğŸ¦  AnÃ¡lise EpidemiolÃ³gica":
            show_epidemiological_analysis(dados)
        elif opcao == "âš¡ Taxa de Ataque":
            show_attack_rate_analysis(dados)
        elif opcao == "ğŸ” ExploraÃ§Ã£o Livre":
            show_free_exploration(dados)
        elif opcao == "ğŸ“‹ RelatÃ³rios":
            show_reports(dados)
        elif opcao == "âš™ï¸ Expositivo TÃ©cnico":
            show_technical_exposition(dados)
        
        # InformaÃ§Ãµes adicionais na sidebar
        st.sidebar.markdown("---")
        st.sidebar.markdown("**ğŸ“Š Dados DisponÃ­veis:**")
        
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame):
                st.sidebar.write(f"âœ… {key}: {value.shape[0]} linhas")
            else:
                st.sidebar.write(f"âœ… {key}")
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("**ğŸ”§ Desenvolvido com:**")
        st.sidebar.markdown("- Streamlit")
        st.sidebar.markdown("- Plotly")
        st.sidebar.markdown("- Pandas")
        st.sidebar.markdown("- NumPy")
        st.sidebar.markdown("- SciPy")
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("**ğŸ“… Ãšltima atualizaÃ§Ã£o:**")
        st.sidebar.markdown(f"{datetime.now().strftime('%d/%m/%Y %H:%M')}")
        
    else:
        st.error("âŒ Erro ao carregar dados. Verifique se os arquivos estÃ£o disponÃ­veis na pasta TABELAS/")
        st.info("ğŸ’¡ Certifique-se de que os seguintes arquivos existem:")
        st.write("- casos_consolidados_2017_2024.csv")
        st.write("- sorogrupos_consolidados_2007_2024.csv")
        st.write("- etiologias_consolidadas_2007_2024.csv")
        st.write("- imunizacao_por_ano.csv")
        st.write("- imunizacao_por_uf.csv")
        st.write("- imunizacao_por_faixa_etaria.csv")
        st.write("- imunizacao_por_sorogrupo.csv")
        st.write("- imunobiologicosem2023a2025.csv")
        st.write("- letalidade_etiologia_2007_2020.csv")
        st.write("- casos_notificados_2017_2022.csv")
        st.write("- dados_gerais_2024.csv")
        st.write("- bacterianas_2024.csv")
        st.write("- etiologia_2024.csv")
        st.write("- sorogrupos_2024.csv")
        st.write("- sih_meningite_long.csv")

if __name__ == "__main__":
    main()
