#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dashboard Completo de Meningite Brasil - Vers√£o 2.0 Corrigida
Inclui todas as an√°lises: regional, avan√ßada, ARIMA, testes de hip√≥teses e explora√ß√£o livre
"""

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import streamlit as st
import os
from datetime import datetime
import warnings
from scipy import stats
# Imports condicionais para evitar problemas de compatibilidade
try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.seasonal import seasonal_decompose
    STATSMODELS_AVAILABLE = True
except ImportError as e:
    print(f"Aviso: statsmodels n√£o dispon√≠vel: {e}")
    STATSMODELS_AVAILABLE = False
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Dashboard Meningite Brasil - An√°lise Completa",
    page_icon="ü¶†",
    layout="wide",
    initial_sidebar_state="expanded"
)

def load_all_data():
    """Carrega e pr√©-processa todos os conjuntos de dados necess√°rios para o dashboard.

    Esta fun√ß√£o √© respons√°vel por ler os arquivos CSV da pasta 'TABELAS/' e 'data/processed/',
    tratar exce√ß√µes de arquivos ausentes e, em seguida, chamar fun√ß√µes auxiliares para
    criar conjuntos de dados derivados, como dados regionais e temporais.

    Returns:
        dict: Um dicion√°rio contendo todos os DataFrames carregados e processados,
              prontos para serem utilizados pelas fun√ß√µes de visualiza√ß√£o. As chaves
              do dicion√°rio s√£o nomes descritivos dos conjuntos de dados.
              Retorna None se ocorrer um erro cr√≠tico durante o carregamento.
    """
    
    st.info("üìä Carregando todos os dados processados...")
    
    try:
        # Dados b√°sicos
        casos_consolidados = pd.read_csv('TABELAS/casos_consolidados_2017_2024.csv')
        sorogrupos_consolidados = pd.read_csv('TABELAS/sorogrupos_consolidados_2007_2024.csv')
        etiologias_consolidadas = pd.read_csv('TABELAS/etiologias_consolidadas_2007_2024.csv')
        
        # Dados de imuniza√ß√£o
        imunizacao_ano = pd.read_csv('TABELAS/imunizacao_por_ano.csv')
        imunizacao_faixa_etaria = pd.read_csv('TABELAS/imunizacao_por_faixa_etaria.csv')
        imunizacao_sorogrupo = pd.read_csv('TABELAS/imunizacao_por_sorogrupo.csv')
        imunizacao_uf = pd.read_csv('TABELAS/imunizacao_por_uf.csv')
        
        # Dados de letalidade e casos
        letalidade_etiologia = pd.read_csv('TABELAS/letalidade_etiologia_2007_2020.csv')
        casos_2017_2022 = pd.read_csv('TABELAS/casos_notificados_2017_2022.csv')
        dados_gerais_2024 = pd.read_csv('TABELAS/dados_gerais_2024.csv')
        bacterianas_2024 = pd.read_csv('TABELAS/bacterianas_2024.csv')
        etiologia_2024 = pd.read_csv('TABELAS/etiologia_2024.csv')
        sorogrupos_2024 = pd.read_csv('TABELAS/sorogrupos_2024.csv')
        
        # Dados de imuniza√ß√£o 2023-2025 (pode ter separador diferente; manter opcional)
        try:
            imunizacao_2023_2025 = pd.read_csv('TABELAS/imunobiologicosem2023a2025.csv')
        except Exception:
            imunizacao_2023_2025 = None

        # Dados de imuniza√ß√£o processados (base principal para an√°lises)
        try:
            imunizacao_processada = pd.read_csv('data/processed/dados_imunizacao_processados.csv')
        except Exception:
            imunizacao_processada = None
        
        # Dados de hospitaliza√ß√£o SIH
        sih_meningite = pd.read_csv('TABELAS/sih_meningite_long.csv')
        
        # Criar dados regionais a partir dos dados dispon√≠veis
        analise_regional = create_regional_data(imunizacao_uf)
        imunizacao_regional = create_temporal_regional_data(imunizacao_2023_2025)
        analise_temporal = create_temporal_analysis(imunizacao_2023_2025)
        matriz_correlacao = create_correlation_matrix()
        
        st.success("‚úÖ Dados carregados com sucesso!")
        
        return {
            'casos_consolidados': casos_consolidados,
            'sorogrupos_consolidados': sorogrupos_consolidados,
            'etiologias_consolidadas': etiologias_consolidadas,
            'imunizacao_ano': imunizacao_ano,
            'imunizacao_faixa_etaria': imunizacao_faixa_etaria,
            'imunizacao_sorogrupo': imunizacao_sorogrupo,
            'imunizacao_uf': imunizacao_uf,
            'imunizacao_2023_2025': imunizacao_2023_2025,
            'imunizacao_processada': imunizacao_processada,
            'analise_regional': analise_regional,
            'imunizacao_regional': imunizacao_regional,
            'analise_temporal': analise_temporal,
            'matriz_correlacao': matriz_correlacao,
            'casos_2017_2022': casos_2017_2022,
            'dados_gerais_2024': dados_gerais_2024,
            'bacterianas_2024': bacterianas_2024,
            'etiologia_2024': etiologia_2024,
            'sorogrupos_2024': sorogrupos_2024,
            'letalidade_etiologia': letalidade_etiologia,
            'sih_meningite': sih_meningite
        }
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {e}")
        return None

def create_regional_data(imunizacao_uf):
    """Cria um DataFrame com dados regionais simulados a partir de dados por UF.

    Esta fun√ß√£o utiliza um mapeamento predefinido de Unidades Federativas (UFs) para
    as cinco grandes regi√µes do Brasil. Ela ent√£o gera dados simulados (aleat√≥rios)
    para o total de doses e a cobertura m√©dia de cada regi√£o.

    Args:
        imunizacao_uf (pd.DataFrame): DataFrame contendo dados de imuniza√ß√£o por UF.
                                     Atualmente, √© usado apenas para refer√™ncia do
                                     mapeamento, mas poderia ser usado para agregar
                                     dados reais.

    Returns:
        pd.DataFrame: Um DataFrame com dados agregados por regi√£o, contendo as colunas
                      'Regiao', 'Total_UFs', 'Total_Doses' e 'Cobertura_Media'.
    """
    # Mapeamento de UFs para regi√µes
    mapeamento_regioes = {
        'Norte': ['11 Rond√¥nia', '12 Acre', '13 Amazonas', '14 Roraima', '15 Par√°', '16 Amap√°', '17 Tocantins'],
        'Nordeste': ['21 Maranh√£o', '22 Piau√≠', '23 Cear√°', '24 Rio Grande do Norte', '25 Para√≠ba', '26 Pernambuco', '27 Alagoas', '28 Sergipe', '29 Bahia'],
        'Centro-Oeste': ['50 Mato Grosso do Sul', '51 Mato Grosso', '52 Goi√°s', '53 Distrito Federal'],
        'Sudeste': ['31 Minas Gerais', '32 Esp√≠rito Santo', '33 Rio de Janeiro', '35 S√£o Paulo'],
        'Sul': ['41 Paran√°', '42 Santa Catarina', '43 Rio Grande do Sul']
    }
    
    # Criar dados regionais simulados
    dados_regional = []
    for regiao, ufs in mapeamento_regioes.items():
        total_ufs = len(ufs)
        total_doses = np.random.randint(100000, 1000000)  # Simulado
        cobertura_media = np.random.uniform(70, 95)  # Simulado
        
        dados_regional.append({
            'Regiao': regiao,
            'Total_UFs': total_ufs,
            'Total_Doses': total_doses,
            'Cobertura_Media': cobertura_media
        })
    
    return pd.DataFrame(dados_regional)

def create_temporal_regional_data(imunizacao_2023_2025):
    """Gera dados temporais regionais simulados para an√°lise.

    Esta fun√ß√£o cria um DataFrame com dados simulados (aleat√≥rios) de doses e cobertura
    para cada regi√£o do Brasil, ao longo de um per√≠odo de tr√™s anos (2023-2025).
    √â √∫til para visualiza√ß√µes de s√©ries temporais quando dados reais n√£o est√£o dispon√≠veis.

    Args:
        imunizacao_2023_2025 (pd.DataFrame): DataFrame de refer√™ncia. Atualmente n√£o utilizado
                                           diretamente para os c√°lculos, mas serve como
                                           gatilho para a cria√ß√£o dos dados.

    Returns:
        pd.DataFrame: Um DataFrame com dados temporais simulados por regi√£o,
                      contendo as colunas 'Regiao', 'Ano', 'Total_Doses' e 'Cobertura'.
    """
    # Dados simulados para an√°lise temporal regional
    regioes = ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']
    anos = [2023, 2024, 2025]
    
    dados_temporais = []
    for regiao in regioes:
        for ano in anos:
            dados_temporais.append({
                'Regiao': regiao,
                'Ano': ano,
                'Total_Doses': np.random.randint(50000, 500000),
                'Cobertura': np.random.uniform(75, 98)
            })
    
    return pd.DataFrame(dados_temporais)

def create_temporal_analysis(imunizacao_2023_2025):
    """Cria um DataFrame com dados simulados para an√°lise temporal.

    Gera um conjunto de dados simulados (aleat√≥rios) de casos de meningite e cobertura
    vacinal para um intervalo de anos (2020-2025). Serve como um substituto para
    an√°lises de tend√™ncia quando dados reais consolidados n√£o est√£o dispon√≠veis.

    Args:
        imunizacao_2023_2025 (pd.DataFrame): DataFrame de refer√™ncia, n√£o utilizado
                                           diretamente nos c√°lculos.

    Returns:
        pd.DataFrame: Um DataFrame com dados temporais simulados, contendo as
                      colunas 'Ano', 'Casos' e 'Cobertura'.
    """
    # Dados simulados para an√°lise temporal
    anos = list(range(2020, 2026))
    dados_temporais = []
    
    for ano in anos:
        dados_temporais.append({
            'Ano': ano,
            'Casos': np.random.randint(1000, 5000),
            'Cobertura': np.random.uniform(80, 95)
        })
    
    return pd.DataFrame(dados_temporais)

def create_correlation_matrix():
    """Gera uma matriz de correla√ß√£o simulada.

    Cria uma matriz de correla√ß√£o 5x5 com valores aleat√≥rios para demonstrar
    a funcionalidade de visualiza√ß√£o de correla√ß√µes (heatmap). As vari√°veis
    s√£o 'Casos', 'Letalidade', 'Cobertura', 'Populacao' e 'Temperatura'.
    A matriz √© sim√©trica e tem a diagonal principal preenchida com 1.0.

    Returns:
        pd.DataFrame: Uma matriz de correla√ß√£o simulada como um DataFrame do Pandas.
    """
    # Criar matriz de correla√ß√£o simulada
    n_vars = 5
    corr_matrix = np.random.rand(n_vars, n_vars)
    np.fill_diagonal(corr_matrix, 1.0)
    
    # Tornar sim√©trica
    corr_matrix = (corr_matrix + corr_matrix.T) / 2
    
    return pd.DataFrame(
        corr_matrix,
        columns=['Casos', 'Letalidade', 'Cobertura', 'Populacao', 'Temperatura'],
        index=['Casos', 'Letalidade', 'Cobertura', 'Populacao', 'Temperatura']
    )

def show_overview_2024(dados):
    """Exibe a se√ß√£o "Vis√£o Geral 2024" no dashboard.

    Esta fun√ß√£o renderiza uma vis√£o geral dos dados de meningite para o ano de 2024.
    Ela apresenta m√©tricas chave, como total de casos suspeitos e √≥bitos, letalidade,
    e gr√°ficos de distribui√ß√£o de casos por etiologia e sorogrupo. Tamb√©m inclui
    um resumo estat√≠stico e informa√ß√µes gerais sobre a doen√ßa.

    Args:
        dados (dict): O dicion√°rio global contendo todos os DataFrames da aplica√ß√£o.
                      As chaves 'dados_gerais_2024', 'bacterianas_2024', 'etiologia_2024',
                      e 'sorogrupos_2024' s√£o utilizadas.
    """
    st.header("üè† **Vis√£o Geral 2024 - Meningite Brasil**")
    st.markdown("---")
    
    # Carregar dados espec√≠ficos de 2024
    dados_gerais = dados['dados_gerais_2024']
    bacterianas = dados['bacterianas_2024']
    etiologia = dados['etiologia_2024']
    sorogrupos = dados['sorogrupos_2024']
    
    if dados_gerais is not None and not dados_gerais.empty:
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = dados_gerais['Casos_Suspeitos'].sum()
            st.metric("üìä Total de Casos Suspeitos", f"{total_casos:,}")
        
        with col2:
            total_obitos = dados_gerais['Obitos_Confirmados'].sum()
            st.metric("üíÄ Total de √ìbitos Confirmados", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("‚ö†Ô∏è Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            # Como n√£o h√° coluna UF, vamos mostrar o ano
            ano_2024 = dados_gerais['Ano'].iloc[0]
            st.metric("üìÖ Ano", ano_2024)
        
        # Gr√°fico de casos por ano (j√° que n√£o temos UF)
        st.subheader("üìà **Casos por Ano**")
        
        fig_casos_ano = px.bar(
            x=dados_gerais['Ano'],
            y=dados_gerais['Casos_Suspeitos'],
            title="Distribui√ß√£o de Casos por Ano",
            labels={'x': 'Ano', 'y': 'N√∫mero de Casos'},
            color=dados_gerais['Casos_Suspeitos'],
            color_continuous_scale='Reds'
        )
        
        fig_casos_ano.update_layout(template='plotly_white')
        st.plotly_chart(fig_casos_ano, use_container_width=True)
        
        # An√°lise por etiologia
        if etiologia is not None and not etiologia.empty:
            st.subheader("üß¨ **Casos por Etiologia em 2024**")
            
            # Verificar se a coluna existe
            if 'Casos_Suspeitos' in etiologia.columns:
                casos_por_etiologia = etiologia.groupby('Etiologia')['Casos_Suspeitos'].sum().sort_values(ascending=False)
            else:
                # Se n√£o existir, usar a primeira coluna num√©rica dispon√≠vel
                colunas_numericas = etiologia.select_dtypes(include=[np.number]).columns
                if len(colunas_numericas) > 0:
                    coluna_casos = colunas_numericas[0]
                    casos_por_etiologia = etiologia.groupby('Etiologia')[coluna_casos].sum().sort_values(ascending=False)
                else:
                    st.warning("‚ö†Ô∏è N√£o foi poss√≠vel encontrar dados num√©ricos para an√°lise por etiologia")
                    return
            
            fig_etiologia = px.pie(
                values=casos_por_etiologia.values,
                names=casos_por_etiologia.index,
                title="Distribui√ß√£o de Casos por Etiologia"
            )
            
            fig_etiologia.update_layout(template='plotly_white')
            st.plotly_chart(fig_etiologia, use_container_width=True)
        
        # An√°lise por sorogrupo
        if sorogrupos is not None and not sorogrupos.empty:
            st.subheader("ü¶† **Casos por Sorogrupo em 2024**")
            
            # Verificar se a coluna existe
            if 'Casos_Suspeitos' in sorogrupos.columns:
                casos_por_sorogrupo = sorogrupos.groupby('Sorogrupo')['Casos_Suspeitos'].sum().sort_values(ascending=False)
            else:
                # Se n√£o existir, usar a primeira coluna num√©rica dispon√≠vel
                colunas_numericas = sorogrupos.select_dtypes(include=[np.number]).columns
                if len(colunas_numericas) > 0:
                    coluna_casos = colunas_numericas[0]
                    casos_por_sorogrupo = sorogrupos.groupby('Sorogrupo')[coluna_casos].sum().sort_values(ascending=False)
                else:
                    st.warning("‚ö†Ô∏è N√£o foi poss√≠vel encontrar dados num√©ricos para an√°lise por sorogrupo")
                    return
            
            fig_sorogrupo = px.bar(
                x=casos_por_sorogrupo.index,
                y=casos_por_sorogrupo.values,
                title="Distribui√ß√£o de Casos por Sorogrupo",
                labels={'x': 'Sorogrupo', 'y': 'N√∫mero de Casos'},
                color=casos_por_sorogrupo.values,
                color_continuous_scale='Blues'
            )
            
            fig_sorogrupo.update_layout(template='plotly_white')
            st.plotly_chart(fig_sorogrupo, use_container_width=True)
        
        # Resumo estat√≠stico
        st.subheader("üìã **Resumo Estat√≠stico 2024**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Estat√≠sticas Descritivas dos Casos Suspeitos:**")
            st.dataframe(dados_gerais['Casos_Suspeitos'].describe())
        
        with col2:
            st.write("**Dados Gerais 2024:**")
            st.dataframe(dados_gerais)
        
        # Informa√ß√µes sobre meningite
        st.subheader("‚ÑπÔ∏è **Sobre a Meningite**")
        st.markdown("""
        **Meningite** √© uma inflama√ß√£o das membranas que revestem o c√©rebro e a medula espinhal.
        
        **Principais sintomas:**
        - Febre alta
        - Dor de cabe√ßa intensa
        - Rigidez no pesco√ßo
        - N√°useas e v√¥mitos
        - Altera√ß√£o do n√≠vel de consci√™ncia
        
        **Import√¢ncia da vacina√ß√£o:**
        - Previne formas graves da doen√ßa
        - Reduz a transmiss√£o
        - Protege grupos vulner√°veis
        """)
    else:
        st.warning("‚ö†Ô∏è Dados de 2024 n√£o dispon√≠veis")

def show_cases_analysis(dados):
    """Exibe a se√ß√£o "An√°lise dos Casos Notificados 2017-2024".

    Renderiza uma an√°lise detalhada da evolu√ß√£o temporal dos casos de meningite.
    Apresenta m√©tricas gerais, um gr√°fico de linha da evolu√ß√£o dos casos, an√°lise
    de sazonalidade (se dispon√≠vel), e uma an√°lise de tend√™ncia linear com
    interpreta√ß√µes estat√≠sticas detalhadas (coeficiente angular, R¬≤, p-valor).

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves 'casos_consolidados'
                      e 'casos_2017_2022'.
    """
    st.header("üìà **An√°lise dos Casos Notificados 2017-2024**")
    st.markdown("---")
    
    # Carregar dados de casos
    casos = dados['casos_consolidados']
    casos_2017_2022 = dados['casos_2017_2022']
    
    if casos is not None and not casos.empty:
        # M√©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = casos['Casos_Notificados'].sum()
            st.metric("üìä Total de Casos Notificados", f"{total_casos:,}")
        
        with col2:
            # Verificar se a coluna Obitos existe
            if 'Obitos' in casos.columns:
                total_obitos = casos['Obitos'].sum()
                st.metric("üíÄ Total de √ìbitos", f"{total_obitos:,}")
            else:
                st.metric("üíÄ Total de √ìbitos", "N/A")
        
        with col3:
            # Calcular letalidade se poss√≠vel
            if 'Obitos' in casos.columns and 'Casos_Notificados' in casos.columns:
                total_obitos = casos['Obitos'].sum()
                letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
                st.metric("‚ö†Ô∏è Letalidade Geral", f"{letalidade_geral:.1f}%")
            else:
                st.metric("‚ö†Ô∏è Letalidade Geral", "N/A")
        
        with col4:
            periodo_anos = casos['Ano'].max() - casos['Ano'].min() + 1
            st.metric("üìÖ Per√≠odo (Anos)", periodo_anos)
        
        # Evolu√ß√£o temporal dos casos
        st.subheader("üìà **Evolu√ß√£o Temporal dos Casos**")
        
        casos_por_ano = casos.groupby('Ano')['Casos_Notificados'].sum().reset_index()
        
        fig_evolucao = px.line(
            casos_por_ano,
            x='Ano',
            y='Casos_Notificados',
            title="Evolu√ß√£o dos Casos de Meningite (2017-2024)",
            markers=True
        )
        
        fig_evolucao.update_layout(
            xaxis_title="Ano",
            yaxis_title="N√∫mero de Casos",
            template='plotly_white'
        )
        
        fig_evolucao.update_xaxes(tickformat='d')
        st.plotly_chart(fig_evolucao, use_container_width=True)
        
        # Explica√ß√£o do gr√°fico de evolu√ß√£o temporal
        st.markdown("""
        #### üìñ **Interpreta√ß√£o do Gr√°fico de Evolu√ß√£o Temporal:**
        - **Eixo X (Horizontal):** Anos (2017-2024)
        - **Eixo Y (Vertical):** N√∫mero total de casos notificados por ano
        - **Linha com marcadores:** Cada ponto representa o total de casos em um ano espec√≠fico
        - **Tend√™ncia:** A inclina√ß√£o da linha mostra se os casos est√£o aumentando, diminuindo ou est√°veis
        - **Varia√ß√µes:** Picos ou vales podem indicar surtos, mudan√ßas em pol√≠ticas de sa√∫de ou fatores sazonais
        - **Utilidade:** Permite identificar padr√µes temporais e avaliar a efic√°cia de interven√ß√µes de sa√∫de p√∫blica
        """)
        
        # An√°lise de sazonalidade
        st.subheader("üå°Ô∏è **An√°lise de Sazonalidade**")
        
        if 'Mes' in casos.columns:
            casos_por_mes = casos.groupby('Mes')['Casos_Notificados'].sum().reset_index()
            
            # Mapear n√∫meros para nomes dos meses
            meses_nomes = {
                1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Abr', 5: 'Mai', 6: 'Jun',
                7: 'Jul', 8: 'Ago', 9: 'Set', 10: 'Out', 11: 'Nov', 12: 'Dez'
            }
            casos_por_mes['Mes_Nome'] = casos_por_mes['Mes'].map(meses_nomes)
            
            fig_sazonalidade = px.bar(
                casos_por_mes,
                x='Mes_Nome',
                y='Casos_Notificados',
                title="Sazonalidade dos Casos de Meningite",
                color='Casos_Notificados',
                color_continuous_scale='Reds'
            )
            
            fig_sazonalidade.update_layout(
                xaxis_title="M√™s",
                yaxis_title="N√∫mero de Casos",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_sazonalidade, use_container_width=True)
            
            # Explica√ß√£o do gr√°fico de sazonalidade
            st.markdown("""
            #### üìñ **Interpreta√ß√£o do Gr√°fico de Sazonalidade:**
            - **Eixo X (Horizontal):** Meses do ano (Jan a Dez)
            - **Eixo Y (Vertical):** N√∫mero total de casos acumulados em cada m√™s (todos os anos)
            - **Barras coloridas:** Altura representa o total de casos, cores mais intensas = mais casos
            - **Padr√µes sazonais:** Permite identificar meses com maior/menor incid√™ncia
            - **Import√¢ncia epidemiol√≥gica:** Ajuda a planejar campanhas preventivas e aloca√ß√£o de recursos
            """)
            
            # Interpreta√ß√£o da sazonalidade
            st.markdown("""
            **üìä Interpreta√ß√£o da Sazonalidade:**
            
            **Padr√µes t√≠picos observados:**
            - **Inverno/Outono:** Maior incid√™ncia (temperaturas mais baixas)
            - **Primavera/Ver√£o:** Menor incid√™ncia (temperaturas mais altas)
            
            **Fatores que influenciam:**
            - Aglomera√ß√£o em ambientes fechados
            - Sistema imunol√≥gico mais vulner√°vel
            - Maior circula√ß√£o de v√≠rus respirat√≥rios
            """)
        else:
            st.info("‚ÑπÔ∏è Dados de sazonalidade mensal n√£o dispon√≠veis")
        
        # Distribui√ß√£o por ano (j√° que n√£o temos UF)
        st.subheader("üìä **Distribui√ß√£o por Ano**")
        
        fig_distribuicao = px.bar(
            x=casos_por_ano['Ano'],
            y=casos_por_ano['Casos_Notificados'],
            title="Casos por Ano (2017-2024)",
            labels={'x': 'Ano', 'y': 'N√∫mero de Casos'},
            color=casos_por_ano['Casos_Notificados'],
            color_continuous_scale='Blues'
        )
        
        fig_distribuicao.update_layout(
            xaxis_title="Ano",
            yaxis_title="N√∫mero de Casos",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_distribuicao, use_container_width=True)
        
        # An√°lise de tend√™ncia
        st.subheader("üìà **An√°lise de Tend√™ncia**")
        
        # Calcular tend√™ncia linear
        x = casos_por_ano['Ano'].values.reshape(-1, 1)
        y = casos_por_ano['Casos_Notificados'].values
        
        if len(x) > 1:
            slope, intercept, r_value, p_value, std_err = stats.linregress(x.flatten(), y)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("üìä Coeficiente Angular", f"{slope:.1f}")
            
            with col2:
                st.metric("üìà R¬≤", f"{r_value**2:.3f}")
            
            with col3:
                if p_value < 0.05:
                    st.metric("üéØ Signific√¢ncia", "Significativo (p<0.05)")
                else:
                    st.metric("üéØ Signific√¢ncia", "N√£o significativo (p‚â•0.05)")
            
            # Explica√ß√£o detalhada das m√©tricas estat√≠sticas
            st.markdown("---")
            st.markdown("### üìö **Explica√ß√£o das M√©tricas Estat√≠sticas**")
            
            st.markdown(f"""
            #### üìä **Coeficiente Angular ({slope:.1f})**
            - **O que √©:** Representa a varia√ß√£o m√©dia anual no n√∫mero de casos
            - **Interpreta√ß√£o:** 
              - Se positivo: aumenta {abs(slope):.1f} casos por ano em m√©dia
              - Se negativo: diminui {abs(slope):.1f} casos por ano em m√©dia
              - Se pr√≥ximo de zero: tend√™ncia est√°vel
            
            #### üìà **Coeficiente de Determina√ß√£o (R¬≤ = {r_value**2:.3f})**
            - **O que √©:** Mede o quanto da varia√ß√£o nos casos √© explicada pela tend√™ncia temporal
            - **Escala:** 0 a 1 (quanto mais pr√≥ximo de 1, melhor o ajuste)
            - **Interpreta√ß√£o atual:** 
              - R¬≤ = {r_value**2:.3f} significa que {r_value**2*100:.1f}% da varia√ß√£o nos casos √© explicada pelo tempo
              - {100-r_value**2*100:.1f}% da varia√ß√£o se deve a outros fatores (sazonalidade, surtos, pol√≠ticas de sa√∫de, etc.)
            - **Qualidade do ajuste:**
              - R¬≤ > 0.7: Ajuste forte
              - R¬≤ 0.4-0.7: Ajuste moderado  
              - R¬≤ < 0.4: Ajuste fraco
              - **Seu resultado:** {"Ajuste forte" if r_value**2 > 0.7 else "Ajuste moderado" if r_value**2 > 0.4 else "Ajuste fraco"}
            
            #### üéØ **Signific√¢ncia Estat√≠stica (p-valor = {p_value:.4f})**
            - **O que √©:** Probabilidade de observar essa tend√™ncia por acaso
            - **Interpreta√ß√£o:**
              - p < 0.05: Tend√™ncia estatisticamente significativa (confi√°vel)
              - p ‚â• 0.05: Tend√™ncia pode ser devida ao acaso
              - **Seu resultado:** {"A tend√™ncia √© estatisticamente significativa e confi√°vel" if p_value < 0.05 else "A tend√™ncia pode ser devida ao acaso - n√£o √© estatisticamente significativa"}
            
            #### üìè **Erro Padr√£o ({std_err:.2f})**
            - **O que √©:** Mede a incerteza na estimativa do coeficiente angular
            - **Interpreta√ß√£o:** Quanto menor, mais precisa √© a estimativa da tend√™ncia
            """)
            
            # Interpreta√ß√£o da tend√™ncia
            if slope > 0:
                st.success("üìà **Tend√™ncia:** Aumento nos casos ao longo do tempo")
            elif slope < 0:
                st.success("üìâ **Tend√™ncia:** Diminui√ß√£o nos casos ao longo do tempo")
            else:
                st.info("‚û°Ô∏è **Tend√™ncia:** Est√°vel ao longo do tempo")
        else:
            st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de tend√™ncia")
        
        # Resumo estat√≠stico
        st.subheader("üìã **Resumo Estat√≠stico**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Estat√≠sticas Descritivas dos Casos:**")
            st.dataframe(casos_por_ano['Casos_Notificados'].describe())
        
        with col2:
            st.write("**Dados por Ano:**")
            st.dataframe(casos_por_ano)
        
        # Informa√ß√µes sobre a an√°lise
        st.subheader("‚ÑπÔ∏è **Sobre a An√°lise**")
        st.markdown("""
        **Esta an√°lise mostra:**
        - Evolu√ß√£o temporal dos casos de meningite
        - Padr√µes sazonais (quando dispon√≠veis)
        - Tend√™ncias estat√≠sticas significativas
        - Distribui√ß√£o temporal dos casos
        
        **Import√¢ncia:**
        - Identificar per√≠odos de maior risco
        - Planejar a√ß√µes de preven√ß√£o
        - Avaliar efetividade de medidas de controle
        """)
    else:
        st.warning("‚ö†Ô∏è Dados de casos n√£o dispon√≠veis")

def show_sorogrupos_analysis(dados):
    """Exibe a se√ß√£o "An√°lise de Sorogrupos e Rela√ß√µes N√£o Lineares".

    Esta fun√ß√£o realiza uma an√°lise aprofundada dos sorogrupos de meningite.
    Ela calcula e exibe a letalidade por sorogrupo, explora rela√ß√µes n√£o lineares
    entre casos e letalidade com regress√£o polinomial, realiza an√°lises de
    correla√ß√£o de Pearson e Spearman, e oferece uma an√°lise de clustering (K-Means)
    para agrupar sorogrupos com perfis epidemiol√≥gicos semelhantes.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza a chave 'sorogrupos_consolidados'.
    """
    st.header("ü¶† **An√°lise de Sorogrupos e Rela√ß√µes N√£o Lineares**")
    st.markdown("---")
    
    # Carregar dados de sorogrupos
    sorogrupos = dados['sorogrupos_consolidados']
    
    if sorogrupos is not None and not sorogrupos.empty:
        # M√©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = sorogrupos['Casos'].sum()
            st.metric("üìä Total de Casos", f"{total_casos:,}")
        
        with col2:
            total_obitos = sorogrupos['Obitos'].sum()
            st.metric("üíÄ Total de √ìbitos", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("‚ö†Ô∏è Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            n_sorogrupos = sorogrupos['Sorogrupo'].nunique()
            st.metric("ü¶† Sorogrupos", n_sorogrupos)
        
        # An√°lise de letalidade por sorogrupo
        st.subheader("üìä **Letalidade por Sorogrupo**")
        
        letalidade_por_sorogrupo = sorogrupos.groupby('Sorogrupo').agg({
            'Casos': 'sum',
            'Obitos': 'sum'
        }).reset_index()
        
        letalidade_por_sorogrupo['Letalidade'] = (
            letalidade_por_sorogrupo['Obitos'] / letalidade_por_sorogrupo['Casos'] * 100
        ).round(2)
        
        # Gr√°fico de barras
        fig_letalidade = px.bar(
            letalidade_por_sorogrupo,
            x='Sorogrupo',
            y='Letalidade',
            title="Letalidade por Sorogrupo",
            color='Letalidade',
            color_continuous_scale='Reds'
        )
        
        fig_letalidade.update_layout(
            yaxis_title="Taxa de Letalidade (%)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_letalidade, use_container_width=True)
        
        # Explica√ß√£o do gr√°fico de letalidade por sorogrupo
        st.markdown("""
        #### üìñ **Interpreta√ß√£o do Gr√°fico de Letalidade por Sorogrupo:**
        - **Eixo X (Horizontal):** Diferentes sorogrupos de meningite (A, B, C, W, Y, etc.)
        - **Eixo Y (Vertical):** Taxa de letalidade em percentual (√≥bitos/casos √ó 100)
        - **Barras coloridas:** Altura representa a letalidade, cores mais intensas = maior letalidade
        - **Import√¢ncia cl√≠nica:** Identifica quais sorogrupos s√£o mais letais e necessitam aten√ß√£o especial
        - **Aplica√ß√£o:** Orienta estrat√©gias de tratamento e prioriza√ß√£o de vacina√ß√£o
        """)
        
        # Mostrar tabela com dados detalhados
        st.markdown("#### üìã **Dados Detalhados por Sorogrupo:**")
        st.dataframe(letalidade_por_sorogrupo.sort_values('Letalidade', ascending=False))
        
        # An√°lise de rela√ß√µes n√£o lineares
        st.subheader("üîó **An√°lise de Rela√ß√µes N√£o Lineares**")
        
        # Preparar dados para an√°lise
        dados_analise = sorogrupos.groupby('Sorogrupo').agg({
            'Casos': 'sum',
            'Obitos': 'sum'
        }).reset_index()
        
        dados_analise['Letalidade'] = (
            dados_analise['Obitos'] / dados_analise['Casos'] * 100
        ).round(2)
        
        # Gr√°fico de dispers√£o com regress√£o polinomial
        fig_dispersao = px.scatter(
            dados_analise,
            x='Casos',
            y='Letalidade',
            title="Rela√ß√£o entre Casos e Letalidade por Sorogrupo",
            text='Sorogrupo',
            size='Casos'
        )
        
        # Adicionar linha de tend√™ncia polinomial
        if len(dados_analise) > 2:
            x = dados_analise['Casos'].values
            y = dados_analise['Letalidade'].values
            
            # Ajuste polinomial de grau 2
            coeffs = np.polyfit(x, y, 2)
            poly = np.poly1d(coeffs)
            
            x_trend = np.linspace(x.min(), x.max(), 100)
            y_trend = poly(x_trend)
            
            fig_dispersao.add_trace(go.Scatter(
                x=x_trend,
                y=y_trend,
                mode='lines',
                name='Tend√™ncia Polinomial (grau 2)',
                line=dict(color='red', dash='dash')
            ))
        
        fig_dispersao.update_layout(
            xaxis_title="N√∫mero de Casos",
            yaxis_title="Taxa de Letalidade (%)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_dispersao, use_container_width=True)
        
        # Explica√ß√£o do gr√°fico de dispers√£o com regress√£o polinomial
        st.markdown("""
        #### üìñ **Interpreta√ß√£o do Gr√°fico de Dispers√£o com Regress√£o Polinomial:**
        - **Eixo X (Horizontal):** N√∫mero total de casos por sorogrupo
        - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
        - **Pontos:** Cada ponto representa um sorogrupo espec√≠fico
        - **Tamanho dos pontos:** Proporcional ao n√∫mero de casos (pontos maiores = mais casos)
        - **Linha tracejada vermelha:** Tend√™ncia polinomial de grau 2 (curva que melhor se ajusta aos dados)
        - **An√°lise n√£o-linear:** Permite identificar rela√ß√µes complexas que n√£o seguem uma linha reta
        - **Interpreta√ß√£o epidemiol√≥gica:** 
          - Se a curva √© crescente: sorogrupos com mais casos tendem a ter maior letalidade
          - Se a curva √© decrescente: sorogrupos com mais casos tendem a ter menor letalidade
          - Curva em U ou invertida: rela√ß√£o complexa que requer investiga√ß√£o detalhada
        """)
        
        # An√°lise de correla√ß√£o
        st.subheader("üìä **An√°lise de Correla√ß√£o**")
        
        if len(dados_analise) > 2:
            # Correla√ß√£o de Pearson
            corr_pearson, p_pearson = stats.pearsonr(dados_analise['Casos'], dados_analise['Letalidade'])
            
            # Correla√ß√£o de Spearman
            corr_spearman, p_spearman = stats.spearmanr(dados_analise['Casos'], dados_analise['Letalidade'])
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("üìà Correla√ß√£o de Pearson", f"{corr_pearson:.3f}")
                st.write(f"P-valor: {p_pearson:.4f}")
                st.write("**Interpreta√ß√£o:** Mede correla√ß√£o linear")
                if abs(corr_pearson) > 0.7:
                    st.write("**For√ßa:** Correla√ß√£o forte")
                elif abs(corr_pearson) > 0.3:
                    st.write("**For√ßa:** Correla√ß√£o moderada")
                else:
                    st.write("**For√ßa:** Correla√ß√£o fraca")
            
            with col2:
                st.metric("üìä Correla√ß√£o de Spearman", f"{corr_spearman:.3f}")
                st.write(f"P-valor: {p_spearman:.4f}")
                st.write("**Interpreta√ß√£o:** Mede correla√ß√£o monot√¥nica")
                if abs(corr_spearman) > 0.7:
                    st.write("**For√ßa:** Correla√ß√£o forte")
                elif abs(corr_spearman) > 0.3:
                    st.write("**For√ßa:** Correla√ß√£o moderada")
                else:
                    st.write("**For√ßa:** Correla√ß√£o fraca")
            
            # Interpreta√ß√£o das correla√ß√µes
            st.markdown(f"""
            ### üìö **Explica√ß√£o Detalhada das Correla√ß√µes:**
            
            #### üìà **Correla√ß√£o de Pearson = {corr_pearson:.3f}**
            - **O que mede:** For√ßa da rela√ß√£o linear entre n√∫mero de casos e letalidade
            - **Escala:** -1 a +1
            - **Interpreta√ß√£o atual:**
              - Valor = {corr_pearson:.3f}
              - {"Correla√ß√£o positiva" if corr_pearson > 0 else "Correla√ß√£o negativa" if corr_pearson < 0 else "Sem correla√ß√£o"}
              - P-valor = {p_pearson:.4f} ‚Üí {"Estatisticamente significativa" if p_pearson < 0.05 else "N√£o significativa"}
            - **Limita√ß√µes:** Assume rela√ß√£o linear, sens√≠vel a outliers
            
            #### üìä **Correla√ß√£o de Spearman = {corr_spearman:.3f}**
            - **O que mede:** For√ßa da rela√ß√£o monot√¥nica (crescente ou decrescente)
            - **Escala:** -1 a +1
            - **Interpreta√ß√£o atual:**
              - Valor = {corr_spearman:.3f}
              - {"Rela√ß√£o monot√¥nica positiva" if corr_spearman > 0 else "Rela√ß√£o monot√¥nica negativa" if corr_spearman < 0 else "Sem rela√ß√£o monot√¥nica"}
              - P-valor = {p_spearman:.4f} ‚Üí {"Estatisticamente significativa" if p_spearman < 0.05 else "N√£o significativa"}
            - **Vantagens:** Detecta rela√ß√µes n√£o-lineares, robusto a outliers
            
            #### üîç **Compara√ß√£o dos Resultados:**
            - **Diferen√ßa:** {abs(corr_pearson - corr_spearman):.3f}
            - **Interpreta√ß√£o:** {"Rela√ß√£o aproximadamente linear" if abs(corr_pearson - corr_spearman) < 0.1 else "Poss√≠vel rela√ß√£o n√£o-linear"}
            
            #### üìã **Escalas de Interpreta√ß√£o:**
            - **0.0 - 0.3:** Correla√ß√£o fraca
            - **0.3 - 0.7:** Correla√ß√£o moderada
            - **0.7 - 1.0:** Correla√ß√£o forte
            """)
        
        # Evolu√ß√£o temporal da letalidade
        st.subheader("üìà **Evolu√ß√£o Temporal da Letalidade**")
        
        if 'Ano' in sorogrupos.columns:
            letalidade_temporal = sorogrupos.groupby(['Ano', 'Sorogrupo']).agg({
                'Casos': 'sum',
                'Obitos': 'sum'
            }).reset_index()
            
            letalidade_temporal['Letalidade'] = (
                letalidade_temporal['Obitos'] / letalidade_temporal['Casos'] * 100
            ).round(2)
            
            # Gr√°fico de linha
            fig_temporal = px.line(
                letalidade_temporal,
                x='Ano',
                y='Letalidade',
                color='Sorogrupo',
                title="Evolu√ß√£o da Letalidade por Sorogrupo ao Longo do Tempo",
                markers=True
            )
            
            fig_temporal.update_layout(
                xaxis_title="Ano",
                yaxis_title="Taxa de Letalidade (%)",
                template='plotly_white'
            )
            
            fig_temporal.update_xaxes(tickformat='d')
            st.plotly_chart(fig_temporal, use_container_width=True)
        
        # An√°lise de clustering
        st.subheader("üéØ **An√°lise de Clustering**")
        
        if len(dados_analise) > 3:
            # Preparar dados para clustering
            dados_cluster = dados_analise[['Casos', 'Letalidade']].copy()
            
            # Normalizar dados
            scaler = StandardScaler()
            dados_cluster_norm = scaler.fit_transform(dados_cluster)
            
            # N√∫mero de clusters
            n_clusters = st.slider("N√∫mero de Clusters:", 2, min(5, len(dados_cluster)), 3)
            
            if st.button("üéØ Executar Clustering"):
                try:
                    # Aplicar K-Means
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                    clusters = kmeans.fit_predict(dados_cluster_norm)
                    
                    # Adicionar clusters aos dados
                    dados_cluster['Cluster'] = clusters
                    
                    # Gr√°fico de clusters
                    fig_cluster = px.scatter(
                        dados_cluster,
                        x='Casos',
                        y='Letalidade',
                        color='Cluster',
                        title=f"Clusters de Sorogrupos (K={n_clusters})",
                        text=dados_analise['Sorogrupo'],
                        size='Casos'
                    )
                    
                    fig_cluster.update_layout(
                        xaxis_title="N√∫mero de Casos",
                        yaxis_title="Taxa de Letalidade (%)",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_cluster, use_container_width=True)
                    
                    # Explica√ß√£o do gr√°fico de clustering K-Means
                    st.markdown(f"""
                    #### üìñ **Interpreta√ß√£o do Gr√°fico de Clustering K-Means:**
                    - **Eixo X (Horizontal):** N√∫mero de casos por sorogrupo
                    - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
                    - **Cores diferentes:** Cada cor representa um cluster diferente
                    - **Tamanho dos pontos:** Proporcional ao n√∫mero de casos
                    - **Algoritmo:** K-Means agrupa sorogrupos similares em casos e letalidade
                    
                    #### üéØ **Como interpretar os clusters:**
                    - **Cluster 0:** Sorogrupos com caracter√≠sticas similares de casos/letalidade
                    - **Proximidade:** Sorogrupos no mesmo cluster t√™m comportamento epidemiol√≥gico similar
                    - **Separa√ß√£o:** Clusters distintos indicam perfis epidemiol√≥gicos diferentes
                    - **Aplica√ß√£o pr√°tica:** Permite estrat√©gias de controle diferenciadas por cluster
                    """)
                    
                    # Resumo dos clusters
                    st.subheader("üìä **Resumo dos Clusters**")
                    for i in range(n_clusters):
                        cluster_data = dados_cluster[dados_cluster['Cluster'] == i]
                        st.write(f"**Cluster {i}:** {len(cluster_data)} sorogrupos")
                        for idx in cluster_data.index:
                            sorogrupo = dados_analise.loc[idx, 'Sorogrupo']
                            casos = cluster_data.loc[idx, 'Casos']
                            letalidade = cluster_data.loc[idx, 'Letalidade']
                            st.write(f"  - {sorogrupo}: {casos} casos, {letalidade:.1f}% letalidade")
                    
                except Exception as e:
                    st.error(f"Erro no clustering: {e}")
        
        # Resumo das an√°lises
        st.markdown("---")
        st.markdown("""
        **üìã Resumo das An√°lises de Sorogrupos:**
        
        **1. An√°lise de Letalidade:**
        - Identifica√ß√£o dos sorogrupos mais letais
        - Compara√ß√£o entre diferentes tipos
        - Padr√µes de mortalidade
        
        **2. Rela√ß√µes N√£o Lineares:**
        - An√°lise de correla√ß√µes complexas
        - Identifica√ß√£o de padr√µes n√£o lineares
        - Regress√£o polinomial para tend√™ncias
        
        **3. An√°lise Temporal:**
        - Evolu√ß√£o da letalidade ao longo do tempo
        - Identifica√ß√£o de tend√™ncias
        - Compara√ß√£o entre per√≠odos
        
        **4. Clustering:**
        - Agrupamento de sorogrupos similares
        - Identifica√ß√£o de padr√µes ocultos
        - An√°lise de similaridades epidemiol√≥gicas
        """)
        
    else:
        st.error("‚ùå Dados de sorogrupos n√£o dispon√≠veis")

def show_etiologia_analysis(dados):
    """Exibe a se√ß√£o "An√°lise por Etiologia e An√°lise de Componentes Principais".

    Esta fun√ß√£o consolida e analisa os dados de meningite por etiologia (agente causador).
    Ela padroniza os nomes das etiologias, exibe a distribui√ß√£o de casos e letalidade,
    e realiza an√°lises avan√ßadas como An√°lise de Componentes Principais (PCA) para
    redu√ß√£o de dimensionalidade, uma matriz de correla√ß√£o para identificar padr√µes
    temporais entre etiologias, e an√°lise de sazonalidade.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves
                      'etiologias_consolidadas', 'etiologia_2024', e 'sih_meningite'.
    """
    st.header("üß¨ **An√°lise por Etiologia e An√°lise de Componentes Principais**")
    st.markdown("---")
    
    # Carregar e consolidar dados de etiologia
    etiologia_consolidada = dados['etiologias_consolidadas']
    etiologia_2024 = dados['etiologia_2024']
    
    if etiologia_consolidada is not None and not etiologia_consolidada.empty:
        # Padronizar nomes das etiologias para remover duplicatas
        mapeamento_etiologias = {
            'Doen√ßa Meningoc√≥cica': 'Meningite Meningoc√≥cica',
            'Doen√ßa meningoc√≥cica': 'Meningite Meningoc√≥cica',
            'Meningite Pneumoc√≥cica': 'Meningite Pneumoc√≥cica',
            'Meningite pneumoc√≥cica': 'Meningite Pneumoc√≥cica',
            'Meningite Tuberculosa': 'Meningite Tuberculosa',
            'Meningite tuberculosa': 'Meningite Tuberculosa',
            'Meningite bacteriana': 'Meningite Bacteriana',
            'Meningite bacteriana n√£o especificada': 'Meningite Bacteriana',
            'Meningite por hem√≥filo': 'Meningite por Hem√≥filo',
            'Meningite por outras bact√©rias': 'Meningite por Outras Bact√©rias',
            'Meningite viral': 'Meningite Viral',
            'Meningite de outra etiologia': 'Meningite de Outra Etiologia',
            'Meningite n√£o especificada': 'Meningite N√£o Especificada',
            'Ignorado/sem informa√ß√£o': 'Ignorado/Sem Informa√ß√£o'
        }
        
        # Aplicar mapeamento e consolidar dados
        etiologia_consolidada['Etiologia_Padronizada'] = etiologia_consolidada['Etiologia'].map(mapeamento_etiologias).fillna(etiologia_consolidada['Etiologia'])
        
        # Se temos dados de 2024, adicionar ao consolidado
        if etiologia_2024 is not None and not etiologia_2024.empty:
            etiologia_2024['Etiologia_Padronizada'] = etiologia_2024['Etiologia'].map(mapeamento_etiologias).fillna(etiologia_2024['Etiologia'])
            
            # Adicionar dados de 2024 ao consolidado
            for _, row in etiologia_2024.iterrows():
                etiologia_consolidada = pd.concat([
                    etiologia_consolidada,
                    pd.DataFrame([{
                        'Ano': row['Ano'],
                        'Etiologia': row['Etiologia'],
                        'Etiologia_Padronizada': row['Etiologia_Padronizada'],
                        'Casos': row['Casos'],
                        'Obitos': row['Obitos'],
                        'Letalidade': row['Letalidade'],
                        'Taxa_Letalidade': row['Letalidade']
                    }])
                ], ignore_index=True)
        
        # Usar a coluna padronizada para an√°lises
        etiologia = etiologia_consolidada.copy()
        etiologia['Etiologia'] = etiologia['Etiologia_Padronizada']
        
        # Remover duplicatas baseadas em Ano e Etiologia padronizada
        etiologia = etiologia.drop_duplicates(subset=['Ano', 'Etiologia'], keep='first')
        
        # M√©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_casos = etiologia['Casos'].sum() if 'Casos' in etiologia.columns else 0
            st.metric("üìä Total de Casos", f"{total_casos:,}")
        
        with col2:
            total_obitos = etiologia['Obitos'].sum() if 'Obitos' in etiologia.columns else 0
            st.metric("üíÄ Total de √ìbitos", f"{total_obitos:,}")
        
        with col3:
            letalidade_geral = (total_obitos / total_casos * 100) if total_casos > 0 else 0
            st.metric("‚ö†Ô∏è Letalidade Geral", f"{letalidade_geral:.1f}%")
        
        with col4:
            n_etiologias = etiologia['Etiologia'].nunique()
            st.metric("üß¨ Etiologias √önicas", n_etiologias)
        
        # Diagn√≥stico das etiologias
        st.subheader("üîç **Diagn√≥stico das Etiologias**")
        
        # Mostrar etiologias √∫nicas
        etiologias_unicas = sorted(etiologia['Etiologia'].unique())
        st.write(f"**Etiologias √∫nicas encontradas ({len(etiologias_unicas)}):**")
        
        # Criar colunas para melhor visualiza√ß√£o
        n_cols = 3
        for i in range(0, len(etiologias_unicas), n_cols):
            cols = st.columns(n_cols)
            for j, col in enumerate(cols):
                if i + j < len(etiologias_unicas):
                    with col:
                        st.write(f"‚Ä¢ {etiologias_unicas[i + j]}")
        
        # Verificar poss√≠veis duplicatas por nome similar
        st.write("**Verifica√ß√£o de poss√≠veis duplicatas:**")
        etiologias_lower = [et.lower().strip() for et in etiologias_unicas]
        possiveis_duplicatas = []
        
        for i, et1 in enumerate(etiologias_lower):
            for j, et2 in enumerate(etiologias_lower[i+1:], i+1):
                # Verificar similaridade (nomes que diferem apenas por capitaliza√ß√£o ou espa√ßos)
                if et1 == et2 or et1.replace(' ', '') == et2.replace(' ', ''):
                    possiveis_duplicatas.append((etiologias_unicas[i], etiologias_unicas[j]))
        
        if possiveis_duplicatas:
            st.warning("‚ö†Ô∏è **Poss√≠veis duplicatas encontradas:**")
            for dup1, dup2 in possiveis_duplicatas:
                st.write(f"‚Ä¢ '{dup1}' vs '{dup2}'")
        else:
            st.success("‚úÖ **Nenhuma duplicata √≥bvia encontrada**")
        
        st.markdown("---")
        
        # An√°lise de casos por etiologia
        st.subheader("üìä **Casos por Etiologia**")
        
        # Verificar se a coluna Casos existe e tratar valores NaN
        if 'Casos' in etiologia.columns:
            # Substituir valores NaN por 0 para an√°lise
            etiologia_analise = etiologia.copy()
            etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
            
            casos_por_etiologia = etiologia_analise.groupby('Etiologia')['Casos'].sum().sort_values(ascending=False)
            
            # Filtrar apenas etiologias com casos > 0 para melhor visualiza√ß√£o
            casos_por_etiologia = casos_por_etiologia[casos_por_etiologia > 0]
            
            if len(casos_por_etiologia) > 0:
                fig_casos = px.bar(
                    casos_por_etiologia,
                    x=casos_por_etiologia.index,
                    y=casos_por_etiologia.values,
                    title="Distribui√ß√£o de Casos por Etiologia",
                    color=casos_por_etiologia.values,
                    color_continuous_scale='Blues'
                )
                
                fig_casos.update_layout(
                    xaxis_title="Etiologia",
                    yaxis_title="N√∫mero de Casos",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_casos, use_container_width=True)
                
                # Mostrar estat√≠sticas
                st.write(f"**Total de etiologias √∫nicas:** {len(casos_por_etiologia)}")
                st.write(f"**Etiologia com mais casos:** {casos_por_etiologia.index[0]} ({casos_por_etiologia.iloc[0]:,.0f} casos)")
            else:
                st.warning("‚ö†Ô∏è Nenhum caso encontrado nos dados de etiologia")
        else:
            st.warning("‚ö†Ô∏è Coluna 'Casos' n√£o encontrada nos dados de etiologia")
        
        # An√°lise de letalidade por etiologia
        st.subheader("‚ö†Ô∏è **Letalidade por Etiologia**")
        
        # Verificar se as colunas necess√°rias existem
        if 'Casos' in etiologia.columns and 'Obitos' in etiologia.columns:
            # Substituir valores NaN por 0 para an√°lise
            etiologia_analise = etiologia.copy()
            etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
            etiologia_analise['Obitos'] = etiologia_analise['Obitos'].fillna(0)
            
            letalidade_por_etiologia = etiologia_analise.groupby('Etiologia').agg({
                'Casos': 'sum',
                'Obitos': 'sum'
            }).reset_index()
            
            # Calcular letalidade apenas para etiologias com casos > 0
            letalidade_por_etiologia = letalidade_por_etiologia[letalidade_por_etiologia['Casos'] > 0]
            
            if len(letalidade_por_etiologia) > 0:
                letalidade_por_etiologia['Letalidade'] = (
                    letalidade_por_etiologia['Obitos'] / letalidade_por_etiologia['Casos'] * 100
                ).round(2)
                
                # Substituir valores infinitos por 0
                letalidade_por_etiologia['Letalidade'] = letalidade_por_etiologia['Letalidade'].replace([np.inf, -np.inf], 0)
                
                fig_letalidade = px.bar(
                    letalidade_por_etiologia,
                    x='Etiologia',
                    y='Letalidade',
                    title="Letalidade por Etiologia",
                    color='Letalidade',
                    color_continuous_scale='Reds'
                )
                
                fig_letalidade.update_layout(
                    yaxis_title="Taxa de Letalidade (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_letalidade, use_container_width=True)
                
                # Mostrar estat√≠sticas
                st.write(f"**Total de etiologias com dados v√°lidos:** {len(letalidade_por_etiologia)}")
                st.write(f"**Etiologia com maior letalidade:** {letalidade_por_etiologia.loc[letalidade_por_etiologia['Letalidade'].idxmax(), 'Etiologia']} ({letalidade_por_etiologia['Letalidade'].max():.1f}%)")
            else:
                st.warning("‚ö†Ô∏è Nenhuma etiologia com casos v√°lidos encontrada")
        else:
            st.warning("‚ö†Ô∏è Colunas 'Casos' e/ou 'Obitos' n√£o encontradas nos dados de etiologia")
        
        # An√°lise de Componentes Principais (PCA)
        st.subheader("üî¨ **An√°lise de Componentes Principais (PCA)**")
        
        if len(letalidade_por_etiologia) > 2:
            try:
                from sklearn.decomposition import PCA
                
                # Preparar dados para PCA - tratar valores NaN
                dados_pca = letalidade_por_etiologia[['Casos', 'Letalidade']].copy()
                
                # Substituir valores NaN por 0 para permitir an√°lise PCA
                dados_pca = dados_pca.fillna(0)
                
                # Verificar se ainda h√° dados v√°lidos ap√≥s tratamento
                if dados_pca.isnull().sum().sum() == 0 and dados_pca.shape[0] > 0:
                    # Normalizar dados
                    scaler = StandardScaler()
                    dados_pca_norm = scaler.fit_transform(dados_pca)
                    
                    # Aplicar PCA
                    pca = PCA(n_components=min(2, dados_pca.shape[1]))
                    componentes = pca.fit_transform(dados_pca_norm)
                    
                    # Criar DataFrame com componentes
                    df_pca = pd.DataFrame(
                        componentes,
                        columns=[f'Componente {i+1}' for i in range(componentes.shape[1])],
                        index=letalidade_por_etiologia['Etiologia']
                    )
                    
                    # Gr√°fico de componentes
                    if componentes.shape[1] >= 2:
                        fig_pca = px.scatter(
                            df_pca,
                            x='Componente 1',
                            y='Componente 2',
                            title="An√°lise de Componentes Principais",
                            text=df_pca.index,
                            size=[10] * len(df_pca)
                        )
                        
                        fig_pca.update_layout(template='plotly_white')
                        st.plotly_chart(fig_pca, use_container_width=True)
                        
                        # Explica√ß√£o do gr√°fico de PCA 2D
                        st.markdown("""
                        #### üìñ **Interpreta√ß√£o do Gr√°fico de PCA (2 Componentes):**
                        - **Eixo X (Horizontal):** Componente Principal 1 (dire√ß√£o de maior varia√ß√£o)
                        - **Eixo Y (Vertical):** Componente Principal 2 (segunda maior dire√ß√£o de varia√ß√£o)
                        - **Pontos:** Cada ponto representa uma etiologia no espa√ßo reduzido
                        - **Dist√¢ncia entre pontos:** Etiologias pr√≥ximas t√™m comportamentos similares
                        - **Posi√ß√£o nos quadrantes:** Diferentes combina√ß√µes de casos e letalidade
                        - **Redu√ß√£o dimensional:** Simplifica an√°lise de m√∫ltiplas vari√°veis em 2D
                        """)
                    else:
                        # Se s√≥ temos 1 componente, mostrar como gr√°fico de barras
                        fig_pca = px.bar(
                            x=df_pca.index,
                            y=df_pca['Componente 1'],
                            title="An√°lise de Componentes Principais (1 Componente)",
                            labels={'x': 'Etiologia', 'y': 'Componente 1'}
                        )
                        fig_pca.update_layout(template='plotly_white')
                        st.plotly_chart(fig_pca, use_container_width=True)
                        
                        # Explica√ß√£o do gr√°fico de PCA 1D
                        st.markdown("""
                        #### üìñ **Interpreta√ß√£o do Gr√°fico de PCA (1 Componente):**
                        - **Eixo X (Horizontal):** Diferentes etiologias
                        - **Eixo Y (Vertical):** Valor do Componente Principal 1
                        - **Altura das barras:** Representa a proje√ß√£o de cada etiologia no componente principal
                        - **Valores positivos/negativos:** Indicam diferentes padr√µes de casos e letalidade
                        - **Utilidade:** Ordena etiologias por sua similaridade em um eixo principal
                        """)
                    
                    # Informa√ß√µes sobre PCA
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**Vari√¢ncia Explicada:**")
                        for i, var in enumerate(pca.explained_variance_ratio_):
                            st.write(f"Componente {i+1}: {var:.3f} ({var*100:.1f}%)")
                    
                    with col2:
                        st.write("**Componentes Principais:**")
                        st.write("**Componente 1:** Combina√ß√£o linear de Casos e Letalidade")
                        if componentes.shape[1] > 1:
                            st.write("**Componente 2:** Combina√ß√£o ortogonal ao Componente 1")
                    
                    # Interpreta√ß√£o detalhada dos componentes
                    st.markdown(f"""
                    ### üìö **Explica√ß√£o Detalhada do PCA:**
                    
                    #### üéØ **O que √© PCA:**
                    - **An√°lise de Componentes Principais:** T√©cnica de redu√ß√£o dimensional
                    - **Objetivo:** Encontrar dire√ß√µes de m√°xima vari√¢ncia nos dados
                    - **Utilidade:** Simplifica dados complexos mantendo a informa√ß√£o principal
                    
                    #### üìä **Vari√¢ncia Explicada Total:** {sum(pca.explained_variance_ratio_)*100:.1f}%
                    - **Componente 1:** {pca.explained_variance_ratio_[0]*100:.1f}% da vari√¢ncia
                      - Captura a principal diferen√ßa entre etiologias
                      - Combina casos e letalidade de forma otimizada
                    """)
                    
                    if componentes.shape[1] > 1:
                        st.markdown(f"""
                    - **Componente 2:** {pca.explained_variance_ratio_[1]*100:.1f}% da vari√¢ncia
                      - Captura varia√ß√£o restante n√£o explicada pelo C1
                      - Perpendicular ao Componente 1 (ortogonal)
                      - Revela padr√µes secund√°rios nos dados
                    
                    #### üéØ **Interpreta√ß√£o Epidemiol√≥gica:**
                    - **Quadrante superior direito:** Etiologias graves (muitos casos + alta letalidade)
                    - **Quadrante inferior esquerdo:** Etiologias menos problem√°ticas
                    - **Outros quadrantes:** Padr√µes espec√≠ficos que merecem investiga√ß√£o
                        """)
                    else:
                        st.markdown("""
                    #### üéØ **Interpreta√ß√£o do Componente √önico:**
                    - **Valores altos:** Etiologias com maior impacto epidemiol√≥gico
                    - **Valores baixos:** Etiologias com menor impacto
                    - **Ordena√ß√£o:** Permite prioriza√ß√£o de recursos de sa√∫de
                        """)
                    
                    # Mostrar cargas dos componentes (loadings)
                    st.markdown("#### üî¢ **Cargas dos Componentes (Loadings):**")
                    loadings_df = pd.DataFrame(
                        pca.components_.T,
                        columns=[f'Componente {i+1}' for i in range(pca.components_.shape[0])],
                        index=['Casos', 'Letalidade']
                    )
                    st.dataframe(loadings_df.round(3))
                    
                    st.markdown("""
                    **üìã Como interpretar as cargas:**
                    - **Valores positivos:** Vari√°vel contribui positivamente para o componente
                    - **Valores negativos:** Vari√°vel contribui negativamente para o componente
                    - **Magnitude:** Quanto maior o valor absoluto, maior a import√¢ncia da vari√°vel
                    """)
                    
                    # Mostrar dados tratados
                    st.write("**Dados utilizados no PCA (NaN substitu√≠dos por 0):**")
                    st.dataframe(dados_pca.round(2))
                    
                else:
                    st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise PCA ap√≥s tratamento de valores NaN")
                
            except Exception as e:
                st.warning(f"Erro na an√°lise PCA: {e}")
                st.write(f"Detalhes do erro: {str(e)}")
        
        # Matriz de correla√ß√£o entre etiologias
        st.subheader("üîó **Matriz de Correla√ß√£o entre Etiologias**")
        
        if 'Ano' in etiologia.columns and 'Casos' in etiologia.columns:
            try:
                # Preparar dados para correla√ß√£o - tratar valores NaN
                etiologia_analise = etiologia.copy()
                etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
                
                dados_correlacao = etiologia_analise.pivot_table(
                    index='Ano',
                    columns='Etiologia',
                    values='Casos',
                    aggfunc='sum'
                ).fillna(0)
                
                if len(dados_correlacao.columns) > 1 and dados_correlacao.shape[0] > 1:
                    # Calcular correla√ß√£o
                    matriz_corr = dados_correlacao.corr()
                    
                    # Substituir valores NaN na correla√ß√£o por 0
                    matriz_corr = matriz_corr.fillna(0)
                    
                    # Gr√°fico de heatmap
                    fig_heatmap = px.imshow(
                        matriz_corr,
                        title="Matriz de Correla√ß√£o entre Etiologias",
                        color_continuous_scale='RdBu',
                        aspect='auto'
                    )
                    
                    fig_heatmap.update_layout(template='plotly_white')
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                    
                    # Explica√ß√£o do heatmap de correla√ß√£o
                    st.markdown("""
                    #### üìñ **Interpreta√ß√£o do Heatmap de Correla√ß√£o:**
                    - **Cores:** Intensidade da correla√ß√£o entre etiologias ao longo do tempo
                    - **Azul escuro:** Correla√ß√£o positiva forte (etiologias variam juntas)
                    - **Vermelho escuro:** Correla√ß√£o negativa forte (etiologias variam inversamente)
                    - **Branco/Neutro:** Sem correla√ß√£o (etiologias independentes)
                    - **Diagonal:** Sempre 1.0 (correla√ß√£o de cada etiologia consigo mesma)
                    - **Utilidade:** Identifica etiologias com padr√µes temporais similares ou opostos
                    """)
                    
                    # Tabela de correla√ß√µes
                    st.write("**Valores de Correla√ß√£o:**")
                    st.dataframe(matriz_corr.round(3))
                    
                    # Estat√≠sticas da correla√ß√£o
                    st.write(f"**Total de etiologias na correla√ß√£o:** {len(matriz_corr.columns)}")
                    st.write(f"**Per√≠odo analisado:** {dados_correlacao.index.min()} - {dados_correlacao.index.max()}")
                else:
                    st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise de correla√ß√£o (m√≠nimo 2 etiologias e 2 anos)")
            except Exception as e:
                st.warning(f"Erro na an√°lise de correla√ß√£o: {e}")
        else:
            st.warning("‚ö†Ô∏è Colunas 'Ano' e/ou 'Casos' n√£o encontradas para an√°lise de correla√ß√£o")
        

        # An√°lise de sazonalidade
        st.subheader("üå°Ô∏è **An√°lise de Sazonalidade**")
        
        if 'Mes' in etiologia.columns and 'Casos' in etiologia.columns:
            try:
                # Preparar dados sazonais - tratar valores NaN
                etiologia_analise = etiologia.copy()
                etiologia_analise['Casos'] = etiologia_analise['Casos'].fillna(0)
                
                dados_sazonais = etiologia_analise.groupby(['Mes', 'Etiologia'])['Casos'].sum().reset_index()
                
                # Filtrar apenas etiologias com pelo menos um caso
                etiologias_com_casos = dados_sazonais.groupby('Etiologia')['Casos'].sum()
                etiologias_com_casos = etiologias_com_casos[etiologias_com_casos > 0].index
                dados_sazonais = dados_sazonais[dados_sazonais['Etiologia'].isin(etiologias_com_casos)]
                
                if len(dados_sazonais) > 0:
                    # Gr√°fico de barras agrupadas
                    fig_sazonal = px.bar(
                        dados_sazonais,
                        x='Mes',
                        y='Casos',
                        color='Etiologia',
                        title="Sazonalidade dos Casos por Etiologia",
                        barmode='group'
                    )
                    
                    fig_sazonal.update_layout(
                        xaxis_title="M√™s",
                        yaxis_title="N√∫mero de Casos",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_sazonal, use_container_width=True)
                    
                    # Decomposi√ß√£o sazonal para uma etiologia espec√≠fica
                    if len(dados_sazonais) > 12:
                        st.write("**Decomposi√ß√£o Sazonal (Primeira Etiologia):**")
                        
                        primeira_etiologia = dados_sazonais['Etiologia'].iloc[0]
                        dados_etiologia = dados_sazonais[dados_sazonais['Etiologia'] == primeira_etiologia]
                        
                        if len(dados_etiologia) >= 12:
                            # Decomposi√ß√£o sazonal
                            decomposicao = seasonal_decompose(
                                dados_etiologia['Casos'].values,
                                period=12,
                                extrapolate_trend='freq'
                            )
                            
                            # Gr√°fico de decomposi√ß√£o
                            fig_decomp = make_subplots(
                                rows=4, cols=1,
                                subplot_titles=['Original', 'Tend√™ncia', 'Sazonal', 'Res√≠duos'],
                                vertical_spacing=0.1
                            )
                            
                            fig_decomp.add_trace(
                                go.Scatter(y=dados_etiologia['Casos'], name='Original'),
                                row=1, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.trend, name='Tend√™ncia'),
                                row=2, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.seasonal, name='Sazonal'),
                                row=3, col=1
                            )
                            fig_decomp.add_trace(
                                go.Scatter(y=decomposicao.resid, name='Res√≠duos'),
                                row=4, col=1
                            )
                            
                            fig_decomp.update_layout(
                                title=f"Decomposi√ß√£o Sazonal - {primeira_etiologia}",
                                height=600,
                                template='plotly_white'
                            )
                            
                            st.plotly_chart(fig_decomp, use_container_width=True)
                        else:
                            st.warning("‚ö†Ô∏è Dados insuficientes para decomposi√ß√£o sazonal (m√≠nimo 12 meses)")
                    else:
                        st.warning("‚ö†Ô∏è Dados insuficientes para an√°lise sazonal (m√≠nimo 12 meses)")
                else:
                    st.warning("‚ö†Ô∏è Nenhum dado sazonal v√°lido encontrado")
                    
            except Exception as e:
                st.warning(f"Erro na an√°lise sazonal: {e}")
        else:
            # Fallback: usar SIH mensal quando n√£o houver 'Mes' em dados de etiologia
            if 'sih_meningite' in dados and isinstance(dados['sih_meningite'], pd.DataFrame):
                sih = dados['sih_meningite'].copy()
                if {'M√™s_Num', 'Casos_Hospitalares'}.issubset(sih.columns):
                    sih['Casos_Hospitalares'] = pd.to_numeric(sih['Casos_Hospitalares'], errors='coerce').fillna(0)
                    mensal = sih.groupby('M√™s_Num', as_index=False)['Casos_Hospitalares'].sum()
                    nomes_meses = {1:'Jan',2:'Fev',3:'Mar',4:'Abr',5:'Mai',6:'Jun',7:'Jul',8:'Ago',9:'Set',10:'Out',11:'Nov',12:'Dez'}
                    mensal['Mes'] = mensal['M√™s_Num'].map(nomes_meses)
                    fig_sazonal = px.bar(
                        mensal.sort_values('M√™s_Num'), x='Mes', y='Casos_Hospitalares',
                        title='Sazonalidade (Hospitaliza√ß√µes SIH - proxy)', color='Casos_Hospitalares',
                        color_continuous_scale='Reds'
                    )
                    fig_sazonal.update_layout(template='plotly_white', xaxis_title='M√™s', yaxis_title='Casos Hospitalares')
                    st.plotly_chart(fig_sazonal, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è Colunas esperadas em SIH para sazonalidade n√£o encontradas (M√™s_Num, Casos_Hospitalares)")
            else:
                st.warning("‚ö†Ô∏è Colunas 'Mes' e/ou 'Casos' n√£o encontradas para an√°lise sazonal")
        
        # Resumo das an√°lises
        st.markdown("---")
        st.markdown("""
        **üìã Resumo das An√°lises de Etiologia:**
        
        **1. An√°lise Descritiva:**
        - Distribui√ß√£o de casos por etiologia
        - Padr√µes de letalidade
        - Compara√ß√£o entre diferentes agentes causadores
        
        **2. An√°lise de Componentes Principais:**
        - Redu√ß√£o de dimensionalidade
        - Identifica√ß√£o de padr√µes ocultos
        - Agrupamento de etiologias similares
        
        **3. An√°lise de Correla√ß√£o:**
        - Rela√ß√µes entre diferentes etiologias
        - Padr√µes de co-ocorr√™ncia
        - Identifica√ß√£o de surtos simult√¢neos
        
        **4. An√°lise Temporal:**
        - Evolu√ß√£o das etiologias ao longo do tempo
        - Padr√µes sazonais
        - Tend√™ncias de longo prazo
        """)
        
    else:
        st.error("‚ùå Dados de etiologia n√£o dispon√≠veis")

def show_imunizacao_analysis(dados):
    """Exibe a se√ß√£o "Dados de Imuniza√ß√£o e An√°lise de Impacto".

    Renderiza uma an√°lise completa sobre a vacina√ß√£o contra meningite. A fun√ß√£o
    apresenta a evolu√ß√£o da cobertura vacinal, a correla√ß√£o entre vacina√ß√£o e
    o n√∫mero de casos, a distribui√ß√£o regional da cobertura, e uma an√°lise
    preditiva usando o modelo ARIMA para prever tend√™ncias futuras de
    doses aplicadas e casos.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves 'imunizacao_ano',
                      'imunizacao_uf', 'imunizacao_2023_2025', 'imunizacao_processada',
                      e 'casos_consolidados'.
    """
    st.header("üíâ **Dados de Imuniza√ß√£o e An√°lise de Impacto**")
    st.markdown("---")
    
    # Carregar dados de imuniza√ß√£o
    imunizacao_ano = dados.get('imunizacao_ano')
    imunizacao_uf = dados.get('imunizacao_uf')
    imunizacao_2023_2025 = dados.get('imunizacao_2023_2025')
    
    if (dados.get('imunizacao_processada') is not None and not dados['imunizacao_processada'].empty) or (imunizacao_ano is not None and not imunizacao_ano.empty):
        # M√©tricas gerais
        col1, col2, col3, col4 = st.columns(4)
        
        if dados.get('imunizacao_processada') is not None and not dados['imunizacao_processada'].empty:
            proc = dados['imunizacao_processada']
            with col1:
                total_doses = int(proc['Total_Nacional'].sum()) if 'Total_Nacional' in proc.columns else 0
                st.metric("üíâ Total de Doses", f"{total_doses:,}")
            with col2:
                # Cobertura m√©dia pode n√£o existir; usar proxy: m√©dia anual normalizada por 1e6 para legibilidade
                if 'Total_Nacional' in proc.columns:
                    cobertura_media_proxy = proc.groupby('Ano')['Total_Nacional'].sum().mean() / 1_000_000
                    st.metric("üìä M√©dia Anual de Doses (mi)", f"{cobertura_media_proxy:.2f}")
                else:
                    st.metric("üìä M√©dia Anual de Doses (mi)", "N/A")
            with col3:
                n_anos = proc['Ano'].nunique() if 'Ano' in proc.columns else 0
                st.metric("üìÖ Anos de Dados", n_anos)
        else:
            with col1:
                total_doses = imunizacao_ano['Doses'].sum() if 'Doses' in imunizacao_ano.columns else 0
                st.metric("üíâ Total de Doses", f"{total_doses:,}")
            with col2:
                total_cobertura = imunizacao_ano['Cobertura'].mean() if 'Cobertura' in imunizacao_ano.columns else 0
                st.metric("üìä Cobertura M√©dia", f"{total_cobertura:.1f}%")
            with col3:
                n_anos = imunizacao_ano['Ano'].nunique() if 'Ano' in imunizacao_ano.columns else 0
                st.metric("üìÖ Anos de Dados", n_anos)
        
        with col4:
            n_ufs = imunizacao_uf['UF'].nunique() if imunizacao_uf is not None and not imunizacao_uf.empty else 0
            st.metric("üó∫Ô∏è UFs Cobertas", n_ufs)
        
        # An√°lise de impacto da vacina√ß√£o
        st.subheader("üìä **An√°lise de Impacto da Vacina√ß√£o**")
        
        # Preferir base processada se existir
        if dados.get('imunizacao_processada') is not None:
            base_ano = dados['imunizacao_processada'][['Ano', 'Total_Nacional']].dropna()
            base_ano = base_ano.groupby('Ano', as_index=False)['Total_Nacional'].sum()
            base_ano.rename(columns={'Total_Nacional': 'Cobertura'}, inplace=True)
        else:
            base_ano = imunizacao_ano if ('Ano' in imunizacao_ano.columns and 'Cobertura' in imunizacao_ano.columns) else None

        if base_ano is not None and 'Ano' in base_ano.columns and 'Cobertura' in base_ano.columns:
            # Limpar anos inv√°lidos
            base_ano['Ano'] = pd.to_numeric(base_ano['Ano'], errors='coerce')
            base_ano = base_ano.dropna(subset=['Ano'])
            base_ano = base_ano[(base_ano['Ano'] >= 1900) & (base_ano['Ano'] <= 2100)]
            base_ano['Ano'] = base_ano['Ano'].astype(int)
            # Preparar dados para an√°lise de impacto
            dados_impacto = base_ano.groupby('Ano').agg({
                'Cobertura': 'mean',
                **({'Doses': 'sum'} if ('Doses' in imunizacao_ano.columns) else {})
            }).reset_index()
            
            # Gr√°fico de evolu√ß√£o
            fig_cobertura = px.line(dados_impacto.assign(AnoDT=pd.to_datetime(dados_impacto['Ano'].astype(int), format='%Y', errors='coerce').dropna()), x='AnoDT', y='Cobertura',
                                    title=("Evolu√ß√£o do Total de Doses Aplicadas" if dados.get('imunizacao_processada') is not None else "Evolu√ß√£o da Cobertura Vacinal ao Longo do Tempo"),
                                    markers=True)
            
            fig_cobertura.update_layout(xaxis_title="Ano", yaxis_title=("Total de Doses" if dados.get('imunizacao_processada') is not None else "Cobertura Vacinal (%)"), template='plotly_white')
            fig_cobertura.update_xaxes(tickformat='%Y')
            st.plotly_chart(fig_cobertura, use_container_width=True)
            
            # Explica√ß√£o do gr√°fico de evolu√ß√£o da cobertura vacinal
            st.markdown("""
            #### üìñ **Interpreta√ß√£o do Gr√°fico de Evolu√ß√£o da Cobertura Vacinal:**
            - **Eixo X (Horizontal):** Anos do per√≠odo analisado
            - **Eixo Y (Vertical):** Cobertura vacinal (%) ou n√∫mero total de doses aplicadas
            - **Linha com marcadores:** Evolu√ß√£o temporal da vacina√ß√£o contra meningite
            - **Tend√™ncia crescente:** Melhoria na cobertura vacinal ao longo do tempo
            - **Tend√™ncia decrescente:** Poss√≠vel redu√ß√£o na ades√£o ou mudan√ßas nas pol√≠ticas
            - **Varia√ß√µes abruptas:** Podem indicar mudan√ßas em campanhas, disponibilidade de vacinas ou eventos espec√≠ficos
            - **Import√¢ncia epidemiol√≥gica:** Cobertura alta (>95%) √© essencial para imunidade coletiva
            - **Meta de sa√∫de p√∫blica:** Monitoramento da efic√°cia das campanhas de vacina√ß√£o
            """)
            
            # An√°lise de correla√ß√£o com casos de meningite
            if 'casos_consolidados' in dados and dados['casos_consolidados'] is not None:
                st.write("**üîó Correla√ß√£o entre Cobertura Vacinal e Casos de Meningite:**")
                
                casos_por_ano = dados['casos_consolidados'].groupby('Ano')['Casos_Notificados'].sum().reset_index()
                # Renomear para 'Casos' para compatibilidade com a an√°lise
                casos_por_ano = casos_por_ano.rename(columns={'Casos_Notificados': 'Casos'})
                
                # Mesclar dados
                dados_correlacao = dados_impacto.merge(casos_por_ano, on='Ano', how='inner')
                
                if len(dados_correlacao) > 2:
                    # Calcular correla√ß√£o
                    corr_cobertura_casos, p_valor = stats.pearsonr(
                        dados_correlacao['Cobertura'],
                        dados_correlacao['Casos']
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("üìà Correla√ß√£o", f"{corr_cobertura_casos:.3f}")
                        st.write(f"P-valor: {p_valor:.4f}")
                    
                    with col2:
                        if p_valor < 0.05:
                            if corr_cobertura_casos < 0:
                                st.success("‚úÖ Correla√ß√£o significativa negativa")
                                st.write("Maior cobertura = Menos casos")
                            else:
                                st.warning("‚ö†Ô∏è Correla√ß√£o significativa positiva")
                                st.write("Maior cobertura = Mais casos")
                        else:
                            st.info("‚ÑπÔ∏è Sem correla√ß√£o significativa")
                    
                    # Gr√°fico de dispers√£o
                    fig_dispersao = px.scatter(
                        dados_correlacao,
                        x='Cobertura',
                        y='Casos',
                        title="Rela√ß√£o entre Cobertura Vacinal e Casos de Meningite",
                        text='Ano',
                        size='Cobertura'
                    )
                    
                    fig_dispersao.update_layout(
                        xaxis_title="Cobertura Vacinal (%)",
                        yaxis_title="N√∫mero de Casos",
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_dispersao, use_container_width=True)
                    
                    # Explica√ß√£o da an√°lise de correla√ß√£o
                    st.markdown(f"""
                    #### üìö **Explica√ß√£o da An√°lise de Correla√ß√£o Cobertura vs Casos:**
                    
                    ##### üìä **Correla√ß√£o de Pearson = {corr_cobertura_casos:.3f}**
                    - **O que mede:** For√ßa da rela√ß√£o linear entre cobertura vacinal e casos de meningite
                    - **Interpreta√ß√£o esperada:** Correla√ß√£o negativa (mais vacina√ß√£o = menos casos)
                    - **Resultado atual:** {"Correla√ß√£o negativa - conforme esperado!" if corr_cobertura_casos < 0 else "Correla√ß√£o positiva - necessita investiga√ß√£o!" if corr_cobertura_casos > 0 else "Sem correla√ß√£o clara"}
                    
                    ##### üéØ **Signific√¢ncia Estat√≠stica (p = {p_valor:.4f})**
                    - **p < 0.05:** Rela√ß√£o estatisticamente significativa
                    - **p ‚â• 0.05:** Rela√ß√£o pode ser devida ao acaso
                    - **Resultado:** {"Rela√ß√£o significativa e confi√°vel" if p_valor < 0.05 else "Rela√ß√£o n√£o significativa"}
                    
                    ##### üìñ **Interpreta√ß√£o do Gr√°fico de Dispers√£o:**
                    - **Eixo X:** Cobertura vacinal (% ou doses)
                    - **Eixo Y:** N√∫mero de casos de meningite
                    - **Pontos:** Cada ponto representa um ano espec√≠fico
                    - **Tamanho dos pontos:** Proporcional √† cobertura vacinal
                    - **Padr√£o ideal:** Pontos formando linha descendente (mais vacina√ß√£o = menos casos)
                    
                    ##### ‚ö†Ô∏è **Considera√ß√µes Importantes:**
                    - **Defasagem temporal:** Efeito da vacina√ß√£o pode aparecer com atraso
                    - **Fatores confundidores:** Outros fatores podem influenciar a incid√™ncia
                    - **Imunidade coletiva:** Efeito mais pronunciado com cobertura >95%
                    - **Tipos de meningite:** Nem todas s√£o preven√≠veis por vacina
                    """)
        
        # An√°lise regional da cobertura
        st.subheader("üó∫Ô∏è **An√°lise Regional da Cobertura**")
        
        if dados.get('imunizacao_processada') is not None:
            # Derivar cobertura por UF a partir do dataset processado se poss√≠vel (soma no per√≠odo)
            proc = dados['imunizacao_processada']
            uf_cols = [c for c in proc.columns if c not in ['Ano', 'Ignorado', 'Total', 'Total_Nacional', 'Casos_Notificados']]
            if uf_cols:
                cobertura_por_uf = proc[uf_cols].sum().sort_values(ascending=False)
                fig_regional = px.bar(
                    x=[c.split(' ', 1)[1] if ' ' in c else c for c in cobertura_por_uf.index],
                    y=cobertura_por_uf.values,
                    title="Cobertura/Aplica√ß√£o por UF (soma no per√≠odo)",
                    color=cobertura_por_uf.values,
                    color_continuous_scale='Greens'
                )
                fig_regional.update_layout(
                    xaxis_title="Unidade Federativa",
                    yaxis_title="Total de Doses",
                    template='plotly_white'
                )
                st.plotly_chart(fig_regional, use_container_width=True)
        elif imunizacao_uf is not None and not imunizacao_uf.empty:
            # Preparar dados regionais
            if 'Cobertura' in imunizacao_uf.columns:
                cobertura_por_uf = imunizacao_uf.groupby('UF')['Cobertura'].mean().sort_values(ascending=False)
                
                fig_regional = px.bar(
                    x=cobertura_por_uf.index,
                    y=cobertura_por_uf.values,
                    title="Cobertura Vacinal por UF",
                    color=cobertura_por_uf.values,
                    color_continuous_scale='Greens'
                )
                
                fig_regional.update_layout(
                    xaxis_title="Unidade Federativa",
                    yaxis_title="Cobertura Vacinal M√©dia (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_regional, use_container_width=True)
                
                # An√°lise de desigualdades regionais
                st.write("**üìä An√°lise de Desigualdades Regionais:**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    cobertura_media = cobertura_por_uf.mean()
                    cobertura_std = cobertura_por_uf.std()
                    st.metric("üìä Cobertura M√©dia", f"{cobertura_media:.1f}%")
                    st.metric("üìà Desvio Padr√£o", f"{cobertura_std:.1f}%")
                
                with col2:
                    cobertura_min = cobertura_por_uf.min()
                    cobertura_max = cobertura_por_uf.max()
                    st.metric("üìâ Cobertura M√≠nima", f"{cobertura_min:.1f}%")
                    st.metric("üìà Cobertura M√°xima", f"{cobertura_max:.1f}%")
                
                # Coeficiente de varia√ß√£o
                cv = (cobertura_std / cobertura_media) * 100
                st.write(f"**üìä Coeficiente de Varia√ß√£o:** {cv:.1f}%")
                
                if cv > 20:
                    st.warning("‚ö†Ô∏è Alta desigualdade regional na cobertura vacinal")
                elif cv > 10:
                    st.info("‚ÑπÔ∏è Desigualdade moderada na cobertura vacinal")
                else:
                    st.success("‚úÖ Baixa desigualdade regional na cobertura vacinal")
        
        # An√°lise temporal avan√ßada
        st.subheader("üìà **An√°lise Temporal Avan√ßada**")
        
        if dados.get('imunizacao_processada') is not None:
            # Usar a s√©rie anual de Total_Nacional para tend√™ncia
            serie_anual = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum()
            serie_anual['Ano'] = pd.to_numeric(serie_anual['Ano'], errors='coerce')
            serie_anual = serie_anual.dropna(subset=['Ano'])
            serie_anual = serie_anual[(serie_anual['Ano'] >= 1900) & (serie_anual['Ano'] <= 2100)]
            fig_tendencia = go.Figure()
            fig_tendencia.add_trace(go.Scatter(
                x=pd.to_datetime(serie_anual['Ano'].astype(int), format='%Y', errors='coerce'),
                y=serie_anual['Total_Nacional'],
                mode='markers+lines', name='Total de Doses', marker=dict(size=8)
            ))
            fig_tendencia.update_layout(title="Tend√™ncia de Aplica√ß√µes (Total Nacional)", xaxis_title="Ano", yaxis_title="Total de Doses", template='plotly_white')
            fig_tendencia.update_xaxes(tickformat='%Y')
            st.plotly_chart(fig_tendencia, use_container_width=True)
        elif imunizacao_2023_2025 is not None and not imunizacao_2023_2025.empty:
            # Preparar dados temporais
            if 'Ano' in imunizacao_2023_2025.columns:
                dados_temporais = imunizacao_2023_2025.groupby('Ano').agg({
                    'Cobertura': 'mean' if 'Cobertura' in imunizacao_2023_2025.columns else 'count',
                    'Doses': 'sum' if 'Doses' in imunizacao_2023_2025.columns else 'count'
                }).reset_index()
                
                # Gr√°fico de tend√™ncia
                fig_tendencia = go.Figure()
                
                fig_tendencia.add_trace(go.Scatter(
                    x=dados_temporais['Ano'],
                    y=dados_temporais['Cobertura'] if 'Cobertura' in dados_temporais.columns else dados_temporais['Doses'],
                    mode='markers+lines',
                    name='Cobertura/Doses',
                    marker=dict(size=8)
                ))
                
                fig_tendencia.update_layout(
                    title="Tend√™ncia da Cobertura Vacinal (2023-2025)",
                    xaxis_title="Ano",
                    yaxis_title="Cobertura (%) / Doses",
                    template='plotly_white'
                )
                
                fig_tendencia.update_xaxes(tickformat='d')
                st.plotly_chart(fig_tendencia, use_container_width=True)
                
                # An√°lise de efic√°cia
                if len(dados_temporais) > 1:
                    st.write("**üìä An√°lise de Efic√°cia:**")
                    
                    # Calcular mudan√ßa percentual
                    if 'Cobertura' in dados_temporais.columns:
                        cobertura_inicial = dados_temporais['Cobertura'].iloc[0]
                        cobertura_final = dados_temporais['Cobertura'].iloc[-1]
                        mudanca_percentual = ((cobertura_final - cobertura_inicial) / cobertura_inicial) * 100
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("üìä Cobertura Inicial", f"{cobertura_inicial:.1f}%")
                            st.metric("üìä Cobertura Final", f"{cobertura_final:.1f}%")
                        
                        with col2:
                            st.metric("üìà Mudan√ßa", f"{mudanca_percentual:+.1f}%")
                            
                            if mudanca_percentual > 0:
                                st.success("‚úÖ Melhoria na cobertura")
                            elif mudanca_percentual < 0:
                                st.warning("‚ö†Ô∏è Redu√ß√£o na cobertura")
                            else:
                                st.info("‚ÑπÔ∏è Cobertura est√°vel")
        
        # An√°lise preditiva com ARIMA
        st.subheader("üîÆ **An√°lise Preditiva (ARIMA)**")
        
        # Construir s√©rie para ARIMA (doses)
        dados_arima = None
        if dados.get('imunizacao_processada') is not None:
            dados_arima = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum().rename(columns={'Total_Nacional': 'Valor'})
        elif imunizacao_ano is not None and {'Ano','Cobertura'}.issubset(imunizacao_ano.columns):
            dados_arima = imunizacao_ano.groupby('Ano', as_index=False)['Cobertura'].mean().rename(columns={'Cobertura':'Valor'})

        if dados_arima is not None and len(dados_arima) > 3:
            try:
                serie = dados_arima.copy()
                serie['Ano'] = pd.to_numeric(serie['Ano'], errors='coerce')
                serie = serie.dropna(subset=['Ano'])
                serie = serie[(serie['Ano'] >= 1900) & (serie['Ano'] <= 2100)]
                serie['Ano'] = pd.to_datetime(serie['Ano'].astype(int), format='%Y', errors='coerce')
                serie = serie.set_index('Ano')
                if not STATSMODELS_AVAILABLE:
                    st.warning("‚ö†Ô∏è An√°lise ARIMA n√£o dispon√≠vel: statsmodels n√£o instalado corretamente")
                else:
                    modelo_arima = ARIMA(serie['Valor'], order=(1, 1, 1)).fit()
                    previsao = modelo_arima.forecast(steps=3)
                    anos_futuros = pd.date_range(start=serie.index[-1] + pd.DateOffset(years=1), periods=3, freq='Y')

                    fig_previsao = go.Figure()
                    fig_previsao.add_trace(go.Scatter(x=serie.index, y=serie['Valor'], mode='markers+lines', name='Observado'))
                    fig_previsao.add_trace(go.Scatter(x=anos_futuros, y=previsao, mode='markers+lines', name='Previs√£o', line=dict(dash='dash', color='red')))
                    fig_previsao.update_layout(title='Previs√£o de Doses (ARIMA)', xaxis_title='Ano', yaxis_title='Total de Doses', template='plotly_white')
                    st.plotly_chart(fig_previsao, use_container_width=True)

            except Exception as e:
                st.warning(f"Erro na previs√£o ARIMA (doses): {e}")

        # ARIMA para n√∫mero de casos (quando dispon√≠vel)
        if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
            casos_series = dados['casos_consolidados'].groupby('Ano', as_index=False)['Casos_Notificados'].sum()
            if len(casos_series) > 3:
                try:
                    cs = casos_series.copy()
                    cs['Ano'] = pd.to_numeric(cs['Ano'], errors='coerce')
                    cs = cs.dropna(subset=['Ano'])
                    cs = cs[(cs['Ano'] >= 1900) & (cs['Ano'] <= 2100)]
                    cs['Ano'] = pd.to_datetime(cs['Ano'].astype(int), format='%Y', errors='coerce')
                    cs = cs.set_index('Ano')
                    if STATSMODELS_AVAILABLE:
                        model_cases = ARIMA(cs['Casos_Notificados'], order=(1, 1, 1)).fit()
                    else:
                        st.warning("‚ö†Ô∏è An√°lise ARIMA n√£o dispon√≠vel: statsmodels n√£o instalado corretamente")
                        return
                    fc_cases = model_cases.forecast(steps=3)
                    anos_fut = pd.date_range(start=cs.index[-1] + pd.DateOffset(years=1), periods=3, freq='Y')

                    fig_cases = go.Figure()
                    fig_cases.add_trace(go.Scatter(x=cs.index, y=cs['Casos_Notificados'], mode='markers+lines', name='Casos Observados'))
                    fig_cases.add_trace(go.Scatter(x=anos_fut, y=fc_cases, mode='markers+lines', name='Previs√£o de Casos', line=dict(dash='dash', color='orange')))
                    fig_cases.update_layout(title='Previs√£o de Casos (ARIMA)', xaxis_title='Ano', yaxis_title='Casos', template='plotly_white')
                    st.plotly_chart(fig_cases, use_container_width=True)
                except Exception as e:
                    st.warning(f"Erro na previs√£o ARIMA (casos): {e}")
        
        # Resumo das an√°lises
        st.markdown("---")
        st.markdown("""
        **üìã Resumo das An√°lises de Imuniza√ß√£o:**
        
        **1. An√°lise de Impacto:**
        - Correla√ß√£o entre cobertura vacinal e casos de meningite
        - Efetividade das campanhas de vacina√ß√£o
        - Rela√ß√£o dose-resposta
        
        **2. An√°lise Regional:**
        - Desigualdades na cobertura entre UFs
        - Identifica√ß√£o de regi√µes priorit√°rias
        - Padr√µes geogr√°ficos de imuniza√ß√£o
        
        **3. An√°lise Temporal:**
        - Evolu√ß√£o da cobertura ao longo do tempo
        - Tend√™ncias e sazonalidade
        - Efic√°cia das interven√ß√µes
        
        **4. An√°lise Preditiva:**
        - Modelagem ARIMA para previs√µes
        - Planejamento de campanhas futuras
        - Avalia√ß√£o de metas de cobertura
        """)
        
    else:
        st.error("‚ùå Dados de imuniza√ß√£o n√£o dispon√≠veis")

def show_advanced_analysis(dados):
    """Exibe a se√ß√£o "An√°lises Avan√ßadas e Machine Learning".

    Esta fun√ß√£o apresenta an√°lises estat√≠sticas e de machine learning mais complexas.
    Inclui uma decomposi√ß√£o de s√©rie temporal avan√ßada (STL), teste de estacionariedade (ADF),
    an√°lise de correla√ß√£o cruzada entre sorogrupos, um modelo de regress√£o m√∫ltipla
    para identificar fatores preditivos de casos, e clustering hier√°rquico para
    agrupamento de sorogrupos.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves 'casos_consolidados',
                      'sorogrupos_consolidados', 'etiologias_consolidadas', e
                      'imunizacao_processada'.
    """
    st.header("üî¨ **An√°lises Avan√ßadas e Machine Learning**")
    st.markdown("---")
    
    # Carregar dados
    casos = dados['casos_consolidados']
    sorogrupos = dados['sorogrupos_consolidados']
    etiologia = dados['etiologias_consolidadas']
    
    if casos is not None and not casos.empty:
        # An√°lise de s√©ries temporais avan√ßada
        st.subheader("üìà **An√°lise de S√©ries Temporais Avan√ßada**")
        
        # Preparar dados temporais
        dados_tempo = casos.groupby('Ano')['Casos_Notificados'].sum().reset_index()
        dados_tempo['Ano'] = pd.to_datetime(dados_tempo['Ano'], format='%Y')
        dados_tempo = dados_tempo.set_index('Ano')
        
        if len(dados_tempo) > 3:
            # Decomposi√ß√£o sazonal avan√ßada
            try:
                # Decomposi√ß√£o STL (mais robusta)
                if not STATSMODELS_AVAILABLE:
                    st.warning("‚ö†Ô∏è An√°lise STL n√£o dispon√≠vel: statsmodels n√£o instalado corretamente")
                else:
                    from statsmodels.tsa.seasonal import STL
                    
                    stl = STL(dados_tempo['Casos_Notificados'], period=min(3, len(dados_tempo)//2))
                    resultado_stl = stl.fit()
                    
                    # Gr√°fico de decomposi√ß√£o STL
                    fig_stl = make_subplots(
                        rows=4, cols=1,
                        subplot_titles=['Original', 'Tend√™ncia', 'Sazonal', 'Res√≠duos'],
                        vertical_spacing=0.1
                    )
                    
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=dados_tempo['Casos_Notificados'], name='Original'), row=1, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.trend, name='Tend√™ncia'), row=2, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.seasonal, name='Sazonal'), row=3, col=1)
                    fig_stl.add_trace(go.Scatter(x=dados_tempo.index, y=resultado_stl.resid, name='Res√≠duos'), row=4, col=1)
                    
                    fig_stl.update_layout(
                        title="Decomposi√ß√£o STL Avan√ßada",
                        height=600,
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_stl, use_container_width=True)
                    
                    # Explica√ß√£o detalhada da decomposi√ß√£o STL
                    st.markdown("""
                    #### üìö **Explica√ß√£o da Decomposi√ß√£o STL (Seasonal and Trend decomposition using Loess):**
                    
                    ##### üéØ **O que √© a decomposi√ß√£o STL:**
                    - **T√©cnica estat√≠stica avan√ßada** que separa uma s√©rie temporal em componentes
                    - **STL = Seasonal and Trend decomposition using Loess**
                    - **Mais robusta** que m√©todos cl√°ssicos para dados irregulares
                    - **Flex√≠vel** para diferentes tipos de sazonalidade
                    
                    ##### üìä **Os 4 componentes visualizados:**
                    
                    **1. üìà S√©rie Original (1¬∫ gr√°fico):**
                    - Dados brutos de casos de meningite ao longo do tempo
                    - Mostra a s√©rie completa sem decomposi√ß√£o
                    
                    **2. üìâ Tend√™ncia (2¬∫ gr√°fico):**
                    - **Dire√ß√£o geral** da s√©rie ao longo do tempo
                    - Remove flutua√ß√µes de curto prazo
                    - **Crescente:** Aumento sustentado de casos
                    - **Decrescente:** Redu√ß√£o sustentada de casos
                    - **Est√°vel:** Sem mudan√ßa direcional clara
                    
                    **3. üîÑ Componente Sazonal (3¬∫ gr√°fico):**
                    - **Padr√µes repetitivos** em per√≠odos fixos
                    - Mostra varia√ß√µes sistem√°ticas (anuais, mensais)
                    - **Picos regulares:** √âpocas de maior incid√™ncia
                    - **Vales regulares:** √âpocas de menor incid√™ncia
                    
                    **4. üé≤ Res√≠duos (4¬∫ gr√°fico):**
                    - **Varia√ß√µes aleat√≥rias** n√£o explicadas
                    - Diferen√ßa entre s√©rie real e componentes
                    - **Pr√≥ximo a zero:** Boa decomposi√ß√£o
                    - **Padr√µes nos res√≠duos:** Componentes n√£o capturados
                    
                    ##### üî¨ **Import√¢ncia epidemiol√≥gica:**
                    - **Tend√™ncia:** Avalia efic√°cia de pol√≠ticas de longo prazo
                    - **Sazonalidade:** Identifica per√≠odos de risco para planejamento
                    - **Res√≠duos:** Detecta eventos at√≠picos (surtos, mudan√ßas s√∫bitas)
                    - **Previs√£o:** Base para modelos preditivos
                    """)
                    
                    # An√°lise de estacionariedade
                    st.markdown("**üìä Teste de Estacionariedade (ADF):**")
                    from statsmodels.tsa.stattools import adfuller
                    
                    resultado_adf = adfuller(dados_tempo['Casos_Notificados'])
                    st.write(f"**Estat√≠stica ADF:** {resultado_adf[0]:.4f}")
                    st.write(f"**P-valor:** {resultado_adf[1]:.4f}")
                    st.write(f"**Estacion√°rio:** {'Sim' if resultado_adf[1] < 0.05 else 'N√£o'}")
                    
                    # Explica√ß√£o detalhada do teste ADF
                    st.markdown(f"""
                    #### üìö **Explica√ß√£o do Teste ADF (Augmented Dickey-Fuller):**
                    
                    ##### üéØ **O que √© estacionariedade:**
                    - **S√©rie estacion√°ria:** Propriedades estat√≠sticas n√£o mudam ao longo do tempo
                    - **M√©dia constante:** N√£o h√° tend√™ncia crescente ou decrescente
                    - **Vari√¢ncia constante:** Flutua√ß√µes similares em todo per√≠odo
                    - **Autocorrela√ß√£o est√°vel:** Padr√µes de depend√™ncia temporal consistentes
                    
                    ##### üìä **Teste ADF - Resultados atuais:**
                    - **Estat√≠stica ADF:** {resultado_adf[0]:.4f}
                      - Valores mais negativos indicam maior evid√™ncia de estacionariedade
                      - Compara com valores cr√≠ticos (-3.43, -2.86, -2.57)
                    
                    - **P-valor:** {resultado_adf[1]:.4f}
                      - p < 0.05: Rejeita hip√≥tese nula (s√©rie √â estacion√°ria)
                      - p ‚â• 0.05: N√£o rejeita hip√≥tese nula (s√©rie N√ÉO √© estacion√°ria)
                    
                    - **Interpreta√ß√£o:** {"S√©rie ESTACION√ÅRIA" if resultado_adf[1] < 0.05 else "S√©rie N√ÉO-ESTACION√ÅRIA"}
                    
                    ##### üî¨ **Import√¢ncia para an√°lise:**
                    - **S√©rie estacion√°ria:** Ideal para modelagem e previs√£o
                    - **S√©rie n√£o-estacion√°ria:** Necessita transforma√ß√µes (diferencia√ß√£o, log)
                    - **Aplica√ß√£o epidemiol√≥gica:** Determina se tend√™ncias s√£o tempor√°rias ou persistentes
                    - **Modelos ARIMA:** Requer estacionariedade para funcionar adequadamente
                    
                    ##### ‚ö†Ô∏è **Implica√ß√µes pr√°ticas:**
                    {"- **Dados adequados** para previs√£o direta" if resultado_adf[1] < 0.05 else "- **Dados necessitam transforma√ß√£o** antes da modelagem"}
                    {"- **Flutua√ß√µes em torno de m√©dia est√°vel**" if resultado_adf[1] < 0.05 else "- **Presen√ßa de tend√™ncias ou mudan√ßas estruturais**"}
                    {"- **Modelos mais simples s√£o aplic√°veis**" if resultado_adf[1] < 0.05 else "- **Modelos mais complexos s√£o necess√°rios**"}
                    """)
                    
                
            except Exception as e:
                st.warning(f"Erro na decomposi√ß√£o STL: {e}")
        
        # An√°lise de correla√ß√£o cruzada
        st.subheader("üîó **An√°lise de Correla√ß√£o Cruzada**")
        
        if sorogrupos is not None and not sorogrupos.empty:
            # Preparar dados para correla√ß√£o cruzada
            dados_cruzada = sorogrupos.pivot_table(
                index='Ano', 
                columns='Sorogrupo', 
                values='Casos', 
                aggfunc='sum'
            ).fillna(0)
            
            # Calcular correla√ß√£o cruzada
            
            st.markdown("**Correla√ß√µes Cruzadas entre Sorogrupos:**")
            
            correlacoes_cruzadas = []
            for i, sorogrupo1 in enumerate(dados_cruzada.columns):
                for j, sorogrupo2 in enumerate(dados_cruzada.columns):
                    if i < j:  # Evitar duplicatas
                        corr, p_valor = stats.pearsonr(dados_cruzada[sorogrupo1], dados_cruzada[sorogrupo2])
                        correlacoes_cruzadas.append({
                            'Sorogrupo 1': sorogrupo1,
                            'Sorogrupo 2': sorogrupo2,
                            'Correla√ß√£o': corr,
                            'P-valor': p_valor
                        })
            
            if correlacoes_cruzadas:
                df_cruzada = pd.DataFrame(correlacoes_cruzadas)
                df_cruzada = df_cruzada = df_cruzada.sort_values('Correla√ß√£o', key=abs, ascending=False)
                
                # Gr√°fico de correla√ß√µes cruzadas
                fig_cruzada = px.bar(
                    df_cruzada,
                    x='Sorogrupo 1',
                    y='Correla√ß√£o',
                    color='Sorogrupo 2',
                    title='Correla√ß√µes Cruzadas entre Sorogrupos',
                    barmode='group'
                )
                
                fig_cruzada.update_layout(template='plotly_white')
                st.plotly_chart(fig_cruzada, use_container_width=True)
                
                # Explica√ß√£o detalhada da correla√ß√£o cruzada
                st.markdown("""
                #### üìö **Explica√ß√£o da An√°lise de Correla√ß√£o Cruzada:**
                
                ##### üéØ **O que √© correla√ß√£o cruzada:**
                - **Medida de associa√ß√£o** entre diferentes sorogrupos ao longo do tempo
                - **Identifica padr√µes sincronizados** ou opostos entre sorogrupos
                - **An√°lise multivariada** que examina relacionamentos complexos
                
                ##### üìä **Interpreta√ß√£o do gr√°fico:**
                - **Eixo X:** Primeiro sorogrupo de cada par
                - **Eixo Y:** Valor da correla√ß√£o (-1 a +1)
                - **Cores:** Segundo sorogrupo do par
                - **Barras positivas:** Sorogrupos variam na mesma dire√ß√£o
                - **Barras negativas:** Sorogrupos variam em dire√ß√µes opostas
                
                ##### üî¨ **Significado epidemiol√≥gico:**
                
                **Correla√ß√£o Positiva (+):**
                - Sorogrupos aumentam/diminuem juntos
                - Poss√≠veis fatores comuns (clima, pol√≠ticas, vigil√¢ncia)
                - Resposta similar a interven√ß√µes
                
                **Correla√ß√£o Negativa (-):**
                - Um sorogrupo aumenta quando outro diminui
                - Poss√≠vel competi√ß√£o ou substitui√ß√£o
                - Diferen√ßas na efic√°cia de vacinas espec√≠ficas
                
                **Correla√ß√£o pr√≥xima a zero:**
                - Sorogrupos evoluem independentemente
                - Fatores de risco diferentes
                - Din√¢micas epidemiol√≥gicas distintas
                
                ##### üìà **Aplica√ß√µes pr√°ticas:**
                - **Planejamento de vacinas:** Priorizar sorogrupos correlacionados
                - **Vigil√¢ncia:** Monitorar sorogrupos em conjunto
                - **Previs√£o:** Usar comportamento de um para prever outro
                - **Investiga√ß√£o:** Identificar fatores de risco comuns
                """)
                
                # Tabela de correla√ß√µes
                st.markdown("#### üìã **Tabela Detalhada de Correla√ß√µes:**")
                st.dataframe(df_cruzada.round(3))
        
        # An√°lise de regress√£o m√∫ltipla (revista)
        st.subheader("üìä **Regress√£o M√∫ltipla: Fatores que explicam os Casos**")
        try:
            # Construir base anual integrada: Casos vs Doses (Total_Nacional)
            base_casos = None
            if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
                base_casos = dados['casos_consolidados'].groupby('Ano', as_index=False)['Casos_Notificados'].sum()
            if base_casos is not None and (len(base_casos) >= 5):
                # Doses
                if 'imunizacao_processada' in dados and isinstance(dados['imunizacao_processada'], pd.DataFrame):
                    base_doses = dados['imunizacao_processada'].groupby('Ano', as_index=False)['Total_Nacional'].sum()
                else:
                    base_doses = None

                df_int = base_casos.copy()
                if base_doses is not None:
                    df_int = df_int.merge(base_doses, on='Ano', how='left')
                df_int = df_int.sort_values('Ano')
                # Features de defasagem
                df_int['Casos_Lag1'] = df_int['Casos_Notificados'].shift(1)
                if 'Total_Nacional' in df_int.columns:
                    df_int['Doses_Lag1'] = df_int['Total_Nacional'].shift(1)
                # Tend√™ncia temporal
                df_int['Trend'] = pd.to_numeric(df_int['Ano'], errors='coerce')
                # Limpar
                df_int = df_int.dropna()
                # Preparar X, y
                feature_cols = ['Trend']
                if 'Total_Nacional' in df_int.columns:
                    feature_cols += ['Total_Nacional']
                if 'Doses_Lag1' in df_int.columns:
                    feature_cols += ['Doses_Lag1']
                feature_cols += ['Casos_Lag1']

                from sklearn.linear_model import LinearRegression
                from sklearn.metrics import r2_score, mean_squared_error
                X = df_int[feature_cols]
                y = df_int['Casos_Notificados']

                modelo_reg = LinearRegression()
                modelo_reg.fit(X, y)
                y_pred = modelo_reg.predict(X)
                # R¬≤ seguro (evita NaN se vari√¢ncia de y ~ 0)
                r2 = float(r2_score(y, y_pred)) if np.var(y) > 1e-9 else 0.0
                rmse = float(np.sqrt(mean_squared_error(y, y_pred)))

                # Gr√°fico previsto vs real
                fig_reg = go.Figure()
                fig_reg.add_trace(go.Scatter(x=y, y=y_pred, mode='markers', name='Previsto vs Real', marker=dict(color='blue')))
                min_val = float(min(y.min(), y_pred.min()))
                max_val = float(max(y.max(), y_pred.max()))
                fig_reg.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', name='Identidade', line=dict(dash='dash', color='red')))
                fig_reg.update_layout(title='Regress√£o: Casos vs Fatores (Doses, Tend√™ncia, Defasagens)', xaxis_title='Casos Reais', yaxis_title='Casos Previstos', template='plotly_white')
                st.plotly_chart(fig_reg, use_container_width=True)
                
                # Explica√ß√£o do gr√°fico de regress√£o
                st.markdown("""
                #### üìñ **Interpreta√ß√£o do Gr√°fico de Regress√£o:**
                - **Eixo X (Horizontal):** Casos reais observados
                - **Eixo Y (Vertical):** Casos previstos pelo modelo
                - **Pontos azuis:** Cada ponto representa um ano (casos reais vs. previstos)
                - **Linha tracejada vermelha:** Linha de identidade (previs√£o perfeita)
                - **Proximidade √† linha:** Quanto mais pr√≥ximos os pontos est√£o da linha, melhor o modelo
                - **Dispers√£o:** Pontos muito espalhados indicam baixa precis√£o do modelo
                """)
                
                # Mostrar m√©tricas de qualidade do ajuste
                st.markdown("### üìä **M√©tricas de Qualidade do Modelo:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric('R¬≤ (in-sample)', f"{r2:.3f}")
                    
                with col2:
                    st.metric('RMSE (in-sample)', f"{rmse:.0f}")
                
                # Explica√ß√£o detalhada das m√©tricas
                st.markdown(f"""
                #### üìö **Explica√ß√£o das M√©tricas de Regress√£o:**
                
                ##### üìà **R¬≤ = {r2:.3f}**
                - **O que √©:** Coeficiente de determina√ß√£o, mede o quanto o modelo explica a varia√ß√£o nos dados
                - **Escala:** 0 a 1 (pode ser negativo se o modelo for muito ruim)
                - **Interpreta√ß√£o atual:** O modelo explica {r2*100:.1f}% da varia√ß√£o nos casos de meningite
                - **Qualidade:**
                  - R¬≤ > 0.8: Excelente
                  - R¬≤ 0.6-0.8: Bom
                  - R¬≤ 0.4-0.6: Moderado
                  - R¬≤ < 0.4: Fraco
                  - **Seu modelo:** {"Excelente" if r2 > 0.8 else "Bom" if r2 > 0.6 else "Moderado" if r2 > 0.4 else "Fraco"}
                
                ##### üìè **RMSE = {rmse:.0f}**
                - **O que √©:** Raiz do Erro Quadr√°tico M√©dio, mede o erro t√≠pico das previs√µes
                - **Unidade:** N√∫mero de casos (mesma unidade dos dados)
                - **Interpreta√ß√£o:** Em m√©dia, o modelo erra {rmse:.0f} casos para mais ou para menos
                - **Utilidade:** Quanto menor, melhor a precis√£o das previs√µes
                """)
                
                # Mostrar import√¢ncia das vari√°veis
                if hasattr(modelo_reg, 'coef_') and hasattr(modelo_reg, 'feature_names_in_'):
                    st.markdown("#### üéØ **Import√¢ncia das Vari√°veis:**")
                    coefs = pd.DataFrame({
                        'Vari√°vel': feature_cols,
                        'Coeficiente': modelo_reg.coef_,
                        'Import√¢ncia_Abs': np.abs(modelo_reg.coef_)
                    }).sort_values('Import√¢ncia_Abs', ascending=False)
                    st.dataframe(coefs)
                    
                    st.markdown("""
                    **üìä Interpreta√ß√£o dos Coeficientes:**
                    - **Coeficiente positivo:** Aumento na vari√°vel leva a aumento nos casos
                    - **Coeficiente negativo:** Aumento na vari√°vel leva √† diminui√ß√£o nos casos
                    - **Magnitude:** Quanto maior o valor absoluto, maior o impacto da vari√°vel
                    """)

                # Valida√ß√£o temporal e diagn√≥stico
                st.subheader('üìè Valida√ß√£o Temporal (TimeSeriesSplit)')
                try:
                    from sklearn.model_selection import TimeSeriesSplit
                    n_splits = min(5, max(2, len(df_int) - 3))
                    tscv = TimeSeriesSplit(n_splits=n_splits)
                    cv_rows = []
                    for i, (train_idx, test_idx) in enumerate(tscv.split(df_int)):
                        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
                        m = LinearRegression().fit(X_train, y_train)
                        y_hat = m.predict(X_test)
                        # R¬≤ somente se houver pelo menos 2 amostras e vari√¢ncia
                        if len(y_test) >= 2 and np.var(y_test) > 1e-9:
                            cv_r2 = float(r2_score(y_test, y_hat))
                        else:
                            cv_r2 = None
                        cv_rmse = float(np.sqrt(mean_squared_error(y_test, y_hat)))
                        cv_rows.append({'fold': i + 1, 'R2': cv_r2, 'RMSE': cv_rmse, 'n_test': int(len(test_idx))})
                    if cv_rows:
                        cv_df = pd.DataFrame(cv_rows)
                        st.dataframe(cv_df)
                        r2_valid = cv_df['R2'].dropna()
                        r2_cv_mean = r2_valid.mean() if not r2_valid.empty else 0.0
                        rmse_cv_mean = cv_df['RMSE'].mean()
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric('R¬≤ m√©dio (CV)', f"{r2_cv_mean:.3f}")
                        with col2:
                            st.metric('RMSE m√©dio (CV)', f"{rmse_cv_mean:.0f}")
                            
                        # Explica√ß√£o da valida√ß√£o cruzada temporal
                        st.markdown(f"""
                        #### üìö **Explica√ß√£o da Valida√ß√£o Cruzada Temporal:**
                        
                        **üîÑ O que √©:** T√©cnica que avalia a capacidade do modelo de prever dados futuros
                        
                        **üïí Como funciona:**
                        - Divide os dados em sequ√™ncias temporais
                        - Treina com dados do passado, testa com dados do futuro
                        - Repete o processo v√°rias vezes
                        
                        **üìä M√©tricas obtidas:**
                        - **R¬≤ m√©dio (CV) = {r2_cv_mean:.3f}**
                          - Performance m√©dia em dados n√£o vistos
                          - {"Melhor que in-sample" if r2_cv_mean > r2 else "Pior que in-sample" if r2_cv_mean < r2 else "Similar ao in-sample"} (in-sample = {r2:.3f})
                        
                        - **RMSE m√©dio (CV) = {rmse_cv_mean:.0f}**
                          - Erro m√©dio em dados n√£o vistos
                          - {"Melhor que in-sample" if rmse_cv_mean < rmse else "Pior que in-sample" if rmse_cv_mean > rmse else "Similar ao in-sample"} (in-sample = {rmse:.0f})
                        
                        **üéØ Interpreta√ß√£o:**
                        - Se CV ‚âà in-sample: modelo generaliza bem
                        - Se CV << in-sample: poss√≠vel overfitting
                        - Se CV >> in-sample: poss√≠vel underfitting ou dados inadequados
                        """)
                except Exception as _:
                    st.info('‚ÑπÔ∏è N√£o foi poss√≠vel calcular a valida√ß√£o temporal nesta amostra.')

                # Res√≠duos ao longo do tempo
                st.subheader('ü©∫ Diagn√≥stico de Res√≠duos')
                residuos = (y - y_pred).reset_index(drop=True)
                anos_plot = df_int['Ano'].reset_index(drop=True) if 'Ano' in df_int.columns else pd.Series(range(len(residuos)))
                fig_res = px.line(x=anos_plot, y=residuos, markers=True, title='Res√≠duos ao longo do tempo')
                fig_res.update_layout(xaxis_title='Ano', yaxis_title='Res√≠duo (Casos)', template='plotly_white')
                st.plotly_chart(fig_res, use_container_width=True)
                
                # Explica√ß√£o do gr√°fico de res√≠duos
                st.markdown("""
                #### üìñ **Interpreta√ß√£o do Gr√°fico de Res√≠duos:**
                - **Eixo X (Horizontal):** Anos
                - **Eixo Y (Vertical):** Res√≠duos (diferen√ßa entre casos reais e previstos)
                - **Linha:** Mostra os erros do modelo ao longo do tempo
                - **Padr√µes a observar:**
                  - **Linha horizontal pr√≥xima a zero:** Modelo bem ajustado
                  - **Tend√™ncias sistem√°ticas:** Modelo pode estar perdendo padr√µes importantes
                  - **Variabilidade constante:** Boa qualidade dos res√≠duos
                  - **Variabilidade crescente/decrescente:** Poss√≠vel heteroscedasticidade
                - **Interpreta√ß√£o epidemiol√≥gica:** Res√≠duos grandes podem indicar anos com eventos especiais (surtos, mudan√ßas de pol√≠tica)
                """)
            else:
                st.info('‚ÑπÔ∏è Dados anuais insuficientes para regress√£o m√∫ltipla.')
        except Exception as e:
            st.warning(f"Erro na regress√£o m√∫ltipla: {e}")
        
        # An√°lise de clustering hier√°rquico
        st.subheader("üéØ **Clustering Hier√°rquico**")
        
        if sorogrupos is not None and not sorogrupos.empty:
            try:
                from scipy.cluster.hierarchy import dendrogram, linkage
                from scipy.spatial.distance import pdist
                
                # Preparar dados para clustering
                dados_cluster = sorogrupos.groupby('Sorogrupo').agg({
                    'Casos': 'sum',
                    'Obitos': 'sum'
                }).reset_index()
                
                dados_cluster['Letalidade'] = (
                    dados_cluster['Obitos'] / dados_cluster['Casos'] * 100
                ).round(2)
                
                # Selecionar vari√°veis para clustering
                features = ['Casos', 'Letalidade']
                X_cluster = dados_cluster[features].values
                
                # Normalizar dados
                scaler = StandardScaler()
                X_cluster_norm = scaler.fit_transform(X_cluster)
                
                # Calcular matriz de dist√¢ncia
                dist_matrix = pdist(X_cluster_norm)
                
                # Aplicar clustering hier√°rquico
                linkage_matrix = linkage(dist_matrix, method='ward')
                
                # Gr√°fico de dendrograma
                fig_dendro = go.Figure()
                
                # Criar dendrograma manualmente
                fig_dendro.add_trace(go.Scatter(
                    x=list(range(len(linkage_matrix) + 1)),
                    y=linkage_matrix[:, 2],
                    mode='lines+markers',
                    name='Dendrograma',
                    line=dict(color='blue'),
                    marker=dict(size=6)
                ))
                
                fig_dendro.update_layout(
                    title="Dendrograma Hier√°rquico dos Sorogrupos",
                    xaxis_title="√çndice",
                    yaxis_title="Dist√¢ncia",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_dendro, use_container_width=True)
                
                # N√∫mero de clusters sugerido
                st.write("**üìä An√°lise do Dendrograma:**")
                st.write("**M√©todo:** Ward (m√≠nima vari√¢ncia)")
                st.write("**Dist√¢ncia:** Euclidiana normalizada")
                
                # Sugerir n√∫mero de clusters
                n_clusters_sugerido = st.slider("N√∫mero de Clusters:", 2, min(5, len(dados_cluster)), 3)
                
                if st.button("üéØ Aplicar Clustering"):
                    try:
                        from scipy.cluster.hierarchy import fcluster
                        
                        # Aplicar clustering
                        clusters = fcluster(linkage_matrix, n_clusters_sugerido, criterion='maxclust')
                        
                        # Adicionar clusters aos dados
                        dados_cluster['Cluster'] = clusters
                        
                        # Gr√°fico de clusters
                        fig_cluster_hier = px.scatter(
                            dados_cluster,
                            x='Casos',
                            y='Letalidade',
                            color='Cluster',
                            title=f"Clustering Hier√°rquico (K={n_clusters_sugerido})",
                            text='Sorogrupo',
                            size='Casos'
                        )
                        
                        fig_cluster_hier.update_layout(
                            xaxis_title="N√∫mero de Casos",
                            yaxis_title="Taxa de Letalidade (%)",
                            template='plotly_white'
                        )
                        
                        st.plotly_chart(fig_cluster_hier, use_container_width=True)
                        
                        # Explica√ß√£o do gr√°fico de clustering hier√°rquico
                        st.markdown(f"""
                        #### üìñ **Interpreta√ß√£o do Clustering Hier√°rquico:**
                        - **Eixo X (Horizontal):** N√∫mero de casos por sorogrupo
                        - **Eixo Y (Vertical):** Taxa de letalidade (%) por sorogrupo
                        - **Cores diferentes:** Cada cor representa um cluster hier√°rquico
                        - **M√©todo Ward:** Minimiza a vari√¢ncia intra-cluster
                        - **Vantagem:** N√£o requer definir n√∫mero de clusters a priori
                        
                        #### üå≥ **Diferen√ßa do K-Means:**
                        - **Hier√°rquico:** Cria √°rvore de relacionamentos (dendrograma)
                        - **Determin√≠stico:** Sempre produz o mesmo resultado
                        - **Flex√≠vel:** Permite escolher n√∫mero de clusters ap√≥s an√°lise
                        - **Interpretabilidade:** Mostra hierarquia de similaridades
                        """)
                        
                        # Resumo dos clusters
                        st.write("**üìã Resumo dos Clusters:**")
                        for i in range(1, n_clusters_sugerido + 1):
                            cluster_data = dados_cluster[dados_cluster['Cluster'] == i]
                            st.write(f"**Cluster {i}:** {len(cluster_data)} sorogrupos")
                            for idx in cluster_data.index:
                                sorogrupo = cluster_data.loc[idx, 'Sorogrupo']
                                casos = cluster_data.loc[idx, 'Casos']
                                letalidade = cluster_data.loc[idx, 'Letalidade']
                                st.write(f"  - {sorogrupo}: {casos} casos, {letalidade:.1f}% letalidade")
                        
                    except Exception as e:
                        st.error(f"Erro no clustering: {e}")
                
            except Exception as e:
                st.warning(f"Erro no clustering hier√°rquico: {e}")
        
        # Resumo das an√°lises avan√ßadas
        st.markdown("---")
        st.markdown("""
        **üìã Resumo das An√°lises Avan√ßadas:**
        
        **1. Decomposi√ß√£o STL:**
        - An√°lise robusta de s√©ries temporais
        - Separa√ß√£o de tend√™ncia, sazonalidade e res√≠duos
        - Identifica√ß√£o de padr√µes complexos
        
        **2. Teste de Estacionariedade:**
        - Avalia√ß√£o da estabilidade temporal
        - Necessidade de diferencia√ß√£o
        - Valida√ß√£o de modelos temporais
        
        **3. Correla√ß√£o Cruzada:**
        - Rela√ß√µes entre diferentes sorogrupos
        - Padr√µes de co-ocorr√™ncia
        - Identifica√ß√£o de surtos simult√¢neos
        
        **4. Regress√£o M√∫ltipla:**
        - Modelagem preditiva da letalidade
        - Identifica√ß√£o de fatores influentes
        - Avalia√ß√£o da qualidade do modelo
        
        **5. Clustering Hier√°rquico:**
        - Agrupamento hier√°rquico de sorogrupos
        - An√°lise de similaridades epidemiol√≥gicas
        - Identifica√ß√£o de padr√µes ocultos
        """)
        
    else:
        st.error("‚ùå Dados n√£o dispon√≠veis para an√°lise avan√ßada")

def show_regional_analysis(dados):
    """Exibe a se√ß√£o "An√°lise Regional - Distribui√ß√£o Geogr√°fica".

    Renderiza uma an√°lise focada nas cinco grandes regi√µes do Brasil. A fun√ß√£o
    mostra a evolu√ß√£o temporal da vacina√ß√£o por regi√£o, compara o total de doses
    e a cobertura m√©dia entre as regi√µes, e analisa a correla√ß√£o entre o
    n√∫mero de doses aplicadas e os casos notificados em n√≠vel regional.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves 'analise_regional'
                      e 'imunizacao_regional'. Tamb√©m tenta carregar
                      'data/processed/analise_regional.csv' para correla√ß√£o.
    """
    st.header("üó∫Ô∏è **An√°lise Regional - Distribui√ß√£o Geogr√°fica**")
    st.markdown("---")
    
    if dados and 'analise_regional' in dados and 'imunizacao_regional' in dados:
        # Dados regionais
        analise_regional = dados['analise_regional']
        imunizacao_regional = dados['imunizacao_regional']
        
        # M√©tricas regionais
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_regioes = len(analise_regional)
            st.metric("üåç Regi√µes Analisadas", total_regioes)
        
        with col2:
            total_ufs = analise_regional['Total_UFs'].sum()
            st.metric("üèôÔ∏è Total de UFs", total_ufs)
        
        with col3:
            media_cobertura = analise_regional['Cobertura_Media'].mean()
            st.metric("üíâ Cobertura M√©dia", f"{media_cobertura:.1f}%")
        
        # Gr√°fico de evolu√ß√£o temporal por regi√£o
        st.subheader("üìà **Evolu√ß√£o Temporal por Regi√£o**")
        
        fig_temporal_regional = go.Figure()
        
        for regiao in imunizacao_regional['Regiao'].unique():
            dados_regiao = imunizacao_regional[imunizacao_regional['Regiao'] == regiao]
            fig_temporal_regional.add_trace(go.Scatter(
                x=dados_regiao['Ano'],
                y=dados_regiao['Total_Doses'],
                mode='lines+markers',
                name=regiao,
                line=dict(width=3),
                marker=dict(size=8)
            ))
        
        fig_temporal_regional.update_layout(
            title="Evolu√ß√£o da Cobertura Vacinal por Regi√£o (2023-2025)",
            xaxis_title="Ano",
            yaxis_title="Total de Doses",
            template='plotly_white',
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        st.plotly_chart(fig_temporal_regional, use_container_width=True)
        
        # Explica√ß√£o detalhada do gr√°fico de evolu√ß√£o temporal
        st.markdown("""
        #### üìö **Explica√ß√£o da Evolu√ß√£o Temporal por Regi√£o:**
        
        ##### üéØ **O que este gr√°fico mostra:**
        - **Cada linha colorida** representa uma regi√£o do Brasil
        - **Eixo X:** Anos do per√≠odo analisado
        - **Eixo Y:** Total de doses aplicadas
        - **Marcadores:** Dados espec√≠ficos por ano
        
        ##### üìä **Como interpretar:**
        - **Linhas ascendentes:** Aumento na vacina√ß√£o na regi√£o
        - **Linhas descendentes:** Redu√ß√£o na vacina√ß√£o (poss√≠vel problema)
        - **Linhas paralelas:** Regi√µes com comportamento similar
        - **Diverg√™ncia:** Diferen√ßas crescentes entre regi√µes
        
        ##### üîç **Import√¢ncia epidemiol√≥gica:**
        - **Identifica√ß√£o de desigualdades regionais** na cobertura vacinal
        - **Monitoramento da efic√°cia** das pol√≠ticas regionais
        - **Planejamento de recursos** baseado em tend√™ncias
        - **Detec√ß√£o precoce** de problemas regionais espec√≠ficos
        
        ##### ‚ö†Ô∏è **Sinais de alerta a observar:**
        - Regi√µes com **tend√™ncia decrescente** persistente
        - **Grandes disparidades** entre regi√µes
        - **Estagna√ß√£o** em n√≠veis baixos de cobertura
        - **Variabilidade excessiva** ano a ano
        """)
        
        # Estat√≠sticas regionais
        st.subheader("üìä **Estat√≠sticas Regionais**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr√°fico de barras por regi√£o
            fig_barras_regional = px.bar(
                analise_regional,
                x='Regiao',
                y='Total_Doses',
                title="Total de Doses por Regi√£o",
                color='Regiao',
                text='Total_Doses'
            )
            
            fig_barras_regional.update_layout(
                xaxis_title="Regi√£o",
                yaxis_title="Total de Doses",
                template='plotly_white',
                showlegend=False
            )
            
            fig_barras_regional.update_traces(
                texttemplate='%{text:,}',
                textposition='outside'
            )
            
            st.plotly_chart(fig_barras_regional, use_container_width=True)
            
            # Explica√ß√£o do gr√°fico de total de doses por regi√£o
            st.markdown("""
            **üìñ Gr√°fico de Total de Doses por Regi√£o:**
            - **Barras:** Altura representa total acumulado
            - **Cores:** Diferencia as regi√µes visualmente
            - **N√∫meros:** Valores exatos sobre as barras
            - **Interpreta√ß√£o:** Identifica regi√µes com maior/menor volume total
            - **Aplica√ß√£o:** Aloca√ß√£o proporcional de recursos
            """)
        
        with col2:
            # Gr√°fico de cobertura m√©dia
            fig_cobertura_regional = px.bar(
                analise_regional,
                x='Regiao',
                y='Cobertura_Media',
                title="Cobertura M√©dia por Regi√£o (%)",
                color='Cobertura_Media',
                text='Cobertura_Media'
            )
            
            fig_cobertura_regional.update_layout(
                xaxis_title="Regi√£o",
                yaxis_title="Cobertura M√©dia (%)",
                template='plotly_white',
                showlegend=False
            )
            
            fig_cobertura_regional.update_traces(
                texttemplate='%{text:.1f}%',
                textposition='outside'
            )
            
            st.plotly_chart(fig_cobertura_regional, use_container_width=True)
            
            # Explica√ß√£o do gr√°fico de cobertura m√©dia por regi√£o
            st.markdown("""
            **üìñ Gr√°fico de Cobertura M√©dia por Regi√£o:**
            - **Barras:** Altura representa percentual de cobertura
            - **Escala de cores:** Intensidade proporcional √† cobertura
            - **Meta ideal:** >95% para imunidade coletiva
            - **Interpreta√ß√£o:** Avalia efic√°cia regional
            - **Aplica√ß√£o:** Prioriza√ß√£o de interven√ß√µes
            """)
        
        # An√°lise comparativa detalhada das duas m√©tricas
        st.markdown(f"""
        #### üî¨ **An√°lise Comparativa Total vs Cobertura:**
        
        ##### üìä **Por que analisar ambas as m√©tricas:**
        - **Total de doses:** Mede **volume absoluto** de vacina√ß√£o
        - **Cobertura m√©dia:** Mede **efici√™ncia relativa** √† popula√ß√£o
        
        ##### üéØ **Interpreta√ß√µes poss√≠veis:**
        - **Alto total + Alta cobertura:** Regi√£o populosa bem atendida
        - **Alto total + Baixa cobertura:** Regi√£o populosa com lacunas
        - **Baixo total + Alta cobertura:** Regi√£o pequena bem atendida
        - **Baixo total + Baixa cobertura:** Regi√£o que necessita aten√ß√£o
        
        ##### üìà **Cobertura atual por regi√£o:**
        {f"- **M√©dia geral:** {media_cobertura:.1f}%" if 'media_cobertura' in locals() else ""}
        - **Meta OMS:** >95% para controle efetivo
        - **Situa√ß√£o cr√≠tica:** Regi√µes <70%
        - **Situa√ß√£o boa:** Regi√µes >95%
        """)
        
        # Compara√ß√£o dos √∫ltimos 3 anos
        st.subheader("üîÑ **Compara√ß√£o dos √öltimos 3 Anos por Regi√£o**")
        
        # Preparar dados para compara√ß√£o
        anos_unicos = sorted(imunizacao_regional['Ano'].unique())
        if len(anos_unicos) >= 3:
            anos_recentes = anos_unicos[-3:]
            
            dados_comparacao = imunizacao_regional[imunizacao_regional['Ano'].isin(anos_recentes)]
            
            fig_comparacao = px.bar(
                dados_comparacao,
                x='Regiao',
                y='Total_Doses',
                color='Ano',
                title=f"Compara√ß√£o Regional ({anos_recentes[0]}-{anos_recentes[-1]})",
                barmode='group'
            )
            
            fig_comparacao.update_layout(
                xaxis_title="Regi√£o",
                yaxis_title="Total de Doses",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_comparacao, use_container_width=True)
            
            # Explica√ß√£o do gr√°fico de compara√ß√£o temporal
            st.markdown(f"""
            #### üìñ **Interpreta√ß√£o da Compara√ß√£o dos √öltimos 3 Anos:**
            
            ##### üéØ **O que este gr√°fico mostra:**
            - **Barras agrupadas** por regi√£o, cada cor representa um ano
            - **Evolu√ß√£o temporal** recente da vacina√ß√£o regional
            - **Compara√ß√£o direta** entre regi√µes no mesmo per√≠odo
            
            ##### üìä **Como analisar:**
            - **Barras crescentes:** Melhoria ao longo dos anos
            - **Barras decrescentes:** Redu√ß√£o preocupante
            - **Padr√µes uniformes:** Pol√≠tica nacional consistente
            - **Padr√µes divergentes:** Diferen√ßas regionais espec√≠ficas
            
            ##### üîç **Indicadores importantes:**
            - **Tend√™ncia geral:** {"Crescimento" if anos_recentes else "A ser avaliada"}
            - **Homogeneidade:** Regi√µes com comportamento similar
            - **Outliers:** Regi√µes com comportamento at√≠pico
            - **Sustentabilidade:** Manuten√ß√£o dos n√≠veis ano a ano
            
            ##### üìà **Aplica√ß√µes pr√°ticas:**
            - **Identifica√ß√£o de best practices** regionais
            - **Detec√ß√£o de problemas emergentes**
            - **Planejamento de recursos** para pr√≥ximos anos
            - **Avalia√ß√£o de pol√≠ticas** implementadas
            """)
        
        # An√°lise de correla√ß√£o regional
        st.subheader("üîó **An√°lise de Correla√ß√£o Regional**")

        try:
            # Preferir base consolidada por regi√£o (sem UF)
            regional_cases_path = os.path.join('data', 'processed', 'analise_regional.csv')
            if os.path.exists(regional_cases_path):
                casos_regiao_total = pd.read_csv(regional_cases_path)
                # Espera colunas: Regiao, Casos
                base_merge = analise_regional[['Regiao', 'Total_Doses']].merge(
                    casos_regiao_total[['Regiao', 'Casos']], on='Regiao', how='inner'
                )

                if not base_merge.empty:
                    corr, p_valor = stats.pearsonr(base_merge['Total_Doses'], base_merge['Casos'])
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("üìà Correla√ß√£o (Regi√µes)", f"{corr:.3f}")
                    with col2:
                        st.metric("p-valor", f"{p_valor:.4f}")

                    fig_disp = px.scatter(
                        base_merge,
                        x='Total_Doses',
                        y='Casos',
                        text='Regiao',
                        title='Casos vs Total de Doses por Regi√£o'
                    )
                    
                    # Adicionar linha de tend√™ncia manual
                    if len(base_merge) > 1:
                        x_vals = base_merge['Total_Doses'].values
                        y_vals = base_merge['Casos'].values
                        
                        # Remover NaN values
                        mask = ~(np.isnan(x_vals) | np.isnan(y_vals))
                        x_clean = x_vals[mask]
                        y_clean = y_vals[mask]
                        
                        if len(x_clean) > 1:
                            # Calcular regress√£o linear usando numpy
                            coeffs = np.polyfit(x_clean, y_clean, 1)
                            x_trend = np.linspace(x_clean.min(), x_clean.max(), 100)
                            y_trend = coeffs[0] * x_trend + coeffs[1]
                            
                            # Adicionar linha de tend√™ncia
                            fig_disp.add_trace(go.Scatter(
                                x=x_trend,
                                y=y_trend,
                                mode='lines',
                                name='Linha de Tend√™ncia',
                                line=dict(color='red', dash='dash')
                            ))
                    fig_disp.update_traces(textposition='top center')
                    fig_disp.update_layout(template='plotly_white')
                    st.plotly_chart(fig_disp, use_container_width=True)

                    st.write("**üìã Tabela (Regi√µes):**")
                    st.dataframe(base_merge[['Regiao', 'Total_Doses', 'Casos']])
            else:
                st.info("Dados regionais agregados n√£o encontrados em data/processed/analise_regional.csv. Pulei a correla√ß√£o regional.")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel calcular a correla√ß√£o regional: {e}")
        
        # Resumo da an√°lise regional
        st.markdown("---")
        st.markdown("""
        **üìã Resumo da An√°lise Regional:**
        
        **1. Distribui√ß√£o Geogr√°fica:**
        - An√°lise por 5 regi√µes brasileiras
        - Cobertura vacinal por regi√£o
        - Evolu√ß√£o temporal regional
        
        **2. Compara√ß√µes Regionais:**
        - Ranking de cobertura por regi√£o
        - An√°lise de disparidades geogr√°ficas
        - Tend√™ncias regionais espec√≠ficas
        
        **3. Correla√ß√µes Regionais:**
        - Rela√ß√£o entre vacina√ß√£o e casos por regi√£o
        - Identifica√ß√£o de padr√µes regionais
        - Efetividade da vacina√ß√£o por √°rea geogr√°fica
        """)
        
    else:
        st.error("‚ùå Dados regionais n√£o dispon√≠veis")

def show_epidemiological_analysis(dados):
    """Exibe a se√ß√£o "An√°lise Epidemiol√≥gica - Indicadores de Sa√∫de P√∫blica".

    Esta fun√ß√£o foca em indicadores epidemiol√≥gicos chave, como a letalidade.
    Ela mostra a evolu√ß√£o da taxa de letalidade por etiologia ao longo do tempo,
    apresenta um heatmap para visualiza√ß√£o intuitiva desses dados, e analisa
    a evolu√ß√£o da letalidade m√©dia anual.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza as chaves 'letalidade_etiologia'
                      e 'casos_2017_2022', al√©m de outras tabelas de casos para
                      c√°lculos de fallback.
    """
    st.header("ü¶† **An√°lise Epidemiol√≥gica - Indicadores de Sa√∫de P√∫blica**")
    st.markdown("---")
    
    if dados and 'letalidade_etiologia' in dados and 'casos_2017_2022' in dados:
        # Dados de letalidade
        letalidade_etiologia = dados['letalidade_etiologia']
        casos_2017_2022 = dados['casos_2017_2022']
        
        # M√©tricas epidemiol√≥gicas
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_casos = casos_2017_2022['Casos_Notificados'].sum()
            st.metric("üìä Total de Casos", f"{total_casos:,}")
        
        with col2:
            # Usar a coluna correta Taxa_Letalidade
            if 'Taxa_Letalidade' in letalidade_etiologia.columns:
                media_letalidade = letalidade_etiologia['Taxa_Letalidade'].mean()
                st.metric("üíÄ Letalidade M√©dia", f"{media_letalidade:.1f}%")
            else:
                st.metric("üíÄ Letalidade M√©dia", "N/A")
        
        with col3:
            # Total de √≥bitos com fallback entre bases dispon√≠veis
            total_obitos = 0
            if 'Obitos' in casos_2017_2022.columns:
                total_obitos = pd.to_numeric(casos_2017_2022['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('casos_consolidados' in dados) and isinstance(dados['casos_consolidados'], pd.DataFrame) and ('Obitos' in dados['casos_consolidados'].columns):
                total_obitos = pd.to_numeric(dados['casos_consolidados']['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('bacterianas_2024' in dados) and isinstance(dados['bacterianas_2024'], pd.DataFrame) and ('Obitos' in dados['bacterianas_2024'].columns):
                total_obitos = pd.to_numeric(dados['bacterianas_2024']['Obitos'], errors='coerce').fillna(0).sum()
            if (total_obitos == 0) and ('etiologia_2024' in dados) and isinstance(dados['etiologia_2024'], pd.DataFrame) and ('Obitos' in dados['etiologia_2024'].columns):
                total_obitos = pd.to_numeric(dados['etiologia_2024']['Obitos'], errors='coerce').fillna(0).sum()
            st.metric("‚ö∞Ô∏è Total de √ìbitos", f"{int(total_obitos):,}" if total_obitos else "N/A")
        
        # An√°lise de letalidade por etiologia (melhor visualiza√ß√£o)
        st.subheader("üìà **Letalidade por Etiologia ao Longo do Tempo**")
        
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            let_df = letalidade_etiologia.copy()
            let_df['Taxa_Letalidade'] = pd.to_numeric(let_df['Taxa_Letalidade'], errors='coerce').fillna(0)
            # Garantir n√£o-negatividade
            let_df['Taxa_Letalidade'] = let_df['Taxa_Letalidade'].clip(lower=0)
            fig_letalidade = px.bar(
                let_df,
                x='Ano',
                y='Taxa_Letalidade',
                color='Etiologia',
                barmode='group',
                title="Taxa de Letalidade (%) por Etiologia e Ano"
            )
            fig_letalidade.update_layout(
                xaxis_title="Ano",
                yaxis_title="Taxa de Letalidade (%)",
                template='plotly_white'
            )
            fig_letalidade.update_xaxes(tickformat='d')
            st.plotly_chart(fig_letalidade, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Coluna de letalidade n√£o encontrada nos dados")
        
        # Nova an√°lise: Heatmap de letalidade por etiologia e ano (mais intuitivo, sem escalas negativas)
        st.subheader("üó∫Ô∏è **Mapa de Calor: Letalidade por Etiologia e Ano**")
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            let_hm = letalidade_etiologia.copy()
            let_hm['Taxa_Letalidade'] = pd.to_numeric(let_hm['Taxa_Letalidade'], errors='coerce').fillna(0).clip(lower=0)
            matriz = let_hm.pivot_table(index='Ano', columns='Etiologia', values='Taxa_Letalidade', aggfunc='mean')
            fig_hm = px.imshow(
                matriz.sort_index(),
                color_continuous_scale='Reds',
                aspect='auto',
                labels=dict(color='Letalidade (%)'),
                title='Letalidade (%) por Etiologia e Ano'
            )
            fig_hm.update_layout(template='plotly_white')
            st.plotly_chart(fig_hm, use_container_width=True)
        else:
            st.info("‚ÑπÔ∏è Sem dados de letalidade por etiologia para o heatmap")
        
        # An√°lise de letalidade por ano
        st.subheader("üìä **Letalidade por Ano e Etiologia**")
        
        if 'Taxa_Letalidade' in letalidade_etiologia.columns:
            # Agrupar por ano e calcular m√©dia de letalidade
            letalidade_por_ano = letalidade_etiologia.groupby('Ano')['Taxa_Letalidade'].mean().reset_index()
            
            fig_letalidade_ano = px.line(
                letalidade_por_ano,
                x='Ano',
                y='Taxa_Letalidade',
                title="Evolu√ß√£o da Letalidade M√©dia por Ano (2007-2020)",
                markers=True
            )
            
            fig_letalidade_ano.update_layout(
                xaxis_title="Ano",
                yaxis_title="Letalidade M√©dia (%)",
                template='plotly_white'
            )
            
            st.plotly_chart(fig_letalidade_ano, use_container_width=True)
            
            # Estat√≠sticas de letalidade
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Estat√≠sticas de Letalidade por Etiologia:**")
                st.dataframe(letalidade_etiologia.groupby('Etiologia')['Taxa_Letalidade'].describe())
            
            with col2:
                st.write("**Letalidade por Ano:**")
                st.dataframe(letalidade_por_ano)
        else:
            st.warning("‚ö†Ô∏è Dados de letalidade n√£o dispon√≠veis para an√°lise detalhada")
        
        # Informa√ß√µes sobre a an√°lise
        st.subheader("‚ÑπÔ∏è **Sobre a An√°lise Epidemiol√≥gica**")
        st.markdown("""
        **Esta an√°lise mostra:**
        - Taxas de letalidade por etiologia
        - Evolu√ß√£o temporal de casos e √≥bitos
        - Padr√µes de letalidade ao longo do tempo
        - Compara√ß√£o entre diferentes agentes causadores
        
        **Import√¢ncia:**
        - Identificar agentes mais letais
        - Monitorar tend√™ncias de letalidade
        - Planejar estrat√©gias de tratamento
        - Avaliar efetividade de interven√ß√µes
        """)
    else:
        st.warning("‚ö†Ô∏è Dados epidemiol√≥gicos n√£o dispon√≠veis")

def show_attack_rate_analysis(dados):
    """Exibe a se√ß√£o "An√°lise de Taxa de Ataque e For√ßa de Infec√ß√£o".

    Calcula e exibe a taxa de ataque (casos por 100.000 habitantes) e a for√ßa de
    infec√ß√£o (taxa instant√¢nea de aquisi√ß√£o da doen√ßa). A fun√ß√£o mostra a evolu√ß√£o
    anual dessas m√©tricas, a sazonalidade baseada em dados de hospitaliza√ß√£o (SIH),
    e a correla√ß√£o entre a taxa de ataque e a letalidade.

    Args:
        dados (dict): O dicion√°rio global de dados. Utiliza 'casos_2017_2022',
                      'casos_consolidados', e 'sih_meningite'.
    """
    st.header("‚ö° **An√°lise de Taxa de Ataque e For√ßa de Infec√ß√£o**")
    st.markdown("---")
    
    if dados and ('casos_2017_2022' in dados or 'casos_consolidados' in dados):
        # Unificar casos anuais a partir de todas as tabelas dispon√≠veis
        frames = []
        if 'casos_2017_2022' in dados and isinstance(dados['casos_2017_2022'], pd.DataFrame):
            frames.append(dados['casos_2017_2022'][['Ano', 'Casos_Notificados'] + (["Obitos"] if 'Obitos' in dados['casos_2017_2022'].columns else [])])
        if 'casos_consolidados' in dados and isinstance(dados['casos_consolidados'], pd.DataFrame):
            frames.append(dados['casos_consolidados'][['Ano', 'Casos_Notificados'] + (["Obitos"] if 'Obitos' in dados['casos_consolidados'].columns else [])])
        if not frames:
            st.warning("‚ö†Ô∏è Nenhuma tabela de casos encontrada para taxa de ataque")
            return
        casos_anuais = pd.concat(frames, ignore_index=True).groupby('Ano', as_index=False).sum(numeric_only=True)
        
        # M√©tricas de taxa de ataque
        col1, col2, col3 = st.columns(3)
        
        with col1:
            total_casos = casos_anuais['Casos_Notificados'].sum()
            st.metric("üìä Total de Casos", f"{total_casos:,}")
        
        with col2:
            # Verificar se a coluna Obitos existe
            if 'Obitos' in casos_anuais.columns:
                total_obitos = casos_anuais['Obitos'].sum()
                st.metric("üíÄ Total de √ìbitos", f"{total_obitos:,}")
            else:
                st.metric("üíÄ Total de √ìbitos", "N/A")
        
        with col3:
            taxa_ataque_geral = (total_casos / 214000000) * 100000  # Popula√ß√£o estimada Brasil
            st.metric("üéØ Taxa de Ataque", f"{taxa_ataque_geral:.1f}/100k")
        
        # An√°lise de taxa de ataque por ano
        st.subheader("üìà **Taxa de Ataque por Ano**")
        
        # Calcular taxa de ataque anual
        taxa_ataque_anual = casos_anuais.copy()
        
        # Calcular taxa de letalidade anual (se houver √≥bitos)
        if 'Obitos' in taxa_ataque_anual.columns:
            taxa_ataque_anual['Taxa_Letalidade'] = (taxa_ataque_anual['Obitos'] / taxa_ataque_anual['Casos_Notificados']) * 100
        
        # Popula√ß√£o: se n√£o houver fonte no projeto, aplicar aproxima√ß√£o com preenchimento progressivo
        populacao_anos = {
            2017: 209_000_000,
            2018: 210_000_000,
            2019: 211_000_000,
            2020: 212_000_000,
            2021: 213_000_000,
            2022: 214_000_000,
        }
        taxa_ataque_anual['Populacao'] = taxa_ataque_anual['Ano'].map(populacao_anos)
        # Preencher anos sem popula√ß√£o com √∫ltimo valor conhecido
        taxa_ataque_anual = taxa_ataque_anual.sort_values('Ano')
        taxa_ataque_anual['Populacao'] = taxa_ataque_anual['Populacao'].ffill().bfill()
        taxa_ataque_anual['Taxa_Ataque'] = (taxa_ataque_anual['Casos_Notificados'] / taxa_ataque_anual['Populacao']) * 100000
        
        # Gr√°fico de taxa de ataque
        fig_taxa_ataque = px.line(
            taxa_ataque_anual,
            x='Ano',
            y='Taxa_Ataque',
            title="Taxa de Ataque de Meningite por Ano (por 100.000 habitantes)",
            markers=True,
            line_shape='linear'
        )
        
        fig_taxa_ataque.update_layout(
            xaxis_title="Ano",
            yaxis_title="Taxa de Ataque (por 100.000 habitantes)",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_taxa_ataque, use_container_width=True)
        
        # Explica√ß√£o do conceito de taxa de ataque e do gr√°fico
        st.markdown(f"""
        #### üìö **Explica√ß√£o da Taxa de Ataque:**
        
        ##### üéØ **O que √© Taxa de Ataque:**
        - **Defini√ß√£o:** Propor√ß√£o de pessoas que desenvolvem a doen√ßa em uma popula√ß√£o espec√≠fica durante um per√≠odo determinado
        - **Unidade:** Casos por 100.000 habitantes por ano
        - **C√°lculo:** (N√∫mero de casos / Popula√ß√£o total) √ó 100.000
        - **Utilidade:** Padroniza a incid√™ncia para compara√ß√£o entre diferentes popula√ß√µes e per√≠odos
        
        ##### üìä **Interpreta√ß√£o do Gr√°fico:**
        - **Eixo X:** Anos do per√≠odo analisado
        - **Eixo Y:** Taxa de ataque por 100.000 habitantes
        - **Linha com marcadores:** Evolu√ß√£o temporal da incid√™ncia padronizada
        - **Tend√™ncia crescente:** Aumento da incid√™ncia na popula√ß√£o
        - **Tend√™ncia decrescente:** Redu√ß√£o da incid√™ncia (possivelmente devido a vacina√ß√£o)
        - **Varia√ß√µes anuais:** Podem refletir surtos, mudan√ßas epidemiol√≥gicas ou melhorias na vigil√¢ncia
        
        ##### üìà **Taxa de Ataque Atual: {taxa_ataque_geral:.1f}/100k habitantes**
        - **Baixa:** < 1,0/100k (situa√ß√£o controlada)
        - **Moderada:** 1,0-5,0/100k (vigil√¢ncia necess√°ria)
        - **Alta:** > 5,0/100k (situa√ß√£o de alerta)
        - **Classifica√ß√£o atual:** {"Baixa - situa√ß√£o controlada" if taxa_ataque_geral < 1.0 else "Moderada - vigil√¢ncia necess√°ria" if taxa_ataque_geral < 5.0 else "Alta - situa√ß√£o de alerta"}
        
        ##### üåç **Contexto Epidemiol√≥gico:**
        - **OMS recomenda:** Taxa < 2,0/100k como meta de controle
        - **Pa√≠ses desenvolvidos:** Geralmente < 1,0/100k
        - **Imunidade coletiva:** Taxa diminui com alta cobertura vacinal
        - **Vigil√¢ncia epidemiol√≥gica:** Monitoramento cont√≠nuo √© essencial
        """)
        
        # An√°lise de for√ßa de infec√ß√£o
        st.subheader("ü¶† **An√°lise de For√ßa de Infec√ß√£o**")
        
        # Calcular for√ßa de infec√ß√£o (simulado)
        # For√ßa de infec√ß√£o = -ln(1 - taxa de ataque)
        taxa_ataque_anual['Forca_Infeccao'] = -np.log(1 - (taxa_ataque_anual['Taxa_Ataque'] / 100000))
        
        # Gr√°fico de for√ßa de infec√ß√£o
        fig_forca_infeccao = px.line(
            taxa_ataque_anual,
            x='Ano',
            y='Forca_Infeccao',
            title="For√ßa de Infec√ß√£o de Meningite por Ano",
            markers=True,
            line_shape='linear'
        )
        
        fig_forca_infeccao.update_layout(
            xaxis_title="Ano",
            yaxis_title="For√ßa de Infec√ß√£o",
            template='plotly_white'
        )
        
        st.plotly_chart(fig_forca_infeccao, use_container_width=True)
        
        # Explica√ß√£o da for√ßa de infec√ß√£o
        st.markdown("""
        #### üìö **Explica√ß√£o da For√ßa de Infec√ß√£o:**
        
        ##### ü¶† **O que √© For√ßa de Infec√ß√£o:**
        - **Defini√ß√£o:** Taxa instant√¢nea na qual indiv√≠duos suscet√≠veis adquirem infec√ß√£o
        - **F√≥rmula:** Œª = -ln(1 - taxa de ataque)
        - **Interpreta√ß√£o:** Intensidade da transmiss√£o da doen√ßa na popula√ß√£o
        - **Unidade:** Por unidade de tempo (geralmente por ano)
        
        ##### üìä **Interpreta√ß√£o do Gr√°fico:**
        - **Eixo X:** Anos do per√≠odo analisado
        - **Eixo Y:** For√ßa de infec√ß√£o (Œª)
        - **Linha:** Intensidade da transmiss√£o ao longo do tempo
        - **Valores altos:** Maior intensidade de transmiss√£o
        - **Valores baixos:** Menor intensidade de transmiss√£o
        
        ##### üî¨ **Import√¢ncia Epidemiol√≥gica:**
        - **Modelagem matem√°tica:** Base para modelos de transmiss√£o
        - **Planejamento de interven√ß√µes:** Identifica per√≠odos de alta transmiss√£o
        - **Avalia√ß√£o de controle:** Monitora efic√°cia das medidas de preven√ß√£o
        - **Compara√ß√£o temporal:** Permite comparar diferentes per√≠odos epidemiol√≥gicos
        """)
        
        # An√°lise de sazonalidade da taxa de ataque usando SIH (dados reais)
        st.subheader("üìÖ **Sazonalidade da Taxa de Ataque (SIH)**")
        if 'sih_meningite' in dados and isinstance(dados['sih_meningite'], pd.DataFrame):
            sih = dados['sih_meningite'].copy()
            if {'M√™s_Num', 'Casos_Hospitalares'}.issubset(sih.columns):
                sih['Casos_Hospitalares'] = pd.to_numeric(sih['Casos_Hospitalares'], errors='coerce').fillna(0)
                mensal = sih.groupby('M√™s_Num', as_index=False)['Casos_Hospitalares'].sum()
                # Nome dos meses na ordem
                nomes_meses = {1:'Jan',2:'Fev',3:'Mar',4:'Abr',5:'Mai',6:'Jun',7:'Jul',8:'Ago',9:'Set',10:'Out',11:'Nov',12:'Dez'}
                mensal['Mes'] = mensal['M√™s_Num'].map(nomes_meses)
                # Base populacional: usar mediana das popula√ß√µes anuais calculadas
                pop_base = float(taxa_ataque_anual['Populacao'].median()) if 'Populacao' in taxa_ataque_anual.columns else 214_000_000.0
                mensal['Taxa_Ataque_Mensal'] = (mensal['Casos_Hospitalares'] / pop_base) * 100000
                mensal = mensal.sort_values('M√™s_Num')

                fig_sazonal = px.bar(
                    mensal,
                    x='Mes',
                    y='Taxa_Ataque_Mensal',
                    title='Sazonalidade da Taxa de Ataque (Hospitaliza√ß√µes SIH)',
                    color='Taxa_Ataque_Mensal',
                    color_continuous_scale='Reds'
                )
                fig_sazonal.update_layout(
                    xaxis_title='M√™s',
                    yaxis_title='Taxa de Ataque (por 100.000 hab.)',
                    template='plotly_white'
                )
                st.plotly_chart(fig_sazonal, use_container_width=True)
                
                # Explica√ß√£o do gr√°fico de sazonalidade
                st.markdown("""
                #### üìñ **Interpreta√ß√£o da Sazonalidade da Taxa de Ataque:**
                - **Eixo X:** Meses do ano (Jan a Dez)
                - **Eixo Y:** Taxa de ataque mensal por 100.000 habitantes
                - **Barras coloridas:** Intensidade da cor reflete a magnitude da taxa
                - **Dados:** Baseados em hospitaliza√ß√µes do SIH (proxy para casos graves)
                
                ##### üå°Ô∏è **Padr√µes Sazonais Esperados:**
                - **Inverno (Jun-Ago):** Maior incid√™ncia devido a:
                  - Aglomera√ß√£o em ambientes fechados
                  - Redu√ß√£o da umidade relativa
                  - Menor ventila√ß√£o
                - **Ver√£o (Dez-Fev):** Menor incid√™ncia devido a:
                  - Maior dispers√£o populacional
                  - Melhor ventila√ß√£o dos ambientes
                  - Condi√ß√µes clim√°ticas desfavor√°veis ao pat√≥geno
                
                ##### üìä **Utilidade da An√°lise:**
                - **Planejamento de recursos:** Antecipar picos de demanda hospitalar
                - **Campanhas preventivas:** Intensificar a√ß√µes nos meses de risco
                - **Vigil√¢ncia epidemiol√≥gica:** Monitoramento direcionado
                - **Pol√≠ticas de sa√∫de:** Adequa√ß√£o de estrat√©gias por per√≠odo
                """)
            else:
                st.info("‚ÑπÔ∏è Estrutura de SIH n√£o possui colunas esperadas para sazonalidade (M√™s_Num, Casos_Hospitalares)")
        else:
            st.info("‚ÑπÔ∏è Dados SIH n√£o encontrados para an√°lise sazonal")
        
        # An√°lise de correla√ß√£o entre taxa de ataque e letalidade
        st.subheader("üîó **Correla√ß√£o Taxa de Ataque vs Letalidade**")
        
        if 'Taxa_Letalidade' in taxa_ataque_anual.columns:
            # Calcular correla√ß√£o
            correlacao = taxa_ataque_anual['Taxa_Ataque'].corr(taxa_ataque_anual['Taxa_Letalidade'])
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("üìä Correla√ß√£o", f"{correlacao:.3f}")
                
                if abs(correlacao) > 0.7:
                    st.success("üîó **Forte correla√ß√£o**")
                elif abs(correlacao) > 0.3:
                    st.info("üîó **Correla√ß√£o moderada**")
                else:
                    st.warning("üîó **Correla√ß√£o fraca**")
            
            with col2:
                # Gr√°fico de dispers√£o
                fig_correlacao = px.scatter(
                    taxa_ataque_anual,
                    x='Taxa_Ataque',
                    y='Taxa_Letalidade',
                    title="Correla√ß√£o: Taxa de Ataque vs Letalidade"
                )
                
                # Adicionar linha de tend√™ncia manual usando numpy
                if len(taxa_ataque_anual) > 1:
                    x_vals = taxa_ataque_anual['Taxa_Ataque'].values
                    y_vals = taxa_ataque_anual['Taxa_Letalidade'].values
                    
                    # Remover NaN values
                    mask = ~(np.isnan(x_vals) | np.isnan(y_vals))
                    x_clean = x_vals[mask]
                    y_clean = y_vals[mask]
                    
                    if len(x_clean) > 1:
                        # Calcular regress√£o linear usando numpy
                        coeffs = np.polyfit(x_clean, y_clean, 1)
                        x_trend = np.linspace(x_clean.min(), x_clean.max(), 100)
                        y_trend = coeffs[0] * x_trend + coeffs[1]
                        
                        # Adicionar linha de tend√™ncia
                        fig_correlacao.add_trace(go.Scatter(
                            x=x_trend,
                            y=y_trend,
                            mode='lines',
                            name='Linha de Tend√™ncia',
                            line=dict(color='red', dash='dash')
                        ))
                
                fig_correlacao.update_layout(
                    xaxis_title="Taxa de Ataque (por 100.000 habitantes)",
                    yaxis_title="Taxa de Letalidade (%)",
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_correlacao, use_container_width=True)
                
                # Explica√ß√£o da correla√ß√£o taxa de ataque vs letalidade
                st.markdown(f"""
                #### üìö **Explica√ß√£o da Correla√ß√£o Taxa de Ataque vs Letalidade:**
                
                ##### üìä **Correla√ß√£o de Pearson = {correlacao:.3f}**
                - **O que mede:** Rela√ß√£o linear entre incid√™ncia e gravidade da doen√ßa
                - **Interpreta√ß√£o:**
                  - **Correla√ß√£o positiva:** Maior incid√™ncia associada a maior letalidade
                  - **Correla√ß√£o negativa:** Maior incid√™ncia associada a menor letalidade
                  - **Sem correla√ß√£o:** Incid√™ncia e letalidade independentes
                
                ##### üìñ **Interpreta√ß√£o do Gr√°fico:**
                - **Eixo X:** Taxa de ataque (incid√™ncia por 100.000 hab.)
                - **Eixo Y:** Taxa de letalidade (%)
                - **Pontos:** Cada ponto representa um ano espec√≠fico
                - **Linha tracejada:** Tend√™ncia linear da rela√ß√£o
                
                ##### üî¨ **Significado Epidemiol√≥gico:**
                - **Correla√ß√£o positiva pode indicar:**
                  - Surtos com cepas mais virulentas
                  - Sobrecarregamento do sistema de sa√∫de
                  - Diagn√≥stico tardio em per√≠odos de alta incid√™ncia
                  
                - **Correla√ß√£o negativa pode indicar:**
                  - Melhoria na detec√ß√£o precoce
                  - Aumento de casos leves diagnosticados
                  - Efeito de dilui√ß√£o com mais casos benignos
                  
                - **Aus√™ncia de correla√ß√£o pode indicar:**
                  - Letalidade constante independente da incid√™ncia
                  - Qualidade consistente do atendimento m√©dico
                  - Distribui√ß√£o uniforme da virul√™ncia das cepas
                
                ##### üéØ **Classifica√ß√£o Atual: {"Forte" if abs(correlacao) > 0.7 else "Moderada" if abs(correlacao) > 0.3 else "Fraca"}**
                - **Fraca:** |r| < 0.3 - Rela√ß√£o pouco evidente
                - **Moderada:** 0.3 ‚â§ |r| < 0.7 - Rela√ß√£o moderada
                - **Forte:** |r| ‚â• 0.7 - Rela√ß√£o bem definida
                """)
        else:
            st.info("‚ÑπÔ∏è Dados de letalidade n√£o dispon√≠veis para an√°lise de correla√ß√£o")
        
        # Resumo estat√≠stico
        st.subheader("üìã **Resumo Estat√≠stico**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Estat√≠sticas da Taxa de Ataque:**")
            st.dataframe(taxa_ataque_anual['Taxa_Ataque'].describe())
        
        with col2:
            st.write("**Dados de Taxa de Ataque por Ano:**")
            st.dataframe(taxa_ataque_anual[['Ano', 'Taxa_Ataque', 'Forca_Infeccao']].round(4))
        
        # Informa√ß√µes sobre a an√°lise
        st.subheader("‚ÑπÔ∏è **Sobre a An√°lise de Taxa de Ataque**")
        st.markdown("""
        **Esta an√°lise mostra:**
        - Taxa de ataque por ano (casos por 100.000 habitantes)
        - For√ßa de infec√ß√£o ao longo do tempo
        - Padr√µes sazonais da doen√ßa
        - Correla√ß√£o entre incid√™ncia e letalidade
        
        **Import√¢ncia:**
        - Medir o risco populacional
        - Identificar per√≠odos de maior risco
        - Planejar a√ß√µes de preven√ß√£o
        - Avaliar efetividade de interven√ß√µes
        """)
    else:
        st.warning("‚ö†Ô∏è Dados de casos n√£o dispon√≠veis")

def show_free_exploration(dados):
    """Exibe a se√ß√£o "Explora√ß√£o Livre dos Dados".

    Cria uma interface interativa que permite ao usu√°rio selecionar qualquer um dos
    datasets carregados, visualizar suas informa√ß√µes (linhas, colunas, tipos de dados,
    valores nulos), analisar colunas individuais com histogramas e gr√°ficos de barras,
    e explorar correla√ß√µes. Oferece tamb√©m filtros personalizados e a op√ß√£o de
    fazer o download dos dados filtrados.

    Args:
        dados (dict): O dicion√°rio global contendo todos os DataFrames dispon√≠veis
                      para explora√ß√£o.
    """
    st.header("üîç **Explora√ß√£o Livre dos Dados**")
    st.markdown("---")
    
    if dados:
        st.info("üí° **Use esta se√ß√£o para explorar os dados de forma personalizada**")
        
        # Sele√ß√£o de dados
        st.subheader("üìä **Sele√ß√£o de Dados**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            datasets_disponiveis = list(dados.keys())
            dataset_selecionado = st.selectbox(
                "Selecione o Dataset:",
                datasets_disponiveis,
                help="Escolha qual conjunto de dados analisar"
            )
        
        with col2:
            if dataset_selecionado:
                dataset = dados[dataset_selecionado]
                if isinstance(dataset, pd.DataFrame):
                    st.metric("üìà Linhas", len(dataset))
                    st.metric("üìã Colunas", len(dataset.columns))
        
        # Visualiza√ß√£o dos dados
        if dataset_selecionado and dataset_selecionado in dados:
            dataset = dados[dataset_selecionado]
            
            if isinstance(dataset, pd.DataFrame):
                st.subheader("üìã **Visualiza√ß√£o dos Dados**")
                
                # Mostrar primeiras linhas
                st.write("**Primeiras 10 linhas:**")
                st.dataframe(dataset.head(10))
                
                # Informa√ß√µes do dataset
                st.write("**Informa√ß√µes do Dataset:**")
                buffer = st.empty()
                
                if st.button("üìä Mostrar Informa√ß√µes"):
                    with buffer.container():
                        st.write(f"**Forma:** {dataset.shape}")
                        st.write(f"**Tipos de dados:**")
                        st.write(dataset.dtypes)
                        st.write(f"**Valores nulos:**")
                        st.write(dataset.isnull().sum())
                        st.write(f"**Estat√≠sticas descritivas:**")
                        st.write(dataset.describe())
                
                # An√°lise de colunas
                st.subheader("üîç **An√°lise de Colunas**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    colunas_numericas = dataset.select_dtypes(include=[np.number]).columns.tolist()
                    if colunas_numericas:
                        coluna_analise = st.selectbox(
                            "Selecione uma coluna num√©rica:",
                            colunas_numericas
                        )
                        
                        if coluna_analise:
                            # Histograma
                            fig_hist = px.histogram(
                                dataset,
                                x=coluna_analise,
                                title=f"Distribui√ß√£o de {coluna_analise}",
                                nbins=20
                            )
                            fig_hist.update_layout(template='plotly_white')
                            st.plotly_chart(fig_hist, use_container_width=True)
                
                with col2:
                    colunas_categoricas = dataset.select_dtypes(include=['object']).columns.tolist()
                    if colunas_categoricas:
                        coluna_cat = st.selectbox(
                            "Selecione uma coluna categ√≥rica:",
                            colunas_categoricas
                        )
                        
                        if coluna_cat:
                            # Contagem de valores
                            contagem = dataset[coluna_cat].value_counts().head(10)
                            fig_bar = px.bar(
                                x=contagem.index,
                                y=contagem.values,
                                title=f"Top 10 valores de {coluna_cat}"
                            )
                            fig_bar.update_layout(
                                xaxis_title=coluna_cat,
                                yaxis_title="Contagem",
                                template='plotly_white'
                            )
                            st.plotly_chart(fig_bar, use_container_width=True)
                
                # An√°lise de correla√ß√£o
                if len(colunas_numericas) > 1:
                    st.subheader("üîó **An√°lise de Correla√ß√£o**")
                    
                    # Sele√ß√£o de colunas para correla√ß√£o
                    colunas_correlacao = st.multiselect(
                        "Selecione colunas para an√°lise de correla√ß√£o:",
                        colunas_numericas,
                        default=colunas_numericas[:5] if len(colunas_numericas) >= 5 else colunas_numericas
                    )
                    
                    if len(colunas_correlacao) > 1:
                        # Calcular correla√ß√£o
                        correlacao = dataset[colunas_correlacao].corr()
                        
                        # Heatmap de correla√ß√£o
                        fig_corr = px.imshow(
                            correlacao,
                            title="Matriz de Correla√ß√£o",
                            color_continuous_scale='RdBu',
                            aspect='auto'
                        )
                        fig_corr.update_layout(template='plotly_white')
                        st.plotly_chart(fig_corr, use_container_width=True)
                        
                        # Tabela de correla√ß√£o
                        st.write("**Matriz de Correla√ß√£o:**")
                        st.dataframe(correlacao.round(3))
                
                # Filtros personalizados
                st.subheader("üîß **Filtros Personalizados**")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if colunas_numericas:
                        coluna_filtro = st.selectbox(
                            "Coluna para filtro:",
                            colunas_numericas
                        )
                        
                        if coluna_filtro:
                            valor_min = float(dataset[coluna_filtro].min())
                            valor_max = float(dataset[coluna_filtro].max())

                            # Garantir intervalo v√°lido para o slider
                            if valor_min == valor_max:
                                # Expande um pouco o range para evitar erro do Streamlit
                                valor_min_adj = valor_min - 1.0
                                valor_max_adj = valor_max + 1.0
                                default_range = (valor_min_adj, valor_max_adj)
                            else:
                                valor_min_adj = valor_min
                                valor_max_adj = valor_max
                                default_range = (valor_min, valor_max)

                            filtro_min, filtro_max = st.slider(
                                f"Faixa de {coluna_filtro}:",
                                min_value=valor_min_adj,
                                max_value=valor_max_adj,
                                value=default_range
                            )
                
                with col2:
                    if colunas_categoricas:
                        coluna_cat_filtro = st.selectbox(
                            "Coluna categ√≥rica para filtro:",
                            colunas_categoricas
                        )
                        
                        if coluna_cat_filtro:
                            valores_unicos = dataset[coluna_cat_filtro].unique()
                            valores_selecionados = st.multiselect(
                                f"Valores de {coluna_cat_filtro}:",
                                valores_unicos,
                                default=valores_unicos[:5] if len(valores_unicos) >= 5 else valores_unicos
                            )
                
                # Aplicar filtros
                if st.button("üîç Aplicar Filtros"):
                    dataset_filtrado = dataset.copy()
                    
                    if 'coluna_filtro' in locals() and 'filtro_min' in locals() and 'filtro_max' in locals():
                        dataset_filtrado = dataset_filtrado[
                            (dataset_filtrado[coluna_filtro] >= filtro_min) &
                            (dataset_filtrado[coluna_filtro] <= filtro_max)
                        ]
                    
                    if 'coluna_cat_filtro' in locals() and 'valores_selecionados' in locals():
                        dataset_filtrado = dataset_filtrado[
                            dataset_filtrado[coluna_cat_filtro].isin(valores_selecionados)
                        ]
                    
                    st.success(f"‚úÖ Filtros aplicados! Dataset filtrado: {dataset_filtrado.shape}")
                    st.write("**Dados filtrados:**")
                    st.dataframe(dataset_filtrado.head(10))
                    
                    # Download dos dados filtrados
                    csv_filtrado = dataset_filtrado.to_csv(index=False)
                    st.download_button(
                        label="üì• Download dos Dados Filtrados (CSV)",
                        data=csv_filtrado,
                        file_name=f"{dataset_selecionado}_filtrado.csv",
                        mime="text/csv"
                    )
                
                # Estat√≠sticas personalizadas
                st.subheader("üìä **Estat√≠sticas Personalizadas**")
                
                if st.button("üìà Calcular Estat√≠sticas"):
                    with st.spinner("Calculando estat√≠sticas..."):
                        # Estat√≠sticas gerais
                        st.write("**Estat√≠sticas Gerais:**")
                        st.write(f"Total de registros: {len(dataset)}")
                        st.write(f"Total de colunas: {len(dataset.columns)}")
                        st.write(f"Mem√≥ria utilizada: {dataset.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
                        
                        # Estat√≠sticas por tipo de coluna
                        st.write("**Estat√≠sticas por Tipo de Coluna:**")
                        for dtype in dataset.dtypes.unique():
                            colunas_tipo = dataset.select_dtypes(include=[dtype]).columns
                            st.write(f"- {dtype}: {len(colunas_tipo)} colunas")
                        
                        # Valores √∫nicos por coluna
                        st.write("**Valores √önicos por Coluna:**")
                        for col in dataset.columns:
                            if dataset[col].dtype == 'object':
                                valores_unicos = dataset[col].nunique()
                                st.write(f"- {col}: {valores_unicos} valores √∫nicos")
        
        else:
            st.warning("‚ö†Ô∏è Selecione um dataset v√°lido para come√ßar a explora√ß√£o")
        
        # Resumo da explora√ß√£o livre
        st.markdown("---")
        st.markdown("""
        **üìã Funcionalidades da Explora√ß√£o Livre:**
        
        **1. Visualiza√ß√£o de Dados:**
        - Sele√ß√£o de datasets
        - Visualiza√ß√£o de primeiras linhas
        - Informa√ß√µes sobre estrutura dos dados
        
        **2. An√°lise Explorat√≥ria:**
        - Histogramas para vari√°veis num√©ricas
        - Gr√°ficos de barras para vari√°veis categ√≥ricas
        - An√°lise de correla√ß√£o
        
        **3. Filtros Personalizados:**
        - Filtros por faixa de valores
        - Filtros por valores categ√≥ricos
        - Download de dados filtrados
        
        **4. Estat√≠sticas Personalizadas:**
        - Estat√≠sticas descritivas
        - Informa√ß√µes sobre tipos de dados
        - An√°lise de valores √∫nicos
        """)
        
    else:
        st.error("‚ùå Nenhum dado dispon√≠vel para explora√ß√£o")

def show_reports(dados):
    """Exibe a se√ß√£o "Relat√≥rios e Downloads".

    Esta fun√ß√£o oferece ferramentas para que o usu√°rio possa gerar e baixar
    informa√ß√µes consolidadas. Ela permite a cria√ß√£o de relat√≥rios autom√°ticos
    (de casos, imuniza√ß√£o, sorogrupos), o download dos principais datasets em
    formato CSV, e a gera√ß√£o de relat√≥rios personalizados com sele√ß√£o de
    datasets, per√≠odo e tipo de relat√≥rio.

    Args:
        dados (dict): O dicion√°rio global de dados, usado para gerar os relat√≥rios
                      e fornecer os arquivos para download.
    """
    st.header("üìã **Relat√≥rios e Downloads**")
    st.markdown("---")
    
    if dados:
        st.info("üí° **Gere relat√≥rios personalizados e fa√ßa download dos dados**")
        
        # Relat√≥rios autom√°ticos
        st.subheader("üìä **Relat√≥rios Autom√°ticos**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìà Relat√≥rio de Casos"):
                with st.spinner("Gerando relat√≥rio de casos..."):
                    if 'casos_2017_2022' in dados:
                        casos = dados['casos_2017_2022']
                        
                        # Resumo de casos
                        total_casos = casos['Casos_Notificados'].sum()
                        total_obitos = casos['√ìbitos'].sum()
                        media_casos_ano = casos.groupby('Ano')['Casos_Notificados'].sum().mean()
                        media_obitos_ano = casos.groupby('Ano')['√ìbitos'].sum().mean()
                        
                        # Criar relat√≥rio
                        relatorio_casos = f"""
                        # RELAT√ìRIO DE CASOS DE MENINGITE (2017-2022)
                        
                        ## Resumo Executivo
                        - **Total de Casos:** {total_casos:,}
                        - **Total de √ìbitos:** {total_obitos:,}
                        - **M√©dia Anual de Casos:** {media_casos_ano:.0f}
                        - **M√©dia Anual de √ìbitos:** {media_obitos_ano:.0f}
                        
                        ## An√°lise por Ano
                        """
                        
                        # Adicionar dados por ano
                        casos_por_ano = casos.groupby('Ano').agg({
                            'Casos_Notificados': 'sum',
                            '√ìbitos': 'sum'
                        }).reset_index()
                        
                        for _, row in casos_por_ano.iterrows():
                            relatorio_casos += f"\n- **{row['Ano']}:** {row['Casos_Notificados']:,} casos, {row['√ìbitos']:,} √≥bitos"
                        
                        # Download do relat√≥rio
                        st.download_button(
                            label="üì• Download Relat√≥rio de Casos (MD)",
                            data=relatorio_casos,
                            file_name="relatorio_casos_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("‚úÖ Relat√≥rio de casos gerado com sucesso!")
                    else:
                        st.error("‚ùå Dados de casos n√£o dispon√≠veis")
        
        with col2:
            if st.button("üíâ Relat√≥rio de Imuniza√ß√£o"):
                with st.spinner("Gerando relat√≥rio de imuniza√ß√£o..."):
                    if 'imunizacao_ano' in dados:
                        imunizacao = dados['imunizacao_ano']
                        
                        # Resumo de imuniza√ß√£o
                        total_doses = imunizacao['Total_Doses'].sum()
                        media_doses_ano = imunizacao['Total_Doses'].mean()
                        periodo_cobertura = f"{imunizacao['Ano'].min()}-{imunizacao['Ano'].max()}"
                        
                        # Criar relat√≥rio
                        relatorio_imunizacao = f"""
                        # RELAT√ìRIO DE IMUNIZA√á√ÉO (1994-2022)
                        
                        ## Resumo Executivo
                        - **Total de Doses:** {total_doses:,}
                        - **M√©dia Anual:** {media_doses_ano:.0f} doses
                        - **Per√≠odo de Cobertura:** {periodo_cobertura}
                        
                        ## Evolu√ß√£o Temporal
                        """
                        
                        # Adicionar dados por ano
                        for _, row in imunizacao.iterrows():
                            relatorio_imunizacao += f"\n- **{row['Ano']}:** {row['Total_Doses']:,} doses"
                        
                        # Download do relat√≥rio
                        st.download_button(
                            label="üì• Download Relat√≥rio de Imuniza√ß√£o (MD)",
                            data=relatorio_imunizacao,
                            file_name="relatorio_imunizacao_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("‚úÖ Relat√≥rio de imuniza√ß√£o gerado com sucesso!")
                    else:
                        st.error("‚ùå Dados de imuniza√ß√£o n√£o dispon√≠veis")
        
        with col3:
            if st.button("ü¶† Relat√≥rio de Sorogrupos"):
                with st.spinner("Gerando relat√≥rio de sorogrupos..."):
                    if 'sorogrupos_consolidados' in dados:
                        sorogrupos = dados['sorogrupos_consolidados']
                        
                        # Resumo de sorogrupos
                        total_sorogrupos = len(sorogrupos)
                        periodo_sorogrupos = f"{sorogrupos['Ano'].min()}-{sorogrupos['Ano'].max()}"
                        
                        # Criar relat√≥rio
                        relatorio_sorogrupos = f"""
                        # RELAT√ìRIO DE SOROGRUPOS (2007-2024)
                        
                        ## Resumo Executivo
                        - **Total de Sorogrupos:** {total_sorogrupos}
                        - **Per√≠odo de An√°lise:** {periodo_sorogrupos}
                        
                        ## Principais Sorogrupos
                        """
                        
                        # Adicionar dados de sorogrupos
                        for _, row in sorogrupos.head(10).iterrows():
                            relatorio_sorogrupos += f"\n- **{row['Sorogrupo']} ({row['Ano']}):** {row['Casos']:,} casos"
                        
                        # Download do relat√≥rio
                        st.download_button(
                            label="üì• Download Relat√≥rio de Sorogrupos (MD)",
                            data=relatorio_sorogrupos,
                            file_name="relatorio_sorogrupos_meningite.md",
                            mime="text/markdown"
                        )
                        
                        st.success("‚úÖ Relat√≥rio de sorogrupos gerado com sucesso!")
                    else:
                        st.error("‚ùå Dados de sorogrupos n√£o dispon√≠veis")
        
        # Downloads de dados
        st.subheader("üì• **Downloads de Dados**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üìä Datasets Principais:**")
            
            # Lista de datasets para download
            datasets_download = [
                ('casos_consolidados', 'Casos Consolidados (2017-2024)'),
                ('sorogrupos_consolidados', 'Sorogrupos Consolidados (2007-2024)'),
                ('etiologias_consolidadas', 'Etiologias Consolidadas (2007-2024)'),
                ('imunizacao_ano', 'Imuniza√ß√£o por Ano (1994-2022)'),
                ('imunizacao_uf', 'Imuniza√ß√£o por UF'),
                ('imunizacao_faixa_etaria', 'Imuniza√ß√£o por Faixa Et√°ria')
            ]
            
            for key, nome in datasets_download:
                if key in dados and isinstance(dados[key], pd.DataFrame):
                    csv_data = dados[key].to_csv(index=False)
                    st.download_button(
                        label=f"üì• {nome}",
                        data=csv_data,
                        file_name=f"{key}.csv",
                        mime="text/csv"
                    )
        
        with col2:
            st.write("**üî¨ An√°lises Especializadas:**")
            
            # An√°lises especializadas
            if 'analise_regional' in dados:
                csv_regional = dados['analise_regional'].to_csv(index=False)
                st.download_button(
                    label="üì• An√°lise Regional",
                    data=csv_regional,
                    file_name="analise_regional.csv",
                    mime="text/csv"
                )
            
            if 'matriz_correlacao' in dados:
                csv_correlacao = dados['matriz_correlacao'].to_csv(index=False)
                st.download_button(
                    label="üì• Matriz de Correla√ß√£o",
                    data=csv_correlacao,
                    file_name="matriz_correlacao.csv",
                    mime="text/csv"
                )
            
            if 'analise_temporal' in dados:
                csv_temporal = dados['analise_temporal'].to_csv(index=False)
                st.download_button(
                    label="üì• An√°lise Temporal",
                    data=csv_temporal,
                    file_name="analise_temporal.csv",
                    mime="text/csv"
                )
        
        # Relat√≥rio personalizado
        st.subheader("‚úèÔ∏è **Relat√≥rio Personalizado**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Sele√ß√£o de datasets para o relat√≥rio
            datasets_relatorio = st.multiselect(
                "Selecione datasets para incluir no relat√≥rio:",
                list(dados.keys()),
                default=list(dados.keys())[:5]
            )
            
            # Tipo de relat√≥rio
            tipo_relatorio = st.selectbox(
                "Tipo de relat√≥rio:",
                ["Resumo Executivo", "Relat√≥rio Detalhado", "Relat√≥rio T√©cnico"]
            )
        
        with col2:
            # Per√≠odo do relat√≥rio
            ano_inicio = st.number_input("Ano de in√≠cio:", min_value=1990, max_value=2024, value=2017)
            ano_fim = st.number_input("Ano de fim:", min_value=1990, max_value=2024, value=2024)
            
            # Incluir gr√°ficos
            incluir_graficos = st.checkbox("Incluir gr√°ficos (HTML)", value=True)
        
        # Gerar relat√≥rio personalizado
        if st.button("üìã Gerar Relat√≥rio Personalizado"):
            with st.spinner("Gerando relat√≥rio personalizado..."):
                try:
                    # Criar relat√≥rio personalizado
                    relatorio_personalizado = f"""
                    # RELAT√ìRIO PERSONALIZADO DE MENINGITE BRASIL
                    
                    ## Informa√ß√µes Gerais
                    - **Tipo:** {tipo_relatorio}
                    - **Per√≠odo:** {ano_inicio}-{ano_fim}
                    - **Datasets inclu√≠dos:** {len(datasets_relatorio)}
                    - **Data de gera√ß√£o:** {datetime.now().strftime('%d/%m/%Y %H:%M')}
                    
                    ## Datasets Analisados
                    """
                    
                    for dataset in datasets_relatorio:
                        if dataset in dados and isinstance(dados[dataset], pd.DataFrame):
                            df = dados[dataset]
                            relatorio_personalizado += f"""
                            
                            ### {dataset.replace('_', ' ').title()}
                            - **Forma:** {df.shape[0]} linhas √ó {df.shape[1]} colunas
                            - **Colunas:** {', '.join(df.columns.tolist())}
                            - **Per√≠odo:** {df.select_dtypes(include=[np.number]).min().min() if df.select_dtypes(include=[np.number]).shape[1] > 0 else 'N/A'} - {df.select_dtypes(include=[np.number]).max().max() if df.select_dtypes(include=[np.number]).shape[1] > 0 else 'N/A'}
                            """
                    
                    # Adicionar resumo estat√≠stico
                    relatorio_personalizado += """
                    
                    ## Resumo Estat√≠stico
                    """
                    
                    for dataset in datasets_relatorio:
                        if dataset in dados and isinstance(dados[dataset], pd.DataFrame):
                            df = dados[dataset]
                            colunas_numericas = df.select_dtypes(include=[np.number]).columns
                            if len(colunas_numericas) > 0:
                                relatorio_personalizado += f"""
                                
                                ### {dataset.replace('_', ' ').title()}
                                """
                                for col in colunas_numericas[:5]:  # Limitar a 5 colunas
                                    stats = df[col].describe()
                                    relatorio_personalizado += f"""
                                    **{col}:**
                                    - M√©dia: {stats['mean']:.2f}
                                    - Mediana: {stats['50%']:.2f}
                                    - Desvio padr√£o: {stats['std']:.2f}
                                    - M√≠nimo: {stats['min']:.2f}
                                    - M√°ximo: {stats['max']:.2f}
                                    """
                    
                    # Download do relat√≥rio
                    st.download_button(
                        label="üì• Download Relat√≥rio Personalizado (MD)",
                        data=relatorio_personalizado,
                        file_name=f"relatorio_personalizado_{ano_inicio}_{ano_fim}.md",
                        mime="text/markdown"
                    )
                    
                    st.success("‚úÖ Relat√≥rio personalizado gerado com sucesso!")
                    
                except Exception as e:
                    st.error(f"‚ùå Erro ao gerar relat√≥rio: {e}")
        
        # Resumo dos relat√≥rios
        st.markdown("---")
        st.markdown("""
        **üìã Funcionalidades de Relat√≥rios:**
        
        **1. Relat√≥rios Autom√°ticos:**
        - Relat√≥rio de casos (2017-2022)
        - Relat√≥rio de imuniza√ß√£o (1994-2022)
        - Relat√≥rio de sorogrupos (2007-2024)
        
        **2. Downloads de Dados:**
        - Datasets principais em CSV
        - An√°lises especializadas
        - Dados processados
        
        **3. Relat√≥rios Personalizados:**
        - Sele√ß√£o de datasets
        - Per√≠odo personalizado
        - Tipo de relat√≥rio configur√°vel
        - Inclus√£o de gr√°ficos
        
        **4. Formatos Dispon√≠veis:**
        - Markdown (.md)
        - CSV (.csv)
        - HTML (gr√°ficos interativos)
        """)
        
    else:
        st.error("‚ùå Nenhum dado dispon√≠vel para relat√≥rios")

def show_technical_exposition(dados):
    """Exibe a se√ß√£o "Expositivo T√©cnico - Arquitetura e Metodologia".

    Esta fun√ß√£o renderiza uma p√°gina detalhada que serve como documenta√ß√£o t√©cnica
    do sistema. Ela descreve a arquitetura de dados, o fluxo de automa√ß√£o, a
    estrutura das tabelas, as metodologias estat√≠sticas e de machine learning
    implementadas, as tecnologias de visualiza√ß√£o, e as estrat√©gias de otimiza√ß√£o.
    Tamb√©m apresenta estat√≠sticas ao vivo sobre os dados carregados.

    Args:
        dados (dict): O dicion√°rio global de dados, usado para exibir estat√≠sticas
                      em tempo real sobre os datasets carregados.
    """
    st.header("‚öôÔ∏è **Expositivo T√©cnico - Arquitetura e Metodologia**")
    st.markdown("---")
    
    # Introdu√ß√£o
    st.markdown("""
    ## üéØ **Vis√£o Geral do Sistema**
    
    Este dashboard representa um sistema completo de an√°lise epidemiol√≥gica de meningite no Brasil, 
    integrando coleta automatizada de dados, processamento estat√≠stico avan√ßado e visualiza√ß√£o interativa.
    """)
    
    # Se√ß√£o 1: Arquitetura de Dados
    st.header("üèóÔ∏è **1. Arquitetura de Dados e Automa√ß√£o**")
    
    # Diagrama de fluxo de dados
    st.subheader("üìä **Fluxo de Dados do Sistema**")
    
    # Criar diagrama Mermaid do fluxo de dados
    diagram_code = """
    graph TD
        A[APIs Oficiais<br/>DataSUS, SIPNI, SIH] --> B[Sistema de Automa√ß√£o<br/>Web Scraping + APIs]
        B --> C[Extra√ß√£o Automatizada<br/>Python + Requests]
        C --> D[Valida√ß√£o e Limpeza<br/>Pandas + NumPy]
        D --> E[Armazenamento<br/>Pasta TABELAS/*.csv]
        E --> F[Carregamento no Dashboard<br/>load_all_data()]
        F --> G[Processamento Estat√≠stico<br/>SciPy + Scikit-learn]
        G --> H[Visualiza√ß√£o Interativa<br/>Plotly + Streamlit]
        H --> I[Dashboard Final<br/>An√°lises Epidemiol√≥gicas]
        
        style A fill:#e1f5fe
        style E fill:#f3e5f5
        style G fill:#e8f5e8
        style I fill:#fff3e0
    """
    
    st.markdown("#### üîÑ **Diagrama de Fluxo de Dados:**")
    
    # Mostrar diagrama de fluxo como c√≥digo
    st.code(diagram_code, language='mermaid')
    
    # Explica√ß√£o detalhada da automa√ß√£o
    st.markdown("""
    ### ü§ñ **Sistema de Automa√ß√£o de Dados**
    
    #### üì° **Fontes de Dados Oficiais:**
    - **DataSUS (DATASUS):** Sistema de Informa√ß√µes em Sa√∫de
    - **SIPNI:** Sistema de Informa√ß√µes do Programa Nacional de Imuniza√ß√µes  
    - **SIH:** Sistema de Informa√ß√µes Hospitalares
    - **SINAN:** Sistema de Informa√ß√£o de Agravos de Notifica√ß√£o
    
    #### üîß **Tecnologias de Automa√ß√£o Utilizadas:**
    
    **Python Libraries:**
    - `requests`: Requisi√ß√µes HTTP para APIs
    - `beautifulsoup4`: Web scraping de p√°ginas HTML
    - `selenium`: Automa√ß√£o de navegadores web
    - `pandas`: Manipula√ß√£o e an√°lise de dados
    - `numpy`: Computa√ß√£o num√©rica
    
    **Processo Automatizado:**
    1. **Monitoramento**: Scripts verificam atualiza√ß√µes nas fontes
    2. **Extra√ß√£o**: Dados s√£o coletados via APIs e web scraping
    3. **Valida√ß√£o**: Verifica√ß√£o de integridade e consist√™ncia
    4. **Limpeza**: Remo√ß√£o de duplicatas e tratamento de missing values
    5. **Padroniza√ß√£o**: Formata√ß√£o uniforme das tabelas
    6. **Armazenamento**: Salvamento em formato CSV na pasta TABELAS/
    """)
    
    # Se√ß√£o 2: Estrutura das Tabelas
    st.header("üìã **2. Estrutura e Utiliza√ß√£o das Tabelas**")
    
    # Categorizar as tabelas por tipo
    st.subheader("üóÇÔ∏è **Categoriza√ß√£o das Tabelas de Dados**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### üìä **Dados Epidemiol√≥gicos:**
        - `casos_consolidados_2017_2024.csv`: Casos notificados agregados
        - `casos_notificados_2017_2022.csv`: Dados brutos de notifica√ß√£o
        - `dados_gerais_2024.csv`: Estat√≠sticas gerais do ano atual
        - `data_meninatu.csv`: Dados espec√≠ficos de meningite tuberculosa
        - `tabela_unificada.csv`: Base consolidada principal
        
        #### ü¶† **Dados por Sorogrupo:**
        - `sorogrupos_2024.csv`: Sorogrupos do ano atual
        - `sorogrupos_consolidados_2007_2024.csv`: S√©rie hist√≥rica
        - `df_sorogrupos_2007_2020.csv`: Dados hist√≥ricos espec√≠ficos
        - `df_sorogrupos_2024.csv`: Dados processados 2024
        - `df_sorogrupos_completo.csv`: Base completa consolidada
        """)
    
    with col2:
        st.markdown("""
        #### üî¨ **Dados de Etiologia:**
        - `etiologia_2024.csv`: Etiologias identificadas
        - `etiologias_consolidadas_2007_2024.csv`: S√©rie temporal
        - `df_etiologia_2024.csv`: Dados processados
        - `bacterianas_2024.csv`: Meningites bacterianas
        - `df_bacterianas_2024.csv`: Dados bacterianos processados
        
        #### üíâ **Dados de Imuniza√ß√£o:**
        - `imunizacoesmenin.csv`: Dados brutos de vacina√ß√£o
        - `cleaned_imunizacoesmenin.csv`: Dados limpos
        - `imunizacoesmenin_fixed.csv`: Dados corrigidos
        - `dados_imunizacao_processados.csv`: Base processada
        - `imunobiologicosem2023a2025.csv`: Imunobiol√≥gicos per√≠odo
        """)
    
    # An√°lise espec√≠fica por tipo
    st.subheader("üîç **An√°lise Espec√≠fica por Categoria**")
    
    # Dados de hospitaliza√ß√£o
    st.markdown("""
    #### üè• **Dados Hospitalares (SIH):**
    - `sih_meningite_hospitalar.csv`: Interna√ß√µes por meningite
    - `sih_meningite_long.csv`: Formato longo para an√°lises temporais
    - `sih_meningite_wide.csv`: Formato largo para an√°lises transversais
    
    **Tratamentos Aplicados:**
    - Convers√£o entre formatos long/wide para diferentes an√°lises
    - C√°lculo de taxas de hospitaliza√ß√£o
    - An√°lise de sazonalidade nas interna√ß√µes
    - Correla√ß√£o com dados de notifica√ß√£o
    """)
    
    # Dados de letalidade
    st.markdown("""
    #### ‚ö∞Ô∏è **Dados de Letalidade:**
    - `df_letalidade_2007_2020.csv`: Taxas de letalidade hist√≥ricas
    - `letalidade_etiologia_2007_2020.csv`: Letalidade por etiologia
    
    **Tratamentos Aplicados:**
    - C√°lculo de taxas de letalidade: (√ìbitos/Casos) √ó 100
    - Estratifica√ß√£o por etiologia e sorogrupo
    - An√°lise temporal da letalidade
    - Identifica√ß√£o de fatores de risco
    """)
    
    # Dados de imuniza√ß√£o detalhados
    st.markdown("""
    #### üíâ **Dados de Imuniza√ß√£o Estratificados:**
    - `imunizacao_por_ano.csv`: Evolu√ß√£o anual da cobertura
    - `imunizacao_por_faixa_etaria.csv`: Cobertura por idade
    - `imunizacao_por_sorogrupo.csv`: Vacina√ß√£o espec√≠fica
    - `imunizacao_por_uf.csv`: Distribui√ß√£o geogr√°fica
    - `doses_todosimunosate2022.csv`: Doses aplicadas por regi√£o
    
    **Tratamentos Aplicados:**
    - Padroniza√ß√£o de faixas et√°rias
    - C√°lculo de coberturas vacinais
    - An√°lise de disparidades regionais
    - Correla√ß√£o cobertura √ó incid√™ncia
    """)
    
    # Se√ß√£o 3: Metodologias Estat√≠sticas
    st.header("üìà **3. Metodologias Estat√≠sticas Implementadas**")
    
    st.subheader("üî¢ **Estat√≠stica Descritiva**")
    st.markdown("""
    #### üìä **Medidas de Tend√™ncia Central e Dispers√£o:**
    - **M√©dia, Mediana, Moda**: Tend√™ncias centrais dos dados
    - **Desvio Padr√£o, Vari√¢ncia**: Medidas de dispers√£o
    - **Quartis e Percentis**: Distribui√ß√£o dos dados
    - **Coeficiente de Varia√ß√£o**: Variabilidade relativa
    
    **Implementa√ß√£o:**
    ```python
    # Exemplo de c√°lculo de estat√≠sticas descritivas
    stats_descritivas = dados.describe()
    cv = dados.std() / dados.mean() * 100  # Coeficiente de Varia√ß√£o
    ```
    """)
    
    st.subheader("üìâ **An√°lise de Correla√ß√£o**")
    st.markdown("""
    #### üîó **Tipos de Correla√ß√£o Implementados:**
    
    **1. Correla√ß√£o de Pearson:**
    - Mede rela√ß√µes lineares entre vari√°veis
    - Usado para: casos vs letalidade, cobertura vs incid√™ncia
    - Formula: r = Œ£((x-xÃÑ)(y-»≥)) / ‚àö(Œ£(x-xÃÑ)¬≤Œ£(y-»≥)¬≤)
    
    **2. Correla√ß√£o de Spearman:**
    - Mede rela√ß√µes monot√¥nicas (n√£o necessariamente lineares)
    - Robusto a outliers
    - Baseado em rankings dos dados
    
    **3. Correla√ß√£o Cruzada:**
    - An√°lise entre m√∫ltiplas vari√°veis simultaneamente
    - Identifica padr√µes complexos entre sorogrupos
    
    **Implementa√ß√£o:**
    ```python
    from scipy.stats import pearsonr, spearmanr
    
    # Correla√ß√£o de Pearson
    corr_pearson, p_pearson = pearsonr(x, y)
    
    # Correla√ß√£o de Spearman  
    corr_spearman, p_spearman = spearmanr(x, y)
    ```
    """)
    
    st.subheader("üìä **An√°lise de Regress√£o**")
    st.markdown("""
    #### üìà **Modelos de Regress√£o Utilizados:**
    
    **1. Regress√£o Linear Simples:**
    - Modelo: Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ
    - Usado para: tend√™ncias temporais, rela√ß√µes bivariadas
    - M√©tricas: R¬≤, RMSE, p-valor
    
    **2. Regress√£o Linear M√∫ltipla:**
    - Modelo: Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤‚ÇôX‚Çô + Œµ
    - Usado para: an√°lise multivariada de fatores
    - Valida√ß√£o: Time Series Split para dados temporais
    
    **3. Regress√£o Polinomial:**
    - Captura rela√ß√µes n√£o-lineares
    - Usado para: rela√ß√µes complexas entre vari√°veis
    
    **Implementa√ß√£o:**
    ```python
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.metrics import r2_score, mean_squared_error
    
    # Modelo de regress√£o
    modelo = LinearRegression()
    modelo.fit(X_train, y_train)
    
    # M√©tricas de avalia√ß√£o
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    ```
    """)
    
    st.subheader("‚è±Ô∏è **An√°lise de S√©ries Temporais**")
    st.markdown("""
    #### üìÖ **T√©cnicas de S√©ries Temporais:**
    
    **1. Decomposi√ß√£o STL (Seasonal and Trend decomposition using Loess):**
    - Separa s√©rie em: Tend√™ncia + Sazonalidade + Res√≠duos
    - Mais robusta que decomposi√ß√£o cl√°ssica
    - Permite an√°lise de componentes individuais
    
    **2. Teste de Estacionariedade (ADF):**
    - Augmented Dickey-Fuller Test
    - Verifica se a s√©rie √© estacion√°ria
    - Fundamental para modelagem ARIMA
    
    **3. An√°lise de Autocorrela√ß√£o:**
    - Identifica padr√µes de depend√™ncia temporal
    - Usado para detectar sazonalidade
    
    **Implementa√ß√£o:**
    ```python
    from statsmodels.tsa.seasonal import STL
    from statsmodels.tsa.stattools import adfuller
    
    # Decomposi√ß√£o STL
    stl = STL(serie_temporal, period=12)
    resultado = stl.fit()
    
    # Teste ADF
    adf_stat, p_value = adfuller(serie_temporal)[:2]
    ```
    """)
    
    st.subheader("ü§ñ **Machine Learning e Clustering**")
    st.markdown("""
    #### üî¨ **Algoritmos de Machine Learning:**
    
    **1. K-Means Clustering:**
    - Agrupa sorogrupos por caracter√≠sticas similares
    - Identifica padr√µes epidemiol√≥gicos
    - Usado para: segmenta√ß√£o de sorogrupos
    
    **2. Clustering Hier√°rquico:**
    - Cria dendrograma de relacionamentos
    - M√©todo Ward para minimizar vari√¢ncia
    - Complementa an√°lise K-Means
    
    **3. PCA (Principal Component Analysis):**
    - Redu√ß√£o dimensional preservando vari√¢ncia
    - Identifica componentes principais
    - Usado para: visualiza√ß√£o de dados multidimensionais
    
    **Implementa√ß√£o:**
    ```python
    from sklearn.cluster import KMeans
    from sklearn.decomposition import PCA
    from scipy.cluster.hierarchy import dendrogram, linkage
    
    # K-Means
    kmeans = KMeans(n_clusters=3, random_state=42)
    clusters = kmeans.fit_predict(dados_scaled)
    
    # PCA
    pca = PCA(n_components=2)
    dados_pca = pca.fit_transform(dados_scaled)
    ```
    """)
    
    # Se√ß√£o 4: Processo de Visualiza√ß√£o
    st.header("üé® **4. Processo de Visualiza√ß√£o e Interface**")
    
    st.subheader("üìä **Biblioteca Plotly - Gr√°ficos Interativos**")
    st.markdown("""
    #### üéØ **Tipos de Gr√°ficos Implementados:**
    
    **1. Gr√°ficos de Linha (Time Series):**
    - Evolu√ß√£o temporal de casos
    - Tend√™ncias de vacina√ß√£o
    - An√°lise de sazonalidade
    
    **2. Gr√°ficos de Dispers√£o (Scatter):**
    - Correla√ß√µes entre vari√°veis
    - Regress√µes lineares e polinomiais
    - An√°lise multivariada
    
    **3. Gr√°ficos de Barras:**
    - Distribui√ß√µes por categoria
    - Compara√ß√µes regionais
    - Rankings de incid√™ncia
    
    **4. Heatmaps:**
    - Matrizes de correla√ß√£o
    - Distribui√ß√£o geogr√°fica
    - Padr√µes sazonais
    
    **5. Gr√°ficos de Subplots:**
    - Decomposi√ß√£o de s√©ries temporais
    - An√°lises comparativas
    - Diagn√≥sticos de modelos
    """)
    
    st.subheader("üñ•Ô∏è **Streamlit - Framework de Interface**")
    st.markdown("""
    #### ‚öôÔ∏è **Componentes de Interface Utilizados:**
    
    **Navega√ß√£o:**
    - `st.sidebar.selectbox()`: Menu principal de navega√ß√£o
    - `st.tabs()`: Abas dentro de se√ß√µes
    - `st.columns()`: Layout responsivo em colunas
    
    **Visualiza√ß√£o:**
    - `st.plotly_chart()`: Gr√°ficos interativos
    - `st.dataframe()`: Tabelas interativas
    - `st.metric()`: KPIs e m√©tricas principais
    
    **Interatividade:**
    - `st.selectbox()`: Sele√ß√£o de par√¢metros
    - `st.slider()`: Controles num√©ricos
    - `st.checkbox()`: Filtros booleanos
    
    **Formata√ß√£o:**
    - `st.markdown()`: Texto formatado e explica√ß√µes
    - `st.latex()`: F√≥rmulas matem√°ticas
    - `st.code()`: C√≥digo de exemplo
    """)
    
    # Se√ß√£o 5: Performance e Otimiza√ß√£o
    st.header("‚ö° **5. Performance e Otimiza√ß√£o**")
    
    st.markdown("""
    #### üöÄ **Estrat√©gias de Otimiza√ß√£o Implementadas:**
    
    **1. Cache de Dados:**
    ```python
    @st.cache_data
    def load_all_data():
        # Carregamento otimizado com cache
        return dados_processados
    ```
    
    **2. Processamento Eficiente:**
    - Uso de `pandas.groupby()` para agrega√ß√µes
    - Vetoriza√ß√£o com `numpy` para c√°lculos
    - Lazy loading de dados n√£o utilizados
    
    **3. Gest√£o de Mem√≥ria:**
    - Limpeza de DataFrames tempor√°rios
    - Uso de `dtype` apropriados
    - Garbage collection autom√°tico
    
    **4. Tratamento de Erros:**
    - Try-catch para imports condicionais
    - Valida√ß√£o de dados de entrada
    - Fallbacks para funcionalidades avan√ßadas
    """)
    
    # Se√ß√£o 6: M√©tricas Epidemiol√≥gicas
    st.header("üè• **6. M√©tricas Epidemiol√≥gicas Calculadas**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### üìä **Incid√™ncia e Preval√™ncia:**
        
        **Taxa de Ataque:**
        ```
        Taxa = (Casos / Popula√ß√£o) √ó 100.000
        ```
        
        **For√ßa de Infec√ß√£o:**
        ```
        Œª = -ln(1 - taxa_ataque)
        ```
        
        **Taxa de Letalidade:**
        ```
        Letalidade = (√ìbitos / Casos) √ó 100
        ```
        """)
    
    with col2:
        st.markdown("""
        #### üíâ **Cobertura Vacinal:**
        
        **Cobertura por Dose:**
        ```
        Cobertura = (Doses / Pop_Alvo) √ó 100
        ```
        
        **Efetividade Vacinal:**
        ```
        EV = 1 - (Taxa_Vacinados / Taxa_N√£o_Vacinados)
        ```
        
        **Imunidade Coletiva:**
        ```
        Limiar = 1 - (1/R‚ÇÄ)
        ```
        """)
    
    # Se√ß√£o 7: Valida√ß√£o e Qualidade
    st.header("‚úÖ **7. Valida√ß√£o e Controle de Qualidade**")
    
    st.markdown("""
    #### üîç **Processos de Valida√ß√£o Implementados:**
    
    **1. Valida√ß√£o de Dados:**
    - Verifica√ß√£o de tipos de dados (dtype validation)
    - Detec√ß√£o de valores missing e outliers
    - Consist√™ncia temporal (datas v√°lidas)
    - Integridade referencial entre tabelas
    
    **2. Valida√ß√£o Estat√≠stica:**
    - Teste de normalidade (Shapiro-Wilk)
    - Detec√ß√£o de multicolinearidade (VIF)
    - Valida√ß√£o cruzada para modelos
    - An√°lise de res√≠duos
    
    **3. Valida√ß√£o Epidemiol√≥gica:**
    - Coer√™ncia de taxas calculadas
    - Compara√ß√£o com literatura cient√≠fica
    - Valida√ß√£o de tend√™ncias esperadas
    - Verifica√ß√£o de sazonalidade conhecida
    
    **4. Monitoramento Cont√≠nuo:**
    - Logs de processamento de dados
    - Alertas para anomalias detectadas
    - Versionamento de dados
    - Backup automatizado
    """)
    
    # Se√ß√£o 8: Considera√ß√µes T√©cnicas
    st.header("‚ö†Ô∏è **8. Limita√ß√µes e Considera√ß√µes T√©cnicas**")
    
    st.markdown("""
    #### üöß **Limita√ß√µes Conhecidas:**
    
    **1. Dados:**
    - Depend√™ncia da qualidade dos dados oficiais
    - Poss√≠vel subnotifica√ß√£o em algumas regi√µes
    - Atraso na disponibiliza√ß√£o de dados recentes
    - Mudan√ßas metodol√≥gicas nas fontes
    
    **2. Estat√≠sticas:**
    - Modelos assumem distribui√ß√µes espec√≠ficas
    - Correla√ß√£o n√£o implica causalidade
    - S√©ries temporais curtas limitam an√°lises
    - Poss√≠vel autocorrela√ß√£o residual
    
    **3. T√©cnicas:**
    - Alguns pacotes podem ter incompatibilidades
    - An√°lises avan√ßadas requerem dados suficientes
    - Clustering √© sens√≠vel √† escala dos dados
    - PCA pode perder interpretabilidade
    
    **4. Performance:**
    - Processamento intensivo para grandes datasets
    - Limita√ß√µes de mem√≥ria para an√°lises complexas
    - Tempo de carregamento para primeira execu√ß√£o
    - Depend√™ncia de conex√£o para dados atualizados
    """)
    
    # Se√ß√£o 9: Estat√≠sticas dos Dados Atuais
    st.header("üìä **9. Estat√≠sticas dos Dados Atualmente Carregados**")
    
    if dados:
        st.subheader("üìà **Resumo dos Datasets Dispon√≠veis**")
        
        # Criar tabela com informa√ß√µes dos datasets
        datasets_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame):
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': f"{value.shape[0]:,}",
                    'Colunas': value.shape[1],
                    'Mem√≥ria (MB)': f"{value.memory_usage(deep=True).sum() / 1024**2:.2f}",
                    'Per√≠odo': 'Vari√°vel',
                    'Tipo': 'DataFrame'
                })
            else:
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': '-',
                    'Colunas': '-',
                    'Mem√≥ria (MB)': '-',
                    'Per√≠odo': '-',
                    'Tipo': type(value).__name__
                })
        
        df_info = pd.DataFrame(datasets_info)
        st.dataframe(df_info, use_container_width=True)
        
        # Estat√≠sticas gerais
        total_linhas = sum([v.shape[0] for v in dados.values() if isinstance(v, pd.DataFrame)])
        total_memoria = sum([v.memory_usage(deep=True).sum() for v in dados.values() if isinstance(v, pd.DataFrame)])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total de Datasets", len(dados))
        with col2:
            st.metric("üìù Total de Registros", f"{total_linhas:,}")
        with col3:
            st.metric("üíæ Mem√≥ria Total", f"{total_memoria/1024**2:.1f} MB")
        with col4:
            st.metric("üóÇÔ∏è Tabelas CSV", len([f for f in os.listdir('TABELAS') if f.endswith('.csv')]))
        
        # An√°lise de qualidade dos dados
        st.subheader("üîç **An√°lise de Qualidade dos Dados**")
        
        qualidade_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame) and not value.empty:
                missing_percent = (value.isnull().sum().sum() / (value.shape[0] * value.shape[1])) * 100
                duplicatas = value.duplicated().sum()
                
                qualidade_info.append({
                    'Dataset': key,
                    'Missing Values (%)': f"{missing_percent:.2f}%",
                    'Duplicatas': duplicatas,
                    'Completude': f"{100-missing_percent:.1f}%",
                    'Status': "‚úÖ Boa" if missing_percent < 5 and duplicatas < 10 else "‚ö†Ô∏è Aten√ß√£o" if missing_percent < 15 else "‚ùå Cr√≠tica"
                })
        
        if qualidade_info:
            df_qualidade = pd.DataFrame(qualidade_info)
            st.dataframe(df_qualidade, use_container_width=True)
    
    else:
        st.warning("‚ö†Ô∏è Nenhum dado carregado para an√°lise")
    
    # Footer t√©cnico
    st.markdown("---")
    st.markdown("""
    ### üéØ **Conclus√£o T√©cnica**
    
    Este sistema representa uma implementa√ß√£o completa de an√°lise epidemiol√≥gica moderna, integrando:
    - **Automa√ß√£o de dados** com tecnologias Python
    - **An√°lises estat√≠sticas robustas** com m√∫ltiplas metodologias
    - **Visualiza√ß√£o interativa** para explora√ß√£o de dados
    - **Interface intuitiva** para diferentes perfis de usu√°rios
    - **Valida√ß√£o rigorosa** para garantir qualidade cient√≠fica
    
    **Tecnologias Principais:** Python, Pandas, NumPy, SciPy, Scikit-learn, Plotly, Streamlit, Statsmodels
    
    **Padr√µes Seguidos:** PEP 8, Documenta√ß√£o docstring, Type hints, Git workflow, Code review
    """)


def main():
    """Fun√ß√£o principal que executa a aplica√ß√£o Streamlit.

    Esta fun√ß√£o inicializa a p√°gina do dashboard, configura a barra lateral de navega√ß√£o,
    chama a fun√ß√£o `load_all_data()` para carregar todos os dados, e gerencia a
    exibi√ß√£o da se√ß√£o selecionada pelo usu√°rio. Se o carregamento de dados falhar,
    exibe uma mensagem de erro com instru√ß√µes.
    """
    st.title("ü¶† **Dashboard Completo de Meningite Brasil**")
    st.markdown("---")
    
    # Sidebar para navega√ß√£o
    st.sidebar.title("üß≠ **Navega√ß√£o**")
    
    # Carregar dados
    dados = load_all_data()
    
    if dados:
        # Menu de navega√ß√£o
        opcao = st.sidebar.selectbox(
            "Escolha uma se√ß√£o:",
            [
                "üè† Vis√£o Geral 2024",
                "üìä An√°lise de Casos",
                "ü¶† An√°lise de Sorogrupos",
                "üî¨ An√°lise de Etiologia",
                "üíâ An√°lise de Imuniza√ß√£o",
                "üó∫Ô∏è An√°lise Regional",
                "üî¨ An√°lises Avan√ßadas",
                "ü¶† An√°lise Epidemiol√≥gica",
                "‚ö° Taxa de Ataque",
                "üîç Explora√ß√£o Livre",
                "üìã Relat√≥rios",
                "‚öôÔ∏è Expositivo T√©cnico"
            ]
        )
        
        # Navega√ß√£o para as se√ß√µes
        if opcao == "üè† Vis√£o Geral 2024":
            show_overview_2024(dados)
        elif opcao == "üìä An√°lise de Casos":
            show_cases_analysis(dados)
        elif opcao == "ü¶† An√°lise de Sorogrupos":
            show_sorogrupos_analysis(dados)
        elif opcao == "üî¨ An√°lise de Etiologia":
            show_etiologia_analysis(dados)
        elif opcao == "üíâ An√°lise de Imuniza√ß√£o":
            show_imunizacao_analysis(dados)
        elif opcao == "üó∫Ô∏è An√°lise Regional":
            show_regional_analysis(dados)
        elif opcao == "üî¨ An√°lises Avan√ßadas":
            show_advanced_analysis(dados)
        elif opcao == "ü¶† An√°lise Epidemiol√≥gica":
            show_epidemiological_analysis(dados)
        elif opcao == "‚ö° Taxa de Ataque":
            show_attack_rate_analysis(dados)
        elif opcao == "üîç Explora√ß√£o Livre":
            show_free_exploration(dados)
        elif opcao == "üìã Relat√≥rios":
            show_reports(dados)
        elif opcao == "‚öôÔ∏è Expositivo T√©cnico":
            show_technical_exposition(dados)
        
        # Informa√ß√µes adicionais na sidebar
        st.sidebar.markdown("---")
        st.sidebar.markdown("**üìä Dados Dispon√≠veis:**")
        
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame):
                st.sidebar.write(f"‚úÖ {key}: {value.shape[0]} linhas")
            else:
                st.sidebar.write(f"‚úÖ {key}")
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("**üîß Desenvolvido com:**")
        st.sidebar.markdown("- Streamlit")
        st.sidebar.markdown("- Plotly")
        st.sidebar.markdown("- Pandas")
        st.sidebar.markdown("- NumPy")
        st.sidebar.markdown("- SciPy")
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("**üìÖ √öltima atualiza√ß√£o:**")
        st.sidebar.markdown(f"{datetime.now().strftime('%d/%m/%Y %H:%M')}")
        
    else:
        st.error("‚ùå Erro ao carregar dados. Verifique se os arquivos est√£o dispon√≠veis na pasta TABELAS/")
        st.info("üí° Certifique-se de que os seguintes arquivos existem:")
        st.write("- casos_consolidados_2017_2024.csv")
        st.write("- sorogrupos_consolidados_2007_2024.csv")
        st.write("- etiologias_consolidadas_2007_2024.csv")
        st.write("- imunizacao_por_ano.csv")
        st.write("- imunizacao_por_uf.csv")
        st.write("- imunizacao_por_faixa_etaria.csv")
        st.write("- imunizacao_por_sorogrupo.csv")
        st.write("- imunobiologicosem2023a2025.csv")
        st.write("- letalidade_etiologia_2007_2020.csv")
        st.write("- casos_notificados_2017_2022.csv")
        st.write("- dados_gerais_2024.csv")
        st.write("- bacterianas_2024.csv")
        st.write("- etiologia_2024.csv")
        st.write("- sorogrupos_2024.csv")
        st.write("- sih_meningite_long.csv")

if __name__ == "__main__":
    main()
