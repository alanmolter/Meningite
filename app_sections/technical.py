import streamlit as st
import pandas as pd
import os
import plotly.graph_objects as go
import plotly.express as px

# Import graphviz com tratamento de erro
try:
    import graphviz
    GRAPHVIZ_AVAILABLE = True
except ImportError:
    GRAPHVIZ_AVAILABLE = False


def create_advanced_flow_diagram():
    """Cria diagrama de fluxo avan√ßado e complexo usando Plotly"""
    
    # Definir estrutura hier√°rquica complexa
    layers = {
        # Camada 1: Fontes de Dados (Topo)
        'sources': {
            'DataSUS': {'x': 1, 'y': 10, 'color': '#1565C0', 'icon': 'üè•', 'size': 70},
            'SIPNI': {'x': 3, 'y': 10, 'color': '#2E7D32', 'icon': 'üíâ', 'size': 70},
            'SIH': {'x': 5, 'y': 10, 'color': '#C62828', 'icon': 'üè®', 'size': 70},
            'SINAN': {'x': 7, 'y': 10, 'color': '#F57C00', 'icon': 'üìä', 'size': 70},
        },
        # Camada 2: Automa√ß√£o (N√≠vel 2)
        'automation': {
            'Web Scraping': {'x': 2, 'y': 8.5, 'color': '#4527A0', 'icon': 'üï∑Ô∏è', 'size': 60},
            'API Requests': {'x': 4, 'y': 8.5, 'color': '#6A1B9A', 'icon': 'üîó', 'size': 60},
            'Data Validation': {'x': 6, 'y': 8.5, 'color': '#AD1457', 'icon': '‚úÖ', 'size': 60},
        },
        # Camada 3: Processamento (N√≠vel 3)
        'processing': {
            'Python Scripts': {'x': 1.5, 'y': 7, 'color': '#00695C', 'icon': 'üêç', 'size': 55},
            'Pandas ETL': {'x': 3.5, 'y': 7, 'color': '#00838F', 'icon': 'üîÑ', 'size': 55},
            'Data Cleaning': {'x': 5.5, 'y': 7, 'color': '#0277BD', 'icon': 'üßπ', 'size': 55},
            'Quality Check': {'x': 7.5, 'y': 7, 'color': '#0288D1', 'icon': 'üîç', 'size': 55},
        },
        # Camada 4: Armazenamento (N√≠vel 4)
        'storage': {
            'CSV Files': {'x': 2, 'y': 5.5, 'color': '#388E3C', 'icon': 'üìÅ', 'size': 70},
            'TABELAS/': {'x': 4, 'y': 5.5, 'color': '#43A047', 'icon': 'üóÇÔ∏è', 'size': 50},
            'Backup System': {'x': 6, 'y': 5.5, 'color': '#4CAF50', 'icon': 'üíæ', 'size': 60},
        },
        # Camada 5: Carregamento (N√≠vel 5)
        'loading': {
            'load_all_data()': {'x': 4, 'y': 4, 'color': '#FF6F00', 'icon': '‚ö°', 'size': 75},
        },
        # Camada 6: An√°lise (N√≠vel 6)
        'analysis': {
            'SciPy': {'x': 1, 'y': 2.5, 'color': '#D32F2F', 'icon': 'üìà', 'size': 50},
            'Scikit-learn': {'x': 2.5, 'y': 2.5, 'color': '#E64A19', 'icon': 'ü§ñ', 'size': 50},
            'Statsmodels': {'x': 4, 'y': 2.5, 'color': '#F57C00', 'icon': 'üìä', 'size': 50},
            'NumPy': {'x': 5.5, 'y': 2.5, 'color': '#FFA000', 'icon': 'üî¢', 'size': 50},
            'Pandas': {'x': 7, 'y': 2.5, 'color': '#FFB300', 'icon': 'üêº', 'size': 50},
        },
        # Camada 7: Visualiza√ß√£o (N√≠vel 7)
        'visualization': {
            'Plotly': {'x': 2, 'y': 1, 'color': '#7B1FA2', 'icon': 'üìä', 'size': 60},
            'Streamlit': {'x': 4, 'y': 1, 'color': '#8E24AA', 'icon': 'üé®', 'size': 60},
            'Interactive Charts': {'x': 6, 'y': 1, 'color': '#9C27B0', 'icon': 'üìà', 'size': 60},
        },
        # Camada 8: Dashboard Final (Base)
        'output': {
            'Dashboard\nEpidemiol√≥gico': {'x': 4, 'y': -0.5, 'color': '#1976D2', 'icon': 'üöÄ', 'size': 90},
        }
    }
    
    # Definir conex√µes complexas entre camadas
    connections = [
        # Sources -> Automation
        ('DataSUS', 'Web Scraping'), ('DataSUS', 'API Requests'),
        ('SIPNI', 'API Requests'), ('SIPNI', 'Data Validation'),
        ('SIH', 'Web Scraping'), ('SIH', 'API Requests'),
        ('SINAN', 'API Requests'), ('SINAN', 'Data Validation'),
        
        # Automation -> Processing
        ('Web Scraping', 'Python Scripts'), ('Web Scraping', 'Pandas ETL'),
        ('API Requests', 'Python Scripts'), ('API Requests', 'Data Cleaning'),
        ('Data Validation', 'Data Cleaning'), ('Data Validation', 'Quality Check'),
        
        # Processing -> Storage
        ('Python Scripts', 'CSV Files'), ('Pandas ETL', 'TABELAS/'),
        ('Data Cleaning', 'TABELAS/'), ('Quality Check', 'Backup System'),
        
        # Storage -> Loading
        ('CSV Files', 'load_all_data()'), ('TABELAS/', 'load_all_data()'),
        ('Backup System', 'load_all_data()'),
        
        # Loading -> Analysis
        ('load_all_data()', 'SciPy'), ('load_all_data()', 'Scikit-learn'),
        ('load_all_data()', 'Statsmodels'), ('load_all_data()', 'NumPy'),
        ('load_all_data()', 'Pandas'),
        
        # Analysis -> Visualization
        ('SciPy', 'Plotly'), ('Scikit-learn', 'Interactive Charts'),
        ('Statsmodels', 'Plotly'), ('NumPy', 'Streamlit'),
        ('Pandas', 'Streamlit'),
        
        # Visualization -> Output
        ('Plotly', 'Dashboard\nEpidemiol√≥gico'), ('Streamlit', 'Dashboard\nEpidemiol√≥gico'),
        ('Interactive Charts', 'Dashboard\nEpidemiol√≥gico'),
    ]
    
    # Criar figura
    fig = go.Figure()
    
    # Adicionar gradiente de fundo
    fig.add_shape(
        type="rect",
        x0=0, y0=-1, x1=8, y1=11,
        fillcolor="rgba(240, 248, 255, 0.3)",
        line=dict(width=0)
    )
    
    # Adicionar camadas de fundo para organiza√ß√£o visual
    layer_backgrounds = [
        {'y0': 9.5, 'y1': 10.5, 'color': 'rgba(33, 150, 243, 0.1)', 'label': 'FONTES DE DADOS'},
        {'y0': 8, 'y1': 9, 'color': 'rgba(156, 39, 176, 0.1)', 'label': 'AUTOMA√á√ÉO'},
        {'y0': 6.5, 'y1': 7.5, 'color': 'rgba(0, 150, 136, 0.1)', 'label': 'PROCESSAMENTO'},
        {'y0': 5, 'y1': 6, 'color': 'rgba(76, 175, 80, 0.1)', 'label': 'ARMAZENAMENTO'},
        {'y0': 3.5, 'y1': 4.5, 'color': 'rgba(255, 111, 0, 0.1)', 'label': 'CARREGAMENTO'},
        {'y0': 2, 'y1': 3, 'color': 'rgba(244, 67, 54, 0.1)', 'label': 'AN√ÅLISE ESTAT√çSTICA'},
        {'y0': 0.5, 'y1': 1.5, 'color': 'rgba(156, 39, 176, 0.1)', 'label': 'VISUALIZA√á√ÉO'},
        {'y0': -1, 'y1': 0, 'color': 'rgba(25, 118, 210, 0.1)', 'label': 'DASHBOARD FINAL'},
    ]
    
    for bg in layer_backgrounds:
        fig.add_shape(
            type="rect",
            x0=0.5, y0=bg['y0'], x1=7.5, y1=bg['y1'],
            fillcolor=bg['color'],
            line=dict(color=bg['color'], width=1),
        )
        # Adicionar r√≥tulo da camada
        fig.add_annotation(
            x=0.2, y=(bg['y0'] + bg['y1'])/2,
            text=bg['label'],
            showarrow=False,
            font=dict(size=10, color='#666'),
            textangle=90,
            xanchor='center',
            yanchor='middle'
        )
    
    # Criar dicion√°rio unificado de todos os n√≥s
    all_nodes = {}
    for layer_nodes in layers.values():
        all_nodes.update(layer_nodes)
    
    # Adicionar conex√µes com diferentes estilos
    for start_name, end_name in connections:
        if start_name in all_nodes and end_name in all_nodes:
            start = all_nodes[start_name]
            end = all_nodes[end_name]
            
            # Estilo da linha baseado na diferen√ßa de camada
            y_diff = abs(start['y'] - end['y'])
            if y_diff > 3:  # Conex√µes de longa dist√¢ncia
                line_style = dict(color='rgba(100, 100, 100, 0.6)', width=2, dash='dot')
            elif y_diff > 1.5:  # Conex√µes m√©dias
                line_style = dict(color='rgba(50, 50, 50, 0.8)', width=3)
            else:  # Conex√µes pr√≥ximas
                line_style = dict(color='rgba(0, 0, 0, 0.9)', width=4)
            
            fig.add_trace(go.Scatter(
                x=[start['x'], end['x']],
                y=[start['y'], end['y']],
                mode='lines',
                line=line_style,
                showlegend=False,
                hoverinfo='none'
            ))
            
            # Adicionar setas mais sofisticadas
            fig.add_annotation(
                x=end['x'],
                y=end['y'],
                ax=start['x'],
                ay=start['y'],
                xref='x', yref='y',
                axref='x', ayref='y',
                arrowhead=3,
                arrowsize=1.2,
                arrowwidth=2,
                arrowcolor='rgba(0, 0, 0, 0.7)',
                showarrow=True,
                text='',
            )
    
    # Adicionar n√≥s com design sofisticado
    for name, props in all_nodes.items():
        # N√≥ principal
        fig.add_trace(go.Scatter(
            x=[props['x']],
            y=[props['y']],
            mode='markers+text',
            marker=dict(
                size=props['size'],
                color=props['color'],
                line=dict(color='rgba(255, 255, 255, 0.8)', width=3),
                opacity=0.9
            ),
            text=f"{props['icon']}<br>{name}",
            textposition='middle center',
            textfont=dict(size=9, color='white', family='Arial Black'),
            showlegend=False,
            hovertemplate=f'<b>{props["icon"]} {name}</b><br>Camada: {props["y"]}<extra></extra>'
        ))
        
        # Adicionar borda destacada para n√≥s importantes
        if props['size'] > 120:
            fig.add_trace(go.Scatter(
                x=[props['x']],
                y=[props['y']],
                mode='markers',
                marker=dict(
                    size=props['size'] + 20,
                    color='rgba(255, 215, 0, 0.3)',
                    line=dict(color='gold', width=2),
                ),
                showlegend=False,
                hoverinfo='none'
            ))
    
    # Configurar layout sofisticado
    fig.update_layout(
        title={
            'text': 'üèóÔ∏è Sistema Epidemiol√≥gico<br><sub>(Atualiza√ß√£o Semanal)</sub>',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 12, 'color': '#1565C0', 'family': 'Arial Black'}
        },
        xaxis=dict(
            showgrid=False,
            showticklabels=False,
            zeroline=False,
            range=[0, 8]
        ),
        yaxis=dict(
            showgrid=False,
            showticklabels=False,
            zeroline=False,
            range=[-1.5, 11]
        ),
        plot_bgcolor='rgba(248, 250, 252, 0.8)',
        paper_bgcolor='white',
        height=320,  # Reduzido drasticamente para 320
        margin=dict(l=20, r=15, t=40, b=20),  # Margens m√≠nimas
        annotations=[
            dict(
                x=4, y=-1.3,
                text='<i>Arquitetura modular com processamento distribu√≠do e an√°lises estat√≠sticas avan√ßadas</i>',
                showarrow=False,
                font=dict(size=10, color='#666'),  # Fonte menor
                xanchor='center'
            )
        ]
    )
    
    # Salvar diagrama Plotly como PNG na raiz do projeto
    try:
        import os
        import plotly.io as pio
        # Obter caminho da raiz do projeto
        current_dir = os.path.dirname(__file__)
        project_root = os.path.dirname(current_dir)
        png_path = os.path.join(project_root, 'diagrama_plotly_sistema_epidemiologico.png')
        
        # Salvar como PNG
        pio.write_image(fig, png_path, width=1200, height=800, scale=2)
        st.success(f"‚úÖ Diagrama Plotly PNG salvo em: {png_path}")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar PNG do Plotly: {e}")
    
    return fig


def create_graphviz_flow_diagram():
    """Cria diagrama usando Graphviz nativo para m√°xima complexidade"""
    
    if not GRAPHVIZ_AVAILABLE:
        return None
    
    try:
        # Criar diagrama Graphviz
        dot = graphviz.Digraph(
            name='sistema_epidemiologico',
            comment='Sistema de An√°lise Epidemiol√≥gica de Meningite - Atualiza√ß√£o Semanal',
            format='png'
        )
        
        # Configura√ß√µes globais do diagrama
        dot.attr(
            rankdir='TB',  # Top to Bottom
            size='6,7',    # Reduzido drasticamente para 6x7
            dpi='120',     # Reduzido para 120
            bgcolor='white',
            fontname='Arial',
            fontsize='9',  # Reduzido para 9
            labelloc='t',
            label='Sistema Epidemiol√≥gico\\n(Atualiza√ß√£o Semanal)'  # T√≠tulo com informa√ß√£o de atualiza√ß√£o
        )
        
        # Configura√ß√µes de n√≥s padr√£o
        dot.attr('node', 
                 shape='box',
                 style='filled,rounded',
                 fontname='Arial Bold',
                 fontsize='7',     # Reduzido drasticamente para 7
                 margin='0.1,0.02', # Margens m√≠nimas
                 width='0.8',      # Largura m√≠nima
                 height='0.5')     # Altura m√≠nima
        
        # Configura√ß√µes de edges padr√£o
        dot.attr('edge',
                 fontname='Arial',
                 fontsize='5',     # Reduzido drasticamente para 5
                 color='#333333')
        
        # Definir subgrafos por camadas
        
        # Camada 1: Fontes de Dados
        with dot.subgraph(name='cluster_sources') as sources:
            sources.attr(label='üåê FONTES DE DADOS OFICIAIS',
                        style='filled',
                        color='lightblue',
                        fontsize='8',  # Reduzido de 14 para 12
                        fontname='Arial Bold')
            
            sources.node('datasus', 'üè•\\nDataSUS', 
                        fillcolor='#1565C0', fontcolor='white')
            sources.node('sipni', 'üíâ\\nSIPNI', 
                        fillcolor='#2E7D32', fontcolor='white')
            sources.node('sih', 'üè®\\nSIH', 
                        fillcolor='#C62828', fontcolor='white')
            sources.node('sinan', 'üìä\\nSINAN', 
                        fillcolor='#F57C00', fontcolor='white')
        
        # Camada 2: Automa√ß√£o
        with dot.subgraph(name='cluster_automation') as automation:
            automation.attr(label='ü§ñ CAMADA DE AUTOMA√á√ÉO',
                           style='filled',
                           color='#F3E5F5',
                           fontsize='8',
                           fontname='Arial Bold')
            
            automation.node('webscraping', 'üï∑Ô∏è\\nWeb Scraping', 
                           fillcolor='#4527A0', fontcolor='white')
            automation.node('apis', 'üîó\\nAPI Requests', 
                           fillcolor='#6A1B9A', fontcolor='white')
            automation.node('validation', '‚úÖ\\nData Validation', 
                           fillcolor='#AD1457', fontcolor='white')
        
        # Camada 3: Processamento
        with dot.subgraph(name='cluster_processing') as processing:
            processing.attr(label='üîß CAMADA DE PROCESSAMENTO',
                           style='filled',
                           color='#E8F5E8',
                           fontsize='8',
                           fontname='Arial Bold')
            
            processing.node('python', 'üêç\\nPython Scripts\\n(Customizados)', 
                           fillcolor='#00695C', fontcolor='white')
            processing.node('pandas_etl', 'üîÑ\\nPandas ETL\\n(Extract, Transform, Load)', 
                           fillcolor='#00838F', fontcolor='white')
            processing.node('cleaning', 'üßπ\\nData Cleaning\\n(Normaliza√ß√£o)', 
                           fillcolor='#0277BD', fontcolor='white')
            processing.node('quality', 'üîç\\nQuality Check\\n(Consist√™ncia)', 
                           fillcolor='#0288D1', fontcolor='white')
        
        # Camada 4: Armazenamento
        with dot.subgraph(name='cluster_storage') as storage:
            storage.attr(label='üíæ CAMADA DE ARMAZENAMENTO',
                        style='filled',
                        color='#E8F5E8',
                        fontsize='14',
                        fontname='Arial Bold')
            
            storage.node('csv', 'üìÅ\\nCSV Files\\n(Estruturados)', 
                        fillcolor='#388E3C', fontcolor='white')
            storage.node('tabelas', 'üóÇÔ∏è\\nTABELAS/\\n(Diret√≥rio Central)', 
                        fillcolor='#43A047', fontcolor='white')
            storage.node('backup', 'üíæ\\nBackup System\\n(Versionamento)', 
                        fillcolor='#4CAF50', fontcolor='white')
        
        # Camada 5: Carregamento
        with dot.subgraph(name='cluster_loading') as loading:
            loading.attr(label='‚ö° CAMADA DE CARREGAMENTO',
                        style='filled',
                        color='#FFF3E0',
                        fontsize='14',
                        fontname='Arial Bold')
            
            loading.node('loader', '‚ö°\\nload_all_data()\\n(Fun√ß√£o Principal)', 
                        fillcolor='#FF6F00', fontcolor='white',
                        shape='ellipse',
                        style='filled,bold')
        
        # Camada 6: An√°lise Estat√≠stica
        with dot.subgraph(name='cluster_analysis') as analysis:
            analysis.attr(label='üìà CAMADA DE AN√ÅLISE ESTAT√çSTICA',
                         style='filled',
                         color='#FFEBEE',
                         fontsize='14',
                         fontname='Arial Bold')
            
            analysis.node('scipy', 'üìà\\nSciPy\\n(Estat√≠sticas)', 
                         fillcolor='#D32F2F', fontcolor='white')
            analysis.node('sklearn', 'ü§ñ\\nScikit-learn\\n(Machine Learning)', 
                         fillcolor='#E64A19', fontcolor='white')
            analysis.node('statsmodels', 'üìä\\nStatsmodels\\n(Modelos Avan√ßados)', 
                         fillcolor='#F57C00', fontcolor='white')
            analysis.node('numpy', 'üî¢\\nNumPy\\n(Computa√ß√£o)', 
                         fillcolor='#FFA000', fontcolor='white')
            analysis.node('pandas_analysis', 'üêº\\nPandas\\n(An√°lise)', 
                         fillcolor='#FFB300', fontcolor='white')
        
        # Camada 7: Visualiza√ß√£o
        with dot.subgraph(name='cluster_visualization') as viz:
            viz.attr(label='üé® CAMADA DE VISUALIZA√á√ÉO',
                     style='filled',
                     color='#F3E5F5',
                     fontsize='14',
                     fontname='Arial Bold')
            
            viz.node('plotly', 'üìä\\nPlotly\\n(Gr√°ficos Interativos)', 
                    fillcolor='#7B1FA2', fontcolor='white')
            viz.node('streamlit', 'üé®\\nStreamlit\\n(Interface Web)', 
                    fillcolor='#8E24AA', fontcolor='white')
            viz.node('charts', 'üìà\\nInteractive Charts\\n(Dashboards)', 
                    fillcolor='#9C27B0', fontcolor='white')
        
        # Camada 8: Dashboard Final
        with dot.subgraph(name='cluster_output') as output:
            output.attr(label='üöÄ DASHBOARD FINAL',
                       style='filled',
                       color='#E3F2FD',
                       fontsize='14',
                       fontname='Arial Bold')
            
            output.node('dashboard', 'üöÄ\\nDashboard\\nEpidemiol√≥gico\\n(Completo)', 
                       fillcolor='#1976D2', fontcolor='white',
                       shape='doubleoctagon',
                       style='filled,bold',
                       fontsize='12')
        
        # Definir conex√µes entre as camadas
        
        # Sources -> Automation
        dot.edge('datasus', 'webscraping', label='scraping')
        dot.edge('datasus', 'apis', label='APIs')
        dot.edge('sipni', 'apis', label='REST API')
        dot.edge('sipni', 'validation', label='validar')
        dot.edge('sih', 'webscraping', label='extra√ß√£o')
        dot.edge('sih', 'apis', label='consultas')
        dot.edge('sinan', 'apis', label='dados')
        dot.edge('sinan', 'validation', label='verificar')
        
        # Automation -> Processing
        dot.edge('webscraping', 'python', label='scripts')
        dot.edge('webscraping', 'pandas_etl', label='ETL')
        dot.edge('apis', 'python', label='processar')
        dot.edge('apis', 'cleaning', label='limpar')
        dot.edge('validation', 'cleaning', label='normalizar')
        dot.edge('validation', 'quality', label='verificar')
        
        # Processing -> Storage
        dot.edge('python', 'csv', label='salvar')
        dot.edge('pandas_etl', 'tabelas', label='armazenar')
        dot.edge('cleaning', 'tabelas', label='persistir')
        dot.edge('quality', 'backup', label='backup')
        
        # Storage -> Loading
        dot.edge('csv', 'loader', label='carregar')
        dot.edge('tabelas', 'loader', label='importar')
        dot.edge('backup', 'loader', label='recuperar')
        
        # Loading -> Analysis
        dot.edge('loader', 'scipy', label='estat√≠sticas')
        dot.edge('loader', 'sklearn', label='ML')
        dot.edge('loader', 'statsmodels', label='modelos')
        dot.edge('loader', 'numpy', label='c√°lculos')
        dot.edge('loader', 'pandas_analysis', label='an√°lise')
        
        # Analysis -> Visualization
        dot.edge('scipy', 'plotly', label='gr√°ficos')
        dot.edge('sklearn', 'charts', label='viz ML')
        dot.edge('statsmodels', 'plotly', label='plots')
        dot.edge('numpy', 'streamlit', label='interface')
        dot.edge('pandas_analysis', 'streamlit', label='dados')
        
        # Visualization -> Output
        dot.edge('plotly', 'dashboard', label='integrar')
        dot.edge('streamlit', 'dashboard', label='renderizar')
        dot.edge('charts', 'dashboard', label='exibir')
        
        # Salvar diagrama como PNG na raiz do projeto
        try:
            import os
            # Obter caminho da raiz do projeto (3 n√≠veis acima de app_sections)
            current_dir = os.path.dirname(__file__)
            project_root = os.path.dirname(current_dir)
            png_path = os.path.join(project_root, 'diagrama_sistema_epidemiologico')
            
            # Renderizar e salvar
            dot.render(png_path, cleanup=True)
            st.success(f"‚úÖ Diagrama PNG salvo em: {png_path}.png")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar PNG: {e}")
        
        return dot
        
    except Exception as e:
        st.error(f"Erro ao criar diagrama Graphviz: {e}")
        return None


def create_data_architecture_diagram():
    """Cria diagrama da arquitetura de dados usando Plotly"""
    
    # Definir categorias e suas tabelas
    categories = {
        'Epidemiol√≥gicos': {
            'x': 2, 'y': 6, 'color': '#E3F2FD',
            'tables': ['casos_consolidados', 'casos_notificados', 'dados_gerais', 'tabela_unificada']
        },
        'Sorogrupos': {
            'x': 6, 'y': 6, 'color': '#F3E5F5', 
            'tables': ['sorogrupos_2024', 'sorogrupos_consolidados', 'df_sorogrupos_completo']
        },
        'Etiologia': {
            'x': 10, 'y': 6, 'color': '#E8F5E8',
            'tables': ['etiologia_2024', 'etiologias_consolidadas', 'bacterianas_2024']
        },
        'Imuniza√ß√£o': {
            'x': 2, 'y': 3, 'color': '#FFF3E0',
            'tables': ['imunizacoesmenin', 'dados_imunizacao_processados', 'imunobiologicos']
        },
        'Hospitalares': {
            'x': 6, 'y': 3, 'color': '#FFEBEE',
            'tables': ['sih_meningite_hospitalar', 'sih_meningite_long', 'sih_meningite_wide']
        },
        'Letalidade': {
            'x': 10, 'y': 3, 'color': '#F1F8E9',
            'tables': ['df_letalidade', 'letalidade_etiologia']
        },
        'Dashboard': {'x': 6, 'y': 0, 'color': '#FFECB3', 'tables': ['An√°lises Integradas']}
    }
    
    fig = go.Figure()
    
    # Adicionar conex√µes para o dashboard central
    for cat_name, cat_data in categories.items():
        if cat_name != 'Dashboard':
            fig.add_trace(go.Scatter(
                x=[cat_data['x'], 6],
                y=[cat_data['y'], 0],
                mode='lines',
                line=dict(color='#999999', width=1, dash='dot'),
                showlegend=False,
                hoverinfo='none'
            ))
    
    # Adicionar n√≥s das categorias
    for cat_name, cat_data in categories.items():
        # Tamanho baseado no n√∫mero de tabelas
        size = 100 + len(cat_data['tables']) * 10
        
        fig.add_trace(go.Scatter(
            x=[cat_data['x']],
            y=[cat_data['y']],
            mode='markers+text',
            marker=dict(
                size=size,
                color=cat_data['color'],
                line=dict(color='#333333', width=2)
            ),
            text=cat_name,
            textposition='middle center',
            textfont=dict(size=11, color='#000000'),
            showlegend=False,
            hovertemplate=f'<b>{cat_name}</b><br>' + 
                         '<br>'.join([f'‚Ä¢ {table}' for table in cat_data['tables']]) + 
                         '<extra></extra>'
        ))
    
    # Configurar layout
    fig.update_layout(
        title={
            'text': 'üèóÔ∏è Arquitetura de Dados - Categorias das Tabelas',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 16, 'color': '#1f77b4'}
        },
        xaxis=dict(
            showgrid=False,
            showticklabels=False,
            zeroline=False,
            range=[0, 12]
        ),
        yaxis=dict(
            showgrid=False,
            showticklabels=False,
            zeroline=False,
            range=[-1, 7]
        ),
        plot_bgcolor='white',
        paper_bgcolor='white',
        height=250,  # Reduzido drasticamente para 250
        margin=dict(l=20, r=20, t=30, b=20)  # Margens m√≠nimas
    )
    
    return fig


def create_data_statistics_charts(dados):
    """Cria gr√°ficos de estat√≠sticas dos dados carregados"""
    
    if not dados:
        return None, None
    
    # Preparar dados para visualiza√ß√£o
    datasets_info = []
    for key, value in dados.items():
        if isinstance(value, pd.DataFrame):
            datasets_info.append({
                'Dataset': key.replace('_', ' ').title(),
                'Linhas': value.shape[0],
                'Colunas': value.shape[1],
                'Mem√≥ria_MB': value.memory_usage(deep=True).sum() / 1024**2,
                'Missing_Percent': (value.isnull().sum().sum() / (value.shape[0] * value.shape[1])) * 100 if value.shape[0] > 0 and value.shape[1] > 0 else 0
            })
    
    if not datasets_info:
        return None, None
    
    df_stats = pd.DataFrame(datasets_info)
    
    # Gr√°fico 1: Tamanho dos datasets (linhas)
    fig1 = px.bar(
        df_stats, 
        x='Dataset', 
        y='Linhas',
        title='üìä N√∫mero de Registros por Dataset',
        color='Linhas',
        color_continuous_scale='Blues',
        text='Linhas'
    )
    fig1.update_traces(texttemplate='%{text:,}', textposition='outside')
    fig1.update_layout(
        xaxis_tickangle=-45,
        height=220,  # Reduzido drasticamente para 220
        showlegend=False
    )
    
    # Gr√°fico 2: Uso de mem√≥ria
    fig2 = px.pie(
        df_stats, 
        values='Mem√≥ria_MB', 
        names='Dataset',
        title='üíæ Distribui√ß√£o de Uso de Mem√≥ria',
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    fig2.update_traces(textposition='inside', textinfo='percent+label')
    fig2.update_layout(height=220)  # Reduzido drasticamente para 220
    
    return fig1, fig2


def show_technical_exposition(dados):
    """Mostra exposi√ß√£o t√©cnica completa do sistema"""
    st.header("‚öôÔ∏è **Expositivo T√©cnico - Arquitetura e Metodologia**")
    st.markdown("---")
    
    # Introdu√ß√£o
    st.markdown("""
    ## üéØ **Vis√£o Geral do Sistema**
    
    Este dashboard representa um sistema completo de an√°lise epidemiol√≥gica de meningite no Brasil, 
    integrando coleta automatizada de dados, processamento estat√≠stico avan√ßado e visualiza√ß√£o interativa.
    
    ### üìÖ **Atualiza√ß√£o Semanal Autom√°tica**
    
    ‚è∞ **O sistema atualiza automaticamente todos os dados SEMANALMENTE (1x por semana):**
    - üîÑ **Consulta autom√°tica** aos sites oficiais (DataSUS, SIPNI, SIH, SINAN)
    - üÜï **Cria√ß√£o de novas tabelas** com dados atualizados
    - üìä **Substitui√ß√£o completa** dos arquivos na pasta `TABELAS/`
    - ‚úÖ **Garantia de dados sempre atuais** para an√°lises precisas
    
    Isso garante que todas as an√°lises e visualiza√ß√µes reflitam sempre os dados mais recentes dispon√≠veis.
    """)
    
    # Se√ß√£o 1: Arquitetura de Dados
    st.header("üèóÔ∏è **1. Arquitetura de Dados e Automa√ß√£o**")
    
    # Diagrama de fluxo de dados visual
    st.subheader("üìä **Fluxo de Dados do Sistema**")
    
    # Oferecer op√ß√£o entre diagramas
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown("**Escolha o tipo de diagrama:**")
    with col2:
        diagram_type = st.selectbox(
            "Tipo:",
            ["Plotly (Interativo)", "Graphviz (Profissional)"],
            index=0
        )
    
    if diagram_type == "Graphviz (Profissional)" and GRAPHVIZ_AVAILABLE:
        # Criar diagrama Graphviz
        try:
            graphviz_diagram = create_graphviz_flow_diagram()
            if graphviz_diagram:
                st.markdown("#### üèóÔ∏è **Diagrama Graphviz - M√°xima Qualidade Profissional**")
                st.graphviz_chart(graphviz_diagram.source)
                st.success("‚úÖ Diagrama Graphviz renderizado com sucesso!")
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel gerar o diagrama Graphviz. Mostrando vers√£o Plotly.")
                flow_diagram = create_advanced_flow_diagram()
                st.plotly_chart(flow_diagram, use_container_width=True)
        except Exception as e:
            st.error(f"‚ùå Erro no Graphviz: {e}")
            st.info("üîÑ Alternando para diagrama Plotly...")
            flow_diagram = create_advanced_flow_diagram()
            st.plotly_chart(flow_diagram, use_container_width=True)
    else:
        if diagram_type == "Graphviz (Profissional)" and not GRAPHVIZ_AVAILABLE:
            st.warning("‚ö†Ô∏è Graphviz n√£o est√° dispon√≠vel. Mostrando vers√£o Plotly interativa.")
        
        # Criar diagrama Plotly
        flow_diagram = create_advanced_flow_diagram()
        st.plotly_chart(flow_diagram, use_container_width=True)
    
    # Explica√ß√£o detalhada das camadas do fluxo
    st.markdown("""
    #### üîç **Explica√ß√£o Detalhada das 8 Camadas do Sistema:**
    
    ##### üåê **Camada 1: FONTES DE DADOS**
    - üè• **DataSUS:** Sistema de Informa√ß√µes em Sa√∫de do Minist√©rio
    - üíâ **SIPNI:** Sistema de Informa√ß√µes do Programa Nacional de Imuniza√ß√µes
    - üè® **SIH:** Sistema de Informa√ß√µes Hospitalares
    - üìä **SINAN:** Sistema de Informa√ß√£o de Agravos de Notifica√ß√£o
    
    ##### ü§ñ **Camada 2: AUTOMA√á√ÉO**
    - üï∑Ô∏è **Web Scraping:** Extra√ß√£o automatizada de p√°ginas web
    - üîó **API Requests:** Requisi√ß√µes diretas a APIs oficiais
    - ‚úÖ **Data Validation:** Valida√ß√£o autom√°tica de integridade
    
    ##### üîß **Camada 3: PROCESSAMENTO**
    - üêç **Python Scripts:** Scripts customizados de processamento
    - üîÑ **Pandas ETL:** Extract, Transform, Load com Pandas
    - üßπ **Data Cleaning:** Limpeza e normaliza√ß√£o de dados
    - üîç **Quality Check:** Verifica√ß√£o de qualidade e consist√™ncia
    
    ##### üíæ **Camada 4: ARMAZENAMENTO**
    - üìÅ **CSV Files:** Arquivos estruturados em formato CSV
    - üóÇÔ∏è **TABELAS/:** Diret√≥rio central de armazenamento
    - üíæ **Backup System:** Sistema de backup e versionamento
    
    ##### ‚ö° **Camada 5: CARREGAMENTO**
    - ‚ö° **load_all_data():** Fun√ß√£o principal de carregamento otimizado
    
    ##### üìà **Camada 6: AN√ÅLISE ESTAT√çSTICA**
    - üìà **SciPy:** Estat√≠sticas cient√≠ficas e testes
    - ü§ñ **Scikit-learn:** Machine learning e modelagem
    - üìä **Statsmodels:** Modelos estat√≠sticos avan√ßados
    - üî¢ **NumPy:** Computa√ß√£o num√©rica de alta performance
    - üêº **Pandas:** Manipula√ß√£o e an√°lise de dados
    
    ##### üé® **Camada 7: VISUALIZA√á√ÉO**
    - üìä **Plotly:** Gr√°ficos interativos e dashboards
    - üé® **Streamlit:** Framework de interface web
    - üìà **Interactive Charts:** Visualiza√ß√µes din√¢micas
    
    ##### üöÄ **Camada 8: DASHBOARD FINAL**
    - üöÄ **Dashboard Epidemiol√≥gico:** Interface completa integrada
    
    **üí° Dica:** Passe o mouse sobre cada elemento do diagrama para ver detalhes espec√≠ficos!
    """)
    
    # Explica√ß√£o detalhada da automa√ß√£o
    st.markdown("""
    ### ü§ñ **Sistema de Automa√ß√£o de Dados**
    
    #### üì° **Fontes de Dados Oficiais:**
    - **DataSUS (DATASUS):** Sistema de Informa√ß√µes em Sa√∫de
    - **SIPNI:** Sistema de Informa√ß√µes do Programa Nacional de Imuniza√ß√µes  
    - **SIH:** Sistema de Informa√ß√µes Hospitalares
    - **SINAN:** Sistema de Informa√ß√£o de Agravos de Notifica√ß√£o
    
    #### üîß **Tecnologias de Automa√ß√£o Utilizadas:**
    
    **Python Libraries:**
    - `requests`: Requisi√ß√µes HTTP para APIs
    - `beautifulsoup4`: Web scraping de p√°ginas HTML
    - `selenium`: Automa√ß√£o de navegadores web
    - `pandas`: Manipula√ß√£o e an√°lise de dados
    - `numpy`: Computa√ß√£o num√©rica
    
    **Processo Automatizado (SEMANAL):**
    
    üìÖ **Cronograma: Toda SEGUNDA-FEIRA √†s 06:00h**
    
    1. **üîç Monitoramento**: Scripts verificam atualiza√ß√µes nas fontes oficiais
    2. **üì• Extra√ß√£o**: Dados s√£o coletados via APIs e web scraping automatizado
    3. **‚úÖ Valida√ß√£o**: Verifica√ß√£o de integridade e consist√™ncia dos dados
    4. **üßπ Limpeza**: Remo√ß√£o de duplicatas e tratamento de missing values
    5. **üìä Padroniza√ß√£o**: Formata√ß√£o uniforme das tabelas (padr√£o CSV)
    6. **üíæ Armazenamento**: Substitui√ß√£o completa dos arquivos na pasta `TABELAS/`
    7. **üîÑ Backup**: Versionamento autom√°tico dos dados anteriores
    8. **üìã Log**: Registro detalhado de todas as opera√ß√µes realizadas
    
    ‚ö° **Resultado:** Dados sempre atualizados com no m√°ximo 7 dias de defasagem!
    """)
    
    # Se√ß√£o 2: Estrutura das Tabelas
    st.header("üìã **2. Estrutura e Utiliza√ß√£o das Tabelas**")
    
    # Diagrama de arquitetura de dados
    st.subheader("üèóÔ∏è **Arquitetura Visual das Categorias de Dados**")
    
    # Criar e exibir diagrama de arquitetura
    architecture_diagram = create_data_architecture_diagram()
    st.plotly_chart(architecture_diagram, use_container_width=True)
    
    st.markdown("""
    **üí° Dica:** Passe o mouse sobre cada categoria para ver as tabelas espec√≠ficas que ela cont√©m!
    """)
    
    # Categorizar as tabelas por tipo
    st.subheader("üóÇÔ∏è **Detalhamento das Categorias de Dados**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### üìä **Dados Epidemiol√≥gicos:**
        - `casos_consolidados_2017_2024.csv`: Casos notificados agregados
        - `casos_notificados_2017_2022.csv`: Dados brutos de notifica√ß√£o
        - `dados_gerais_2024.csv`: Estat√≠sticas gerais do ano atual
        - `data_meninatu.csv`: Dados espec√≠ficos de meningite tuberculosa
        - `tabela_unificada.csv`: Base consolidada principal
        
        #### ü¶† **Dados por Sorogrupo:**
        - `sorogrupos_2024.csv`: Sorogrupos do ano atual
        - `sorogrupos_consolidados_2007_2024.csv`: S√©rie hist√≥rica
        - `df_sorogrupos_2007_2020.csv`: Dados hist√≥ricos espec√≠ficos
        - `df_sorogrupos_2024.csv`: Dados processados 2024
        - `df_sorogrupos_completo.csv`: Base completa consolidada
        """)
    
    with col2:
        st.markdown("""
        #### üî¨ **Dados de Etiologia:**
        - `etiologia_2024.csv`: Etiologias identificadas
        - `etiologias_consolidadas_2007_2024.csv`: S√©rie temporal
        - `df_etiologia_2024.csv`: Dados processados
        - `bacterianas_2024.csv`: Meningites bacterianas
        - `df_bacterianas_2024.csv`: Dados bacterianos processados
        
        #### üíâ **Dados de Imuniza√ß√£o:**
        - `imunizacoesmenin.csv`: Dados brutos de vacina√ß√£o
        - `cleaned_imunizacoesmenin.csv`: Dados limpos
        - `imunizacoesmenin_fixed.csv`: Dados corrigidos
        - `dados_imunizacao_processados.csv`: Base processada
        - `imunobiologicosem2023a2025.csv`: Imunobiol√≥gicos per√≠odo
        """)
    
    # An√°lise espec√≠fica por tipo
    st.subheader("üîç **An√°lise Espec√≠fica por Categoria**")
    
    # Dados de hospitaliza√ß√£o
    st.markdown("""
    #### üè• **Dados Hospitalares (SIH):**
    - `sih_meningite_hospitalar.csv`: Interna√ß√µes por meningite
    - `sih_meningite_long.csv`: Formato longo para an√°lises temporais
    - `sih_meningite_wide.csv`: Formato largo para an√°lises transversais
    
    **Tratamentos Aplicados:**
    - Convers√£o entre formatos long/wide para diferentes an√°lises
    - C√°lculo de taxas de hospitaliza√ß√£o
    - An√°lise de sazonalidade nas interna√ß√µes
    - Correla√ß√£o com dados de notifica√ß√£o
    """)
    
    # Dados de letalidade
    st.markdown("""
    #### ‚ö∞Ô∏è **Dados de Letalidade:**
    - `df_letalidade_2007_2020.csv`: Taxas de letalidade hist√≥ricas
    - `letalidade_etiologia_2007_2020.csv`: Letalidade por etiologia
    
    **Tratamentos Aplicados:**
    - C√°lculo de taxas de letalidade: (√ìbitos/Casos) √ó 100
    - Estratifica√ß√£o por etiologia e sorogrupo
    - An√°lise temporal da letalidade
    - Identifica√ß√£o de fatores de risco
    """)
    
    # Dados de imuniza√ß√£o detalhados
    st.markdown("""
    #### üíâ **Dados de Imuniza√ß√£o Estratificados:**
    - `imunizacao_por_ano.csv`: Evolu√ß√£o anual da cobertura
    - `imunizacao_por_faixa_etaria.csv`: Cobertura por idade
    - `imunizacao_por_sorogrupo.csv`: Vacina√ß√£o espec√≠fica
    - `imunizacao_por_uf.csv`: Distribui√ß√£o geogr√°fica
    - `doses_todosimunosate2022.csv`: Doses aplicadas por regi√£o
    
    **Tratamentos Aplicados:**
    - Padroniza√ß√£o de faixas et√°rias
    - C√°lculo de coberturas vacinais
    - An√°lise de disparidades regionais
    - Correla√ß√£o cobertura √ó incid√™ncia
    """)
    
    # Se√ß√£o 3: Metodologias Estat√≠sticas
    st.header("üìà **3. Metodologias Estat√≠sticas Implementadas**")
    
    st.subheader("üî¢ **Estat√≠stica Descritiva**")
    st.markdown("""
    #### üìä **Medidas de Tend√™ncia Central e Dispers√£o:**
    - **M√©dia, Mediana, Moda**: Tend√™ncias centrais dos dados
    - **Desvio Padr√£o, Vari√¢ncia**: Medidas de dispers√£o
    - **Quartis e Percentis**: Distribui√ß√£o dos dados
    - **Coeficiente de Varia√ß√£o**: Variabilidade relativa
    
    **Implementa√ß√£o:**
    ```python
    # Exemplo de c√°lculo de estat√≠sticas descritivas
    stats_descritivas = dados.describe()
    cv = dados.std() / dados.mean() * 100  # Coeficiente de Varia√ß√£o
    ```
    """)
    
    st.subheader("üìâ **An√°lise de Correla√ß√£o**")
    st.markdown("""
    #### üîó **Tipos de Correla√ß√£o Implementados:**
    
    **1. Correla√ß√£o de Pearson:**
    - Mede rela√ß√µes lineares entre vari√°veis
    - Usado para: casos vs letalidade, cobertura vs incid√™ncia
    - Formula: r = Œ£((x-xÃÑ)(y-»≥)) / ‚àö(Œ£(x-xÃÑ)¬≤Œ£(y-»≥)¬≤)
    
    **2. Correla√ß√£o de Spearman:**
    - Mede rela√ß√µes monot√¥nicas (n√£o necessariamente lineares)
    - Robusto a outliers
    - Baseado em rankings dos dados
    
    **3. Correla√ß√£o Cruzada:**
    - An√°lise entre m√∫ltiplas vari√°veis simultaneamente
    - Identifica padr√µes complexos entre sorogrupos
    
    **Implementa√ß√£o:**
    ```python
    from scipy.stats import pearsonr, spearmanr
    
    # Correla√ß√£o de Pearson
    corr_pearson, p_pearson = pearsonr(x, y)
    
    # Correla√ß√£o de Spearman  
    corr_spearman, p_spearman = spearmanr(x, y)
    ```
    """)
    
    st.subheader("üìä **An√°lise de Regress√£o**")
    st.markdown("""
    #### üìà **Modelos de Regress√£o Utilizados:**
    
    **1. Regress√£o Linear Simples:**
    - Modelo: Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ
    - Usado para: tend√™ncias temporais, rela√ß√µes bivariadas
    - M√©tricas: R¬≤, RMSE, p-valor
    
    **2. Regress√£o Linear M√∫ltipla:**
    - Modelo: Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤‚ÇôX‚Çô + Œµ
    - Usado para: an√°lise multivariada de fatores
    - Valida√ß√£o: Time Series Split para dados temporais
    
    **3. Regress√£o Polinomial:**
    - Captura rela√ß√µes n√£o-lineares
    - Usado para: rela√ß√µes complexas entre vari√°veis
    
    **Implementa√ß√£o:**
    ```python
    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.metrics import r2_score, mean_squared_error
    
    # Modelo de regress√£o
    modelo = LinearRegression()
    modelo.fit(X_train, y_train)
    
    # M√©tricas de avalia√ß√£o
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    ```
    """)
    
    st.subheader("‚è±Ô∏è **An√°lise de S√©ries Temporais**")
    st.markdown("""
    #### üìÖ **T√©cnicas de S√©ries Temporais:**
    
    **1. Decomposi√ß√£o STL (Seasonal and Trend decomposition using Loess):**
    - Separa s√©rie em: Tend√™ncia + Sazonalidade + Res√≠duos
    - Mais robusta que decomposi√ß√£o cl√°ssica
    - Permite an√°lise de componentes individuais
    
    **2. Teste de Estacionariedade (ADF):**
    - Augmented Dickey-Fuller Test
    - Verifica se a s√©rie √© estacion√°ria
    - Fundamental para modelagem ARIMA
    
    **3. An√°lise de Autocorrela√ß√£o:**
    - Identifica padr√µes de depend√™ncia temporal
    - Usado para detectar sazonalidade
    
    **Implementa√ß√£o:**
    ```python
    from statsmodels.tsa.seasonal import STL
    from statsmodels.tsa.stattools import adfuller
    
    # Decomposi√ß√£o STL
    stl = STL(serie_temporal, period=12)
    resultado = stl.fit()
    
    # Teste ADF
    adf_stat, p_value = adfuller(serie_temporal)[:2]
    ```
    """)
    
    st.subheader("ü§ñ **Machine Learning e Clustering**")
    st.markdown("""
    #### üî¨ **Algoritmos de Machine Learning:**
    
    **1. K-Means Clustering:**
    - Agrupa sorogrupos por caracter√≠sticas similares
    - Identifica padr√µes epidemiol√≥gicos
    - Usado para: segmenta√ß√£o de sorogrupos
    
    **2. Clustering Hier√°rquico:**
    - Cria dendrograma de relacionamentos
    - M√©todo Ward para minimizar vari√¢ncia
    - Complementa an√°lise K-Means
    
    **3. PCA (Principal Component Analysis):**
    - Redu√ß√£o dimensional preservando vari√¢ncia
    - Identifica componentes principais
    - Usado para: visualiza√ß√£o de dados multidimensionais
    
    **Implementa√ß√£o:**
    ```python
    from sklearn.cluster import KMeans
    from sklearn.decomposition import PCA
    from scipy.cluster.hierarchy import dendrogram, linkage
    
    # K-Means
    kmeans = KMeans(n_clusters=3, random_state=42)
    clusters = kmeans.fit_predict(dados_scaled)
    
    # PCA
    pca = PCA(n_components=2)
    dados_pca = pca.fit_transform(dados_scaled)
    ```
    """)
    
    # Se√ß√£o 4: Processo de Visualiza√ß√£o
    st.header("üé® **4. Processo de Visualiza√ß√£o e Interface**")
    
    st.subheader("üìä **Biblioteca Plotly - Gr√°ficos Interativos**")
    st.markdown("""
    #### üéØ **Tipos de Gr√°ficos Implementados:**
    
    **1. Gr√°ficos de Linha (Time Series):**
    - Evolu√ß√£o temporal de casos
    - Tend√™ncias de vacina√ß√£o
    - An√°lise de sazonalidade
    
    **2. Gr√°ficos de Dispers√£o (Scatter):**
    - Correla√ß√µes entre vari√°veis
    - Regress√µes lineares e polinomiais
    - An√°lise multivariada
    
    **3. Gr√°ficos de Barras:**
    - Distribui√ß√µes por categoria
    - Compara√ß√µes regionais
    - Rankings de incid√™ncia
    
    **4. Heatmaps:**
    - Matrizes de correla√ß√£o
    - Distribui√ß√£o geogr√°fica
    - Padr√µes sazonais
    
    **5. Gr√°ficos de Subplots:**
    - Decomposi√ß√£o de s√©ries temporais
    - An√°lises comparativas
    - Diagn√≥sticos de modelos
    """)
    
    st.subheader("üñ•Ô∏è **Streamlit - Framework de Interface**")
    st.markdown("""
    #### ‚öôÔ∏è **Componentes de Interface Utilizados:**
    
    **Navega√ß√£o:**
    - `st.sidebar.selectbox()`: Menu principal de navega√ß√£o
    - `st.tabs()`: Abas dentro de se√ß√µes
    - `st.columns()`: Layout responsivo em colunas
    
    **Visualiza√ß√£o:**
    - `st.plotly_chart()`: Gr√°ficos interativos
    - `st.dataframe()`: Tabelas interativas
    - `st.metric()`: KPIs e m√©tricas principais
    
    **Interatividade:**
    - `st.selectbox()`: Sele√ß√£o de par√¢metros
    - `st.slider()`: Controles num√©ricos
    - `st.checkbox()`: Filtros booleanos
    
    **Formata√ß√£o:**
    - `st.markdown()`: Texto formatado e explica√ß√µes
    - `st.latex()`: F√≥rmulas matem√°ticas
    - `st.code()`: C√≥digo de exemplo
    """)
    
    # Se√ß√£o 5: Performance e Otimiza√ß√£o
    st.header("‚ö° **5. Performance e Otimiza√ß√£o**")
    
    st.markdown("""
    #### üöÄ **Estrat√©gias de Otimiza√ß√£o Implementadas:**
    
    **1. Cache de Dados:**
    ```python
    @st.cache_data
    def load_all_data():
        # Carregamento otimizado com cache
        return dados_processados
    ```
    
    **2. Processamento Eficiente:**
    - Uso de `pandas.groupby()` para agrega√ß√µes
    - Vetoriza√ß√£o com `numpy` para c√°lculos
    - Lazy loading de dados n√£o utilizados
    
    **3. Gest√£o de Mem√≥ria:**
    - Limpeza de DataFrames tempor√°rios
    - Uso de `dtype` apropriados
    - Garbage collection autom√°tico
    
    **4. Tratamento de Erros:**
    - Try-catch para imports condicionais
    - Valida√ß√£o de dados de entrada
    - Fallbacks para funcionalidades avan√ßadas
    """)
    
    # Se√ß√£o 6: M√©tricas Epidemiol√≥gicas
    st.header("üè• **6. M√©tricas Epidemiol√≥gicas Calculadas**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### üìä **Incid√™ncia e Preval√™ncia:**
        
        **Taxa de Ataque:**
        ```
        Taxa = (Casos / Popula√ß√£o) √ó 100.000
        ```
        
        **For√ßa de Infec√ß√£o:**
        ```
        Œª = -ln(1 - taxa_ataque)
        ```
        
        **Taxa de Letalidade:**
        ```
        Letalidade = (√ìbitos / Casos) √ó 100
        ```
        """)
    
    with col2:
        st.markdown("""
        #### üíâ **Cobertura Vacinal:**
        
        **Cobertura por Dose:**
        ```
        Cobertura = (Doses / Pop_Alvo) √ó 100
        ```
        
        **Efetividade Vacinal:**
        ```
        EV = 1 - (Taxa_Vacinados / Taxa_N√£o_Vacinados)
        ```
        
        **Imunidade Coletiva:**
        ```
        Limiar = 1 - (1/R‚ÇÄ)
        ```
        """)
    
    # Se√ß√£o 7: Modelagem Epidemiol√≥gica
    st.header("üßÆ **7. Modelagem Epidemiol√≥gica Avan√ßada**")
    
    st.markdown("""
    ### ü¶† **Modelo SIR Implementado**
    
    O sistema inclui uma implementa√ß√£o completa do **modelo SIR** (Susceptible-Infected-Recovered), 
    um dos modelos matem√°ticos mais fundamentais em epidemiologia.
    
    #### üî¨ **Caracter√≠sticas da Implementa√ß√£o:**
    
    **üìä Funcionalidades Principais:**
    - ‚úÖ **Ajuste autom√°tico** de par√¢metros aos dados reais
    - ‚úÖ **Estima√ß√£o de R‚ÇÄ** (n√∫mero b√°sico de reprodu√ß√£o)
    - ‚úÖ **Visualiza√ß√µes interativas** com m√∫ltiplas perspectivas
    - ‚úÖ **An√°lise de sensibilidade** dos par√¢metros
    - ‚úÖ **Interpreta√ß√£o did√°tica** dos resultados
    
    **‚öôÔ∏è M√©todos Matem√°ticos:**
    - **Resolu√ß√£o num√©rica**: M√©todo odeint (scipy.integrate)
    - **Otimiza√ß√£o**: Minimiza√ß√£o de erro quadr√°tico m√©dio
    - **Algoritmo**: Nelder-Mead para ajuste de par√¢metros
    - **Valida√ß√£o**: Compara√ß√£o com dados hist√≥ricos
    
    **üìà Equa√ß√µes Diferenciais:**
    ```
    dS/dt = -Œ≤ √ó S √ó I / N
    dI/dt = Œ≤ √ó S √ó I / N - Œ≥ √ó I  
    dR/dt = Œ≥ √ó I
    ```
    
    **üéØ Par√¢metros Estimados:**
    - **Œ≤ (beta)**: Taxa de transmiss√£o
    - **Œ≥ (gamma)**: Taxa de recupera√ß√£o
    - **R‚ÇÄ = Œ≤/Œ≥**: N√∫mero b√°sico de reprodu√ß√£o
    
    #### üìä **Visualiza√ß√µes Geradas:**
    
    1. **Compara√ß√£o Dados Reais vs Modelo**: Valida√ß√£o do ajuste
    2. **Evolu√ß√£o S-I-R**: Din√¢mica dos compartimentos
    3. **Taxa de Infec√ß√£o**: Velocidade de propaga√ß√£o
    4. **Fase Portrait**: Rela√ß√£o din√¢mica S vs I
    5. **An√°lise de Sensibilidade**: Impacto de varia√ß√µes nos par√¢metros
    
    #### üéì **Interpreta√ß√£o Epidemiol√≥gica:**
    
    **R‚ÇÄ (N√∫mero B√°sico de Reprodu√ß√£o):**
    - **R‚ÇÄ < 1**: Epidemia em decl√≠nio
    - **R‚ÇÄ = 1**: Epidemia est√°vel  
    - **R‚ÇÄ > 1**: Epidemia em crescimento
    
    **Per√≠odo Infeccioso**: 1/Œ≥ (tempo m√©dio de infec√ß√£o)
    
    **Taxa de Transmiss√£o**: Œ≤ (probabilidade de transmiss√£o por contato)
    
    #### üîç **Limita√ß√µes Reconhecidas:**
    
    - **Popula√ß√£o homog√™nea**: Assume mistura aleat√≥ria
    - **Par√¢metros constantes**: Œ≤ e Œ≥ fixos no tempo
    - **Sem reinfec√ß√£o**: Imunidade permanente assumida
    - **Dados agregados**: Resolu√ß√£o temporal limitada
    
    #### üí° **Aplica√ß√µes Pr√°ticas:**
    
    - **Previs√£o de surtos**: Estimativa de picos epid√™micos
    - **Avalia√ß√£o de interven√ß√µes**: Impacto de medidas de controle
    - **Planejamento de recursos**: Dimensionamento de leitos/vacinas
    - **Comunica√ß√£o de risco**: Visualiza√ß√£o did√°tica para gestores
    
    #### üìö **Bibliotecas Utilizadas:**
    
    **Modelagem Epidemiol√≥gica:**
    - `epimodels`: Modelos epidemiol√≥gicos cl√°ssicos
    - `epydemiology`: An√°lises epidemiol√≥gicas avan√ßadas
    - `lmfit`: Ajuste de modelos n√£o-lineares
    - `pymc`: Modelagem probabil√≠stica bayesiana
    - `arviz`: An√°lise e visualiza√ß√£o de modelos bayesianos
    
    **Computa√ß√£o Cient√≠fica:**
    - `scipy.integrate.odeint`: Resolu√ß√£o de EDOs
    - `scipy.optimize.minimize`: Otimiza√ß√£o de par√¢metros
    - `numpy`: Opera√ß√µes num√©ricas eficientes
    - `pandas`: Manipula√ß√£o de dados temporais
    """)
    
    # Se√ß√£o 8: Valida√ß√£o e Qualidade
    st.header("‚úÖ **8. Valida√ß√£o e Controle de Qualidade**")
    
    st.markdown("""
    #### üîç **Processos de Valida√ß√£o Implementados:**
    
    **1. Valida√ß√£o de Dados:**
    - Verifica√ß√£o de tipos de dados (dtype validation)
    - Detec√ß√£o de valores missing e outliers
    - Consist√™ncia temporal (datas v√°lidas)
    - Integridade referencial entre tabelas
    
    **2. Valida√ß√£o Estat√≠stica:**
    - Teste de normalidade (Shapiro-Wilk)
    - Detec√ß√£o de multicolinearidade (VIF)
    - Valida√ß√£o cruzada para modelos
    - An√°lise de res√≠duos
    
    **3. Valida√ß√£o Epidemiol√≥gica:**
    - Coer√™ncia de taxas calculadas
    - Compara√ß√£o com literatura cient√≠fica
    - Valida√ß√£o de tend√™ncias esperadas
    - Verifica√ß√£o de sazonalidade conhecida
    
    **4. Monitoramento Cont√≠nuo:**
    - Logs de processamento de dados
    - Alertas para anomalias detectadas
    - Versionamento de dados
    - Backup automatizado
    """)
    
    # Se√ß√£o 9: Considera√ß√µes T√©cnicas
    st.header("‚ö†Ô∏è **9. Limita√ß√µes e Considera√ß√µes T√©cnicas**")
    
    st.markdown("""
    #### üöß **Limita√ß√µes Conhecidas:**
    
    **1. Dados:**
    - Depend√™ncia da qualidade dos dados oficiais
    - Poss√≠vel subnotifica√ß√£o em algumas regi√µes
    - Atraso na disponibiliza√ß√£o de dados recentes
    - Mudan√ßas metodol√≥gicas nas fontes
    
    **2. Estat√≠sticas:**
    - Modelos assumem distribui√ß√µes espec√≠ficas
    - Correla√ß√£o n√£o implica causalidade
    - S√©ries temporais curtas limitam an√°lises
    - Poss√≠vel autocorrela√ß√£o residual
    
    **3. T√©cnicas:**
    - Alguns pacotes podem ter incompatibilidades
    - An√°lises avan√ßadas requerem dados suficientes
    - Clustering √© sens√≠vel √† escala dos dados
    - PCA pode perder interpretabilidade
    
    **4. Performance:**
    - Processamento intensivo para grandes datasets
    - Limita√ß√µes de mem√≥ria para an√°lises complexas
    - Tempo de carregamento para primeira execu√ß√£o
    - Depend√™ncia de conex√£o para dados atualizados
    """)
    
    # Se√ß√£o 9: Estat√≠sticas dos Dados Atuais
    st.header("üìä **9. Estat√≠sticas dos Dados Atualmente Carregados**")
    
    if dados:
        # Gr√°ficos visuais das estat√≠sticas
        st.subheader("üìà **Visualiza√ß√£o das Estat√≠sticas dos Dados**")
        
        chart1, chart2 = create_data_statistics_charts(dados)
        
        if chart1 and chart2:
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(chart1, use_container_width=True)
            with col2:
                st.plotly_chart(chart2, use_container_width=True)
        
        st.subheader("üìã **Tabela Detalhada dos Datasets**")
        
        # Criar tabela com informa√ß√µes dos datasets
        datasets_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame):
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': f"{value.shape[0]:,}",
                    'Colunas': value.shape[1],
                    'Mem√≥ria (MB)': f"{value.memory_usage(deep=True).sum() / 1024**2:.2f}",
                    'Per√≠odo': 'Vari√°vel',
                    'Tipo': 'DataFrame'
                })
            else:
                datasets_info.append({
                    'Dataset': key,
                    'Linhas': '-',
                    'Colunas': '-',
                    'Mem√≥ria (MB)': '-',
                    'Per√≠odo': '-',
                    'Tipo': type(value).__name__
                })
        
        df_info = pd.DataFrame(datasets_info)
        st.dataframe(df_info, use_container_width=True)
        
        # Estat√≠sticas gerais
        total_linhas = sum([v.shape[0] for v in dados.values() if isinstance(v, pd.DataFrame)])
        total_memoria = sum([v.memory_usage(deep=True).sum() for v in dados.values() if isinstance(v, pd.DataFrame)])
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìä Total de Datasets", len(dados))
        with col2:
            st.metric("üìù Total de Registros", f"{total_linhas:,}")
        with col3:
            st.metric("üíæ Mem√≥ria Total", f"{total_memoria/1024**2:.1f} MB")
        with col4:
            st.metric("üóÇÔ∏è Tabelas CSV", len([f for f in os.listdir('TABELAS') if f.endswith('.csv')]))
        
        # An√°lise de qualidade dos dados
        st.subheader("üîç **An√°lise de Qualidade dos Dados**")
        
        qualidade_info = []
        for key, value in dados.items():
            if isinstance(value, pd.DataFrame) and not value.empty:
                missing_percent = (value.isnull().sum().sum() / (value.shape[0] * value.shape[1])) * 100
                duplicatas = value.duplicated().sum()
                
                qualidade_info.append({
                    'Dataset': key,
                    'Missing Values (%)': f"{missing_percent:.2f}%",
                    'Duplicatas': duplicatas,
                    'Completude': f"{100-missing_percent:.1f}%",
                    'Status': "‚úÖ Boa" if missing_percent < 5 and duplicatas < 10 else "‚ö†Ô∏è Aten√ß√£o" if missing_percent < 15 else "‚ùå Cr√≠tica"
                })
        
        if qualidade_info:
            df_qualidade = pd.DataFrame(qualidade_info)
            st.dataframe(df_qualidade, use_container_width=True)
    
    else:
        st.warning("‚ö†Ô∏è Nenhum dado carregado para an√°lise")
    
    # Footer t√©cnico
    st.markdown("---")
    st.markdown("""
    ### üéØ **Conclus√£o T√©cnica**
    
    Este sistema representa uma implementa√ß√£o completa de an√°lise epidemiol√≥gica moderna, integrando:
    - **Automa√ß√£o de dados** com tecnologias Python
    - **An√°lises estat√≠sticas robustas** com m√∫ltiplas metodologias
    - **Visualiza√ß√£o interativa** para explora√ß√£o de dados
    - **Interface intuitiva** para diferentes perfis de usu√°rios
    - **Valida√ß√£o rigorosa** para garantir qualidade cient√≠fica
    
    **Tecnologias Principais:** Python, Pandas, NumPy, SciPy, Scikit-learn, Plotly, Streamlit, Statsmodels
    
    **Padr√µes Seguidos:** PEP 8, Documenta√ß√£o docstring, Type hints, Git workflow, Code review
    """)
